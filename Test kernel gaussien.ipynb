{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook dédiée au test du noyau gaussien avec les différents classifieurs\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.Import des fonctions, créations des fonctions utiles et des classifieurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import numexpr as ne\n",
    "from scipy.stats import uniform\n",
    "from scipy.linalg import solve,lstsq\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from cvxopt import matrix\n",
    "from cvxopt import solvers\n",
    "from itertools import product,compress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kernel_Ridge_Regression(X_train,y_train,lbd,weight,gamma,degree,c0,k,biais,kernel):\n",
    "    if kernel==\"rbf\":\n",
    "        K=rbf_kernel(X_train,gamma)\n",
    "    elif kernel==\"poly\":\n",
    "        K=poly_kernel(X_train,X_train,degree,c0)\n",
    "    elif kernel==\"spectrum\":\n",
    "        K=spectrum_kernel(X_train,k)\n",
    "    elif kernel==\"precomputed\":\n",
    "        K=X_train\n",
    "    n=K.shape[0]\n",
    "    w=weight\n",
    "    if not(biais):\n",
    "        if isinstance(weight,bool):\n",
    "            A=(K+n*lbd*np.eye(n))\n",
    "            alpha=solve(A,y_train,assume_a=\"sym\")\n",
    "            return alpha\n",
    "        elif isinstance(weight,str):\n",
    "                w1=(y_train==1).mean()\n",
    "                w0=1-w1\n",
    "                w=np.where(y_train==1,w1,w0)\n",
    "        wi=(1/w)\n",
    "        \n",
    "        A=K+n*lbd*wi*np.eye(n)\n",
    "        alpha=solve(A,y_train,assume_a=\"sym\")\n",
    "     \n",
    "        return alpha\n",
    "    else:\n",
    "        \n",
    "        Kb=addbiais(K)\n",
    "        \n",
    "        K0=addzeros(K)\n",
    "    \n",
    "        if isinstance(weight,bool):\n",
    "            A=(Kb.T.dot(Kb)+lbd*n*K0)\n",
    "            B=Kb.T.dot(y_train)\n",
    "            alpha=solve(A,B,assume_a=\"sym\")\n",
    "            return alpha\n",
    "        elif isinstance(weight,str):\n",
    "                w1=(y_train==1).mean()\n",
    "                w0=1-w1\n",
    "                w=np.where(y_train==1,w1,w0)\n",
    "        W=np.diag(w)\n",
    "        A=(Kb.T.dot(W.dot(Kb))+lbd*n*K0)\n",
    "        B=Kb.T.dot(W.dot(y_train),assume_a=\"sym\")\n",
    "        alpha=solve(A,B)\n",
    "        return alpha\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelRR(BaseEstimator,ClassifierMixin):\n",
    "    def __init__(self,lbd=1,weight=False,gamma=\"auto\",degree=2,c0=1,k=3,biais=False,kernel=\"rbf\"):\n",
    "        self.lbd=lbd\n",
    "        self.weight=weight\n",
    "        self.gamma=gamma\n",
    "        self.degree=degree\n",
    "        self.c0=c0\n",
    "        self.k=k\n",
    "        self.biais=biais\n",
    "        self.kernel=kernel\n",
    "    def fit(self,X,y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.Xtr=X\n",
    "        if isinstance(self.gamma,str) and self.kernel==\"rbf\":\n",
    "            self.gamma=1/self.Xtr.shape[1]\n",
    "        self.alpha=Kernel_Ridge_Regression(X,y,self.lbd,self.weight,self.gamma,self.degree,self.c0,self.k,self.biais,self.kernel)\n",
    "        return self\n",
    "    def decision_function(self,X):\n",
    "        if self.kernel==\"precomputed\":\n",
    "            return X.dot(self.alpha)\n",
    "        if not(self.biais):\n",
    "            if self.kernel==\"rbf\":\n",
    "                return K_rbf_kernel(X,self.Xtr,self.gamma).dot(self.alpha) \n",
    "            elif self.kernel==\"poly\":\n",
    "                return poly_kernel(X,self.Xtr,self.degree,self.c0).dot(self.alpha) \n",
    "            elif self.kernel==\"spectrum\":\n",
    "                return K_spectrum_kernel(X,self.Xtr,self.k).dot(self.alpha) \n",
    "        else:\n",
    "            if self.kernel==\"rbf\":\n",
    "                return addbiais(K_rbf_kernel(X,self.Xtr,self.gamma)).dot(self.alpha)\n",
    "            elif self.kernel==\"poly\":\n",
    "                return addbiais(poly_kernel(X,self.Xtr,self.degree,self.c0)).dot(self.alpha)\n",
    "            elif self.kernel==\"spectrum\":\n",
    "                return addbiais(K_spectrum_kernel(X,self.Xtr,self.k)).dot(self.alpha)\n",
    "\n",
    "    def predict(self,X,y=None):\n",
    "        scores=self.decision_function(X)\n",
    "        if len(scores.shape) == 1:\n",
    "            indices = (scores > 0).astype(np.int)\n",
    "        else:\n",
    "            indices = scores.argmax(axis=1)\n",
    "        return self.classes_[indices]\n",
    "   \n",
    "    def get_params(self, deep=True):\n",
    "    \n",
    "        return {\"lbd\": self.lbd,\"weight\":self.weight,\"gamma\":self.gamma,\"degree\":self.degree,\"c0\":self.c0,\"k\":self.k,\n",
    "                \"biais\":self.biais,\"kernel\":self.kernel}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Kernel Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(v):\n",
    "    return 1/(1+np.exp(-v))\n",
    "def log_loss(v):\n",
    "    return np.log(1+np.exp(-v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IRLS(X_train,y_train,lbd,ga,degree,c0,k,bs,ker,n_iter,eps=10**-6,method='slow'):\n",
    "    n=y_train.shape[0]\n",
    "  \n",
    "    if ker==\"rbf\":\n",
    "        K=rbf_kernel(X_train,ga)\n",
    "    elif ker==\"poly\":\n",
    "        K=poly_kernel(X_train,X_train,degree,c0)\n",
    "    elif ker==\"spectrum\":\n",
    "        K=spectrum_kernel(X_train,k)\n",
    "    elif ker==\"precomputed\":\n",
    "        K=X_train\n",
    "    #alpha=Kernel_Ridge_Regression(K,y_train,lbd,False,1,bs,\"precomputed\")\n",
    "    #alpha=np.zeros(n)\n",
    "    #l=[]\n",
    "  \n",
    "    if bs :\n",
    "        Kb=addbiais(K)\n",
    "        K0=addzeros(K)\n",
    "        alpha=np.zeros(n+1)\n",
    "    else:\n",
    "        alpha=np.zeros(n)\n",
    "    for i in range(n_iter):\n",
    "   \n",
    "        alpha_old=alpha\n",
    "       \n",
    "        if bs:\n",
    "            m=Kb.dot(alpha)\n",
    "            #l.append(log_loss(y_train*m).mean()+lbd*alpha[:-1].dot(K.dot(alpha[:-1])))\n",
    "        \n",
    "        else:\n",
    "            m=K.dot(alpha)\n",
    "            #l.append(log_loss(y_train*m).mean()+lbd*alpha.dot(m))\n",
    "        \n",
    "        \n",
    "        p=sigmoid(m)\n",
    "       \n",
    "        weight=p*(1-p)\n",
    "       \n",
    "        weight=np.where(weight<0.000001,0.000001,weight)\n",
    "       \n",
    "   \n",
    "        u=np.where(sigmoid(y_train*m)<0.000001,0.000001,sigmoid(y_train*m))\n",
    "        z = m + y_train/u\n",
    "    \n",
    "        if not(bs):\n",
    "        \n",
    "            S = np.diag(weight**-1)\n",
    "            A=(K+2*lbd*n*S)\n",
    "            alpha=solve(A,z,assume_a=\"sym\")\n",
    "            \n",
    "            #print(np.linalg.norm(alpha_old-alpha))\n",
    "            \n",
    "            if np.linalg.norm(alpha_old-alpha)<eps:\n",
    "                break\n",
    "        else:\n",
    "            S = np.diag(weight)\n",
    "            A=(Kb.T.dot(S.dot(Kb))+2*lbd*n*K0)\n",
    "            B=Kb.T.dot(S.dot(z))\n",
    "            if method==\"slow\":\n",
    "                alpha=lstsq(A,B)[0]\n",
    "            else:\n",
    "                alpha=solve(A,B,assume_a=\"sym\")\n",
    "            #print(np.linalg.norm(alpha_old-alpha))\n",
    "            if np.linalg.norm(alpha_old-alpha)<eps:\n",
    "                break\n",
    "                \n",
    "       \n",
    "    return alpha #,l\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelLR(BaseEstimator,ClassifierMixin):\n",
    "    def __init__(self,lbd=1,gamma='auto',degree=2,c0=1,k=3,biais=False,kernel=\"rbf\",n_iter=15,method=\"slow\"):\n",
    "        self.lbd=lbd\n",
    "        self.gamma=gamma\n",
    "        self.degree=degree\n",
    "        self.c0=c0\n",
    "        self.k=k\n",
    "        self.biais=biais\n",
    "        self.kernel=kernel\n",
    "        self.n_iter=n_iter\n",
    "        self.method=method\n",
    "    def fit(self,X,y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.Xtr=X\n",
    "        if isinstance(self.gamma,str) and self.kernel==\"rbf\":\n",
    "            self.gamma=1/self.Xtr.shape[1]\n",
    "        self.alpha=IRLS(X,y,self.lbd,self.gamma,self.degree,self.c0,self.k,self.biais,self.kernel,self.n_iter,method=self.method)\n",
    "        return self\n",
    "    def decision_function(self,X):\n",
    "        if not(self.biais):\n",
    "            if self.kernel==\"precomputed\":\n",
    "                return X.dot(self.alpha)\n",
    "            if self.kernel==\"rbf\":\n",
    "                return K_rbf_kernel(X,self.Xtr,self.gamma).dot(self.alpha) \n",
    "            elif self.kernel==\"poly\":\n",
    "                return poly_kernel(X,self.Xtr,self.degree,self.c0).dot(self.alpha) \n",
    "            elif self.kernel==\"spectrum\":\n",
    "                return K_spectrum_kernel(X,self.Xtr,self.k).dot(self.alpha) \n",
    "        else:\n",
    "            if self.kernel==\"rbf\":\n",
    "                return addbiais(K_rbf_kernel(X,self.Xtr,self.gamma)).dot(self.alpha)\n",
    "            elif self.kernel==\"poly\":\n",
    "                return addbiais(poly_kernel(X,self.Xtr,self.degree,self.c0)).dot(self.alpha)\n",
    "            elif self.kernel==\"spectrum\":\n",
    "                return addbiais(K_spectrum_kernel(X,self.Xtr,self.k)).dot(self.alpha)\n",
    "        \n",
    "\n",
    "    def predict(self,X,y=None):\n",
    "        scores=self.decision_function(X)\n",
    "        if len(scores.shape) == 1:\n",
    "            indices = (scores > 0).astype(np.int)\n",
    "        else:\n",
    "            indices = scores.argmax(axis=1)\n",
    "        return self.classes_[indices]\n",
    "    def predict_proba_(self,X,y=None):\n",
    "        p=sigmoid(self.decision_function(X)).reshape(-1,1)\n",
    "        return hstack((p,1-p))\n",
    "    def get_params(self, deep=True):\n",
    "    \n",
    "        return {\"lbd\": self.lbd,\"gamma\":self.gamma,\"degree\":self.degree,\"c0\":self.c0,\"k\":self.k,\"biais\":self.biais,\n",
    "                \"kernel\":self.kernel,\"n_iter\":self.n_iter,\"method\":self.method}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(X_train,y_train,C,gamma,degree,c0,k,kernel):\n",
    "    n=y_train.shape[0]\n",
    "    if kernel==\"rbf\":\n",
    "        K=rbf_kernel(X_train,gamma)\n",
    "    elif kernel==\"poly\":\n",
    "        K=poly_kernel(X_train,X_train,degree,c0)\n",
    "    elif kernel==\"spectrum\":\n",
    "        K=spectrum_kernel(X_train,k)\n",
    "    elif kernel==\"precomputed\":\n",
    "        K=X_train\n",
    "    P=matrix(K,tc='d')\n",
    "    q=matrix(-y_train,tc='d')\n",
    "    g1=np.diag(y_train)\n",
    "    G=matrix(np.vstack((g1,-g1)),tc='d')\n",
    "    h=matrix(np.hstack((np.repeat(C,n),np.zeros(n))),tc='d')\n",
    "    solvers.options['show_progress'] = False\n",
    "    sol=solvers.qp(P,q,G,h)\n",
    "    return np.array(sol['x']).reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelSVM(BaseEstimator,ClassifierMixin):\n",
    "    def __init__(self,C=1,gamma='auto',degree=\"2\",c0=1,k=3,kernel=\"rbf\"):\n",
    "        self.C=C\n",
    "        self.gamma=gamma\n",
    "        self.degree=degree\n",
    "        self.c0=c0\n",
    "        self.k=k\n",
    "        self.kernel=kernel\n",
    "    def fit(self,X,y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.Xtr=X\n",
    "        if isinstance(self.gamma,str) and self.kernel==\"rbf\":\n",
    "            self.gamma=1/self.Xtr.shape[1]\n",
    "        self.alpha=SVM(X,y,self.C,self.gamma,self.degree,self.c0,self.k,self.kernel)\n",
    "        #idx=self.alpha>10**-5\n",
    "        #self.Xtr=self.Xtr[idx]\n",
    "        #self.alpha=self.alpha[idx]\n",
    "        return self\n",
    "    def decision_function(self,X):\n",
    "        if self.kernel==\"precomputed\":\n",
    "            return X.dot(self.alpha)\n",
    "        elif self.kernel==\"rbf\":\n",
    "            return K_rbf_kernel(X,self.Xtr,self.gamma).dot(self.alpha) \n",
    "        elif self.kernel==\"poly\":\n",
    "            return poly_kernel(X,self.Xtr,self.degree,self.c0).dot(self.alpha) \n",
    "        elif self.kernel==\"spectrum\":\n",
    "            return K_spectrum_kernel(X,self.Xtr,self.k).dot(self.alpha) \n",
    "            \n",
    "           \n",
    "    def predict(self,X,y=None):\n",
    "        scores=self.decision_function(X)\n",
    "        if len(scores.shape) == 1:\n",
    "            indices = (scores > 0).astype(np.int)\n",
    "        else:\n",
    "            indices = scores.argmax(axis=1)\n",
    "        return self.classes_[indices]\n",
    "    def get_params(self, deep=True):\n",
    "    \n",
    "        return {\"C\": self.C,\"gamma\":self.gamma,\"degree\":self.degree,\"c0\":self.c0,\"k\":self.k,\"kernel\":self.kernel}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.4 Fonctions utiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def présentation_résultat(search,n):\n",
    "    mask=search.cv_results_['rank_test_score']<=n\n",
    "    params=list(compress(search.cv_results_['params'], list(mask)))\n",
    "    mean_test_score=search.cv_results_['mean_test_score'][mask]\n",
    "    a={}\n",
    "    for i in range(mean_test_score.size):\n",
    "        k=''\n",
    "        for key, value in params[i].items():\n",
    "            k+=\" \"+key+\" \"+str(value)\n",
    "        a.update({k:mean_test_score[i]})\n",
    "        sortedDict = sorted(a.items(), key=lambda x: x[1],reverse=True)\n",
    "    l=[]\n",
    "    for i in sortedDict:\n",
    "        u=i[0].split(sep=' ')\n",
    "        del(u[0])\n",
    "        lp=[]\n",
    "        for j in u[1::2]:\n",
    "            lp.append(j)\n",
    "        lp.append(i[1])\n",
    "        l.append(lp)\n",
    "    head=list(params[0].keys())+[\"mean_test_score\"]\n",
    "\n",
    "    return(pd.DataFrame(l,columns=head))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addbiais(X):\n",
    "    return np.hstack((X,np.ones((X.shape[0],1))))\n",
    "def addzeros(X):\n",
    "    n,_=X.shape\n",
    "    A=np.zeros((n+1,n+1))\n",
    "    A[:n,:n]=X\n",
    "    return(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_file(models,filename): #models is a list of 3 models\n",
    "    Y_test=np.empty(0)\n",
    "    for X_train, Y_train, X_test, model  in zip([X_0train,X_1train,X_2train], [Y_0train,Y_1train,Y_2train], [X_0test,X_1test,X_2test], models):\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred=model.predict(X_test)\n",
    "        Y_test=np.concatenate((Y_test,np.where(Y_pred==-1,0,Y_pred)), axis=0)\n",
    "    \n",
    "    Y_test=Y_test.reshape(len(Y_test),1)\n",
    "    \n",
    "    ids=np.arange(Y_test.shape[0])\n",
    "    ids=ids.reshape(len(ids),1)\n",
    "    \n",
    "    df=pd.DataFrame(data=np.concatenate((ids,Y_test), axis=1), columns=['Id','Bound'],dtype=np.int)\n",
    "    \n",
    "    return df.to_csv('Predictions/'+filename, index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.5 Kernel gaussien "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_kernel(X_train,gamma):\n",
    "    X_norm = np.sum(X_train ** 2, axis = -1)\n",
    "    K = ne.evaluate('exp(-g * (A + B - 2 * C))', {\n",
    "        'A' : X_norm[:,None],\n",
    "        'B' : X_norm[None,:],\n",
    "        'C' : np.dot(X_train, X_train.T),\n",
    "        'g' : gamma,\n",
    "    })\n",
    "    return K\n",
    "\n",
    "def K_rbf_kernel(X_test,X_train,gamma):\n",
    "   \n",
    "    Xtt_norm = np.sum(X_test ** 2, axis = -1)\n",
    "    Xtr_norm = np.sum(X_train ** 2, axis = -1)\n",
    "    K = ne.evaluate('exp(-g * (A + B - 2 * C))', {\n",
    "        'A' : Xtt_norm[:,None],\n",
    "        'B' : Xtr_norm[None,:],\n",
    "        'C' : np.dot(X_test, X_train.T),\n",
    "        'g' : gamma,\n",
    "    })\n",
    "    return K\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Test des différents classifieurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0=pd.read_csv(\"Data/Xtr0_mat100.csv\",sep=' ',header=None)\n",
    "X_1=pd.read_csv(\"Data/Xtr1_mat100.csv\",sep=' ',header=None)\n",
    "X_2=pd.read_csv(\"Data/Xtr2_mat100.csv\",sep=' ',header=None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Y_0=pd.read_csv(\"Data/Ytr0.csv\",sep=',')\n",
    "Y_1=pd.read_csv(\"Data/Ytr1.csv\",sep=',')\n",
    "Y_2=pd.read_csv(\"Data/Ytr2.csv\",sep=',')\n",
    "\n",
    "Y_0train=np.where(Y_0[\"Bound\"]==0,-1,Y_0[\"Bound\"])\n",
    "Y_1train=np.where(Y_1[\"Bound\"]==0,-1,Y_1[\"Bound\"])\n",
    "Y_2train=np.where(Y_2[\"Bound\"]==0,-1,Y_2[\"Bound\"])\n",
    "\n",
    "X_0train=X_0.to_numpy()\n",
    "X_1train=X_1.to_numpy()\n",
    "X_2train=X_2.to_numpy()\n",
    "\n",
    "X_0test=pd.read_csv(\"Data/Xte0_mat100.csv\",sep=' ',header=None).to_numpy()\n",
    "X_1test=pd.read_csv(\"Data/Xte1_mat100.csv\",sep=' ',header=None).to_numpy()\n",
    "X_2test=pd.read_csv(\"Data/Xte2_mat100.csv\",sep=' ',header=None).to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Tests de Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KRR=make_pipeline(StandardScaler(),KernelRR(kernel=\"rbf\"))\n",
    "print(KRR)\n",
    "\n",
    "hps0={'kernelrr__lbd':[10**-6,10**-5,10**-4,10**-3,10**-2,10**-1,1,10]}\n",
    "searchKRR0= GridSearchCV(KRR,hps0,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKRR0.fit(X_0train, Y_0train)\n",
    "\n",
    "hps1={\"kernelrr__lbd\":[10**-6,10**-5,10**-4,10**-3,10**-2,10**-1,1,10]}\n",
    "searchKRR1= GridSearchCV(KRR,hps1,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKRR1.fit(X_1train, Y_1train)\n",
    "\n",
    "\n",
    "hps2={\"kernelrr__lbd\":[10**-6,10**-5,10**-4,10**-3,10**-2,10**-1,1,10]}\n",
    "searchKRR2= GridSearchCV(KRR,hps2,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKRR2.fit(X_2train, Y_2train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKRR0,10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKRR1,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKRR2,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KRR=make_pipeline(StandardScaler(),KernelRR(weight=False,gamma=\"auto\",kernel=\"rbf\"))\n",
    "print(KRR)\n",
    "\n",
    "hps0={\"kernelrr__lbd\":uniform(loc=10**-4,scale=5*10**-2)}\n",
    "searchKRR0= RandomizedSearchCV(KRR,hps0,n_iter=500,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKRR0.fit(X_0train, Y_0train)\n",
    "\n",
    "hps1={\"kernelrr__lbd\":uniform(loc=5*10**-5,scale=5*10**-2)}\n",
    "searchKRR1=RandomizedSearchCV(KRR,hps1,n_iter=500,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKRR1.fit(X_1train, Y_1train)\n",
    "\n",
    "\n",
    "hps2={\"kernelrr__lbd\":uniform(loc=5*10**-5,scale=5*10**-2)}\n",
    "searchKRR2= RandomizedSearchCV(KRR,hps2,n_iter=100,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKRR2.fit(X_2train, Y_2train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKRR0,10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKRR1,10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKRR2,10)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Tests de Kernel Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KLR=make_pipeline(StandardScaler(),KernelLR())\n",
    "print(KLR)\n",
    "\n",
    "hps0={'kernellr__lbd':[10**-6,10**-5,10**-4,10**-3,10**-2,10**-1,1,10]}\n",
    "searchKLR0= GridSearchCV(KLR,hps0,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKLR0.fit(X_0train, Y_0train)\n",
    "\n",
    "hps1={'kernellr__lbd':[10**-6,10**-5,10**-4,10**-3,10**-2,10**-1,1,10]}\n",
    "searchKLR1= GridSearchCV(KLR,hps1,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKLR1.fit(X_1train, Y_1train)\n",
    "\n",
    "\n",
    "hps2={'kernellr__lbd':[10**-6,10**-5,10**-4,10**-3,10**-2,10**-1,1,10]}\n",
    "searchKLR2= GridSearchCV(KLR,hps2,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKLR2.fit(X_2train, Y_2train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKLR0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKLR1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKLR2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps0={\"kernellr__lbd\":uniform(loc=5*10**-6,scale=5*10**-3)}\n",
    "searchKLR0= RandomizedSearchCV(KLR,hps0,n_iter=500,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKLR0.fit(X_0train, Y_0train)\n",
    "\n",
    "hps1={\"kernellr__lbd\":uniform(loc=5*10**-7,scale=5*10**-3)}\n",
    "searchKLR1=RandomizedSearchCV(KLR,hps1,n_iter=500,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKLR1.fit(X_1train, Y_1train)\n",
    "\n",
    "\n",
    "hps2={\"kernellr__lbd\":uniform(loc=5*10**-7,scale=5*10**-3)}\n",
    "searchKLR2= RandomizedSearchCV(KLR,hps2,n_iter=500,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKLR2.fit(X_2train, Y_2train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKLR0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKLR1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKLR2,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Test de Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KSVM=make_pipeline(StandardScaler(),KernelSVM())\n",
    "print(KSVM)\n",
    "\n",
    "hps0={'kernelsvm__C':[10**-2,10**-1,1,10,50,100,500,1000]}\n",
    "searchKSVM0= GridSearchCV(KSVM,hps0,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKSVM0.fit(X_0train, Y_0train)\n",
    "\n",
    "hps1={'kernelsvm__C':[10**-2,10**-1,1,10,50,100,500,1000]}\n",
    "searchKSVM1= GridSearchCV(KSVM,hps1,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKSVM1.fit(X_1train, Y_1train)\n",
    "\n",
    "\n",
    "hps2={'kernelsvm__C':[10**-2,10**-1,1,10,50,100,500,1000]}\n",
    "searchKSVM2= GridSearchCV(KSVM,hps2,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKSVM2.fit(X_2train, Y_2train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKSVM0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKSVM1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKSVM2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps0={\"kernelsvm__C\":uniform(loc=0.5,scale=5)}\n",
    "searchKSVM0= RandomizedSearchCV(KSVM,hps0,n_iter=100,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKSVM0.fit(X_0train, Y_0train)\n",
    "\n",
    "hps1={\"kernelsvm__C\":uniform(loc=0.5,scale=5)}\n",
    "searchKSVM1= RandomizedSearchCV(KSVM,hps1,n_iter=100,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKSVM1.fit(X_1train, Y_1train)\n",
    "\n",
    "hps2={\"kernelsvm__C\":uniform(loc=0.1,scale=3)}\n",
    "searchKSVM2= RandomizedSearchCV(KSVM,hps2,n_iter=100,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKSVM2.fit(X_2train, Y_2train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKSVM0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKSVM1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKSVM2,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Elaboration du model final et création du fichier csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KLR0=make_pipeline(StandardScaler(),KernelLR(lbd=0.00018))\n",
    "KLR1=make_pipeline(StandardScaler(),KernelLR(lbd=0.00016))\n",
    "KLR2=make_pipeline(StandardScaler(),KernelLR(lbd=5.89*(10**-5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file([KLR0,KLR1,KLR2],filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
