{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel methods \n",
    "\n",
    "### Import des fonctions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV,StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.linalg import solve,lstsq\n",
    "from scipy.stats import uniform\n",
    "from cvxopt import matrix\n",
    "from cvxopt import solvers\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from itertools import compress, product\n",
    "import numexpr as ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  Bound\n",
       "0        0      0\n",
       "1        1      1\n",
       "2        2      1\n",
       "3        3      1\n",
       "4        4      1\n",
       "...    ...    ...\n",
       "1995  1995      0\n",
       "1996  1996      1\n",
       "1997  1997      0\n",
       "1998  1998      0\n",
       "1999  1999      0\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_0=pd.read_csv(\"Data/Xtr0_mat100.csv\",sep=' ',header=None)\n",
    "X_1=pd.read_csv(\"Data/Xtr1_mat100.csv\",sep=' ',header=None)\n",
    "X_2=pd.read_csv(\"Data/Xtr2_mat100.csv\",sep=' ',header=None)\n",
    "\n",
    "\n",
    "Y_0=pd.read_csv(\"Data/Ytr0.csv\",sep=',')\n",
    "Y_1=pd.read_csv(\"Data/Ytr1.csv\",sep=',')\n",
    "Y_2=pd.read_csv(\"Data/Ytr2.csv\",sep=',')\n",
    "\n",
    "Y_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1038\n",
      "1     962\n",
      "Name: Bound, dtype: int64\n",
      "1    1001\n",
      "0     999\n",
      "Name: Bound, dtype: int64\n",
      "0    1003\n",
      "1     997\n",
      "Name: Bound, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Y_0[\"Bound\"].value_counts())\n",
    "print(Y_1[\"Bound\"].value_counts())\n",
    "print(Y_2[\"Bound\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les classes sont plutôt équilibrées "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 100)\n"
     ]
    }
   ],
   "source": [
    "Y_0train=np.where(Y_0[\"Bound\"]==0,-1,Y_0[\"Bound\"])\n",
    "Y_1train=np.where(Y_1[\"Bound\"]==0,-1,Y_1[\"Bound\"])\n",
    "Y_2train=np.where(Y_2[\"Bound\"]==0,-1,Y_2[\"Bound\"])\n",
    "\n",
    "X_0train=X_0.to_numpy()\n",
    "X_1train=X_1.to_numpy()\n",
    "X_2train=X_2.to_numpy()\n",
    "print(X_0train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression ( équivalent à Kernel ridge régression avec noyau linéaire) \n",
    "On ajoute une colonne de biais "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0train_forRR=np.hstack((np.ones((X_0train.shape[0],1)),X_0train))\n",
    "X_1train_forRR=np.hstack((np.ones((X_0train.shape[0],1)),X_0train))\n",
    "X_2train_forRR=np.hstack((np.ones((X_0train.shape[0],1)),X_0train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solver ridge Regression \n",
    "Même si les classes sont équilibrées je laisse la possibilité de modifier les poids. Enfin pas vraiment puisque le seul poids que je met quand on souhaite en mettre c'est le poid correspondant au poids des classes dans le set qui sera entraîné.\n",
    "J'utilisais lstsq pour résoudre le système lineaire car plus stable si la matrice est mal conditionné/pas inversible mais cela prend beaucoup plus de temps que solve, ducoup je suis repassé à solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ridge_Regresssion(X_train,y_train,lbd,weight=False):\n",
    "    n=y_train.shape[0]\n",
    "    d=X_train.shape[1]\n",
    "    if not(weight):\n",
    "        A=(X_train.T.dot(X_train))/n+lbd*np.eye(d)\n",
    "        B=X_train.T.dot(y_train)/n\n",
    "        theta=solve(A,B)\n",
    "        return theta\n",
    "    else:\n",
    "        w1=(y_train==1).mean()\n",
    "        w0=1-w1\n",
    "        w=np.where(y_train==1,w1,w0)\n",
    "        W=np.diag(w)\n",
    "        A=(X_train.T.dot(W.dot(X_train)))/n+lbd*np.eye(d)\n",
    "        B=X_train.T.dot(W.dot(y_train))/n\n",
    "        theta=solve(A,B)\n",
    "        return theta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Création de l'estimateur Ridge regression compatible avec l'API de scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRR(BaseEstimator,ClassifierMixin):\n",
    "    def __init__(self,lbd=1,weight=False):\n",
    "        self.lbd=lbd\n",
    "        self.weight=weight\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        \n",
    "        self.theta=Ridge_Regresssion(X,y,self.lbd,self.weight)\n",
    "        return self\n",
    "    def decision_function(self,X):\n",
    "        return X.dot(self.theta)\n",
    "        \n",
    "    def predict(self,X,y=None):\n",
    "        scores=self.decision_function(X)\n",
    "        if len(scores.shape) == 1:\n",
    "            indices = (scores > 0).astype(np.int)\n",
    "        else:\n",
    "            indices = scores.argmax(axis=1)\n",
    "        return self.classes_[indices]\n",
    "   \n",
    "    def get_params(self, deep=True):\n",
    "    \n",
    "        return {\"lbd\": self.lbd,\"weight\":self.weight}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction permettant d'afficher les n meilleurs résultats avec les paramètres associées d'une grid search dans un tableau (dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def présentation_résultat(search,n):\n",
    "    mask=search.cv_results_['rank_test_score']<=n\n",
    "    params=list(compress(search.cv_results_['params'], list(mask)))\n",
    "    mean_test_score=search.cv_results_['mean_test_score'][mask]\n",
    "    a={}\n",
    "    for i in range(mean_test_score.size):\n",
    "        k=''\n",
    "        for key, value in params[i].items():\n",
    "            k+=\" \"+key+\" \"+str(value)\n",
    "        a.update({k:mean_test_score[i]})\n",
    "        sortedDict = sorted(a.items(), key=lambda x: x[1],reverse=True)\n",
    "    l=[]\n",
    "    for i in sortedDict:\n",
    "        u=i[0].split(sep=' ')\n",
    "        del(u[0])\n",
    "        lp=[]\n",
    "        for j in u[1::2]:\n",
    "            lp.append(j)\n",
    "        lp.append(i[1])\n",
    "        l.append(lp)\n",
    "    head=list(params[0].keys())+[\"mean_test_score\"]\n",
    "\n",
    "    return(pd.DataFrame(l,columns=head))\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Première recherche des hyperparamètres pour chaque train set \n",
    "Je crée un pipeline composé d'un transformer de données et de la ridge regression. Dans la manière dont j'ai défini la pipeline le transformer en question est *StandardScaler()* qui standardise les données ((X-mean)/std)). Attention cela standardise les données selon la mean et std du train set et donc lors d'une prédiction le test/validation set sera standardisé par rapport à la mean et std du training set. \n",
    "En soit la manière dont j'ai défini le tranformeur n'a pas d'importance car dans la gridSearch je teste d'autres transformeur à certain moment(mais fallait bien en mettre pour faire la pipeline), il y a même une option *\"passthrough\"* pour la première étape de la pipeline qui veut dire tout simplement passer à l'étape suivante et donc ne pas transfomrer mes données.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RR=Pipeline([(\"preprocess\",StandardScaler()),(\"linearrr\",LinearRR())])\n",
    "print(RR)\n",
    "\n",
    "hps0={\"linearrr__lbd\":[10**-6,10**-5,10**-4,10**-3,10**-2,10**-1,1,10],\"linearrr__weight\":[False,True],\n",
    "     \"preprocess\":[\"passthrough\",StandardScaler(),RobustScaler(),MinMaxScaler()]}\n",
    "searchLRR0= GridSearchCV(RR,hps0,scoring=\"accuracy\",cv=5,verbose=1)\n",
    "searchLRR0.fit(X_0train_forRR, Y_0train)\n",
    "\n",
    "hps1={\"linearrr__lbd\":[10**-6,10**-5,10**-4,10**-3,10**-2,10**-1,1,10],\"linearrr__weight\":[False,True],\n",
    "     \"preprocess\":[\"passthrough\",StandardScaler(),RobustScaler(),MinMaxScaler()]}\n",
    "searchLRR1= GridSearchCV(RR,hps1,scoring=\"accuracy\",cv=5,verbose=1)\n",
    "searchLRR1.fit(X_1train_forRR, Y_1train)\n",
    "\n",
    "\n",
    "hps2={\"linearrr__lbd\":[10**-6,10**-5,10**-4,10**-3,10**-2,10**-1,1,10],\"linearrr__weight\":[False,True],\n",
    "     \"preprocess\":[\"passthrough\",StandardScaler(),RobustScaler(),MinMaxScaler()]}\n",
    "searchLRR2= GridSearchCV(RR,hps2,scoring=\"accuracy\",cv=5,verbose=1)\n",
    "searchLRR2.fit(X_2train_forRR, Y_2train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage des résulats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchLRR0,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchLRR1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchLRR2,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche plus fine dans les zones d'intérêts déterminés à l'aide la search précedente\n",
    "\n",
    "Ici je fais une RandomizedGrid search car j'ai beaucoup plus d'informations sur les zones d'intérêts où il faut chercher(notamment pour le lambda). Si je l'avais fait avant étant donné que j'avais aucun à priori sur la valeur de lambda la recherche au hasard aurait été plus difficile. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hps0={\"linearrr__lbd\":uniform(loc=0.005,scale=5),\"linearrr__weight\":[False,True]}\n",
    "searchLRR0= RandomizedSearchCV(RR,hps0,n_iter=500,scoring=\"accuracy\",cv=5,verbose=1)\n",
    "searchLRR0.fit(X_0train_forRR, Y_0train)\n",
    "\n",
    "hps1={\"linearrr__lbd\":uniform(loc=0.05,scale=15),\"linearrr__weight\":[False,True],\n",
    "     \"preprocess\":[\"passthrough\",StandardScaler(),RobustScaler(),MinMaxScaler()]}\n",
    "searchLRR1= RandomizedSearchCV(RR,hps1,n_iter=1000,scoring=\"accuracy\",cv=5,verbose=1)\n",
    "searchLRR1.fit(X_1train_forRR, Y_1train)\n",
    "\n",
    "\n",
    "hps2={\"linearrr__lbd\":uniform(loc=0.005,scale=15),\"linearrr__weight\":[False,True],\n",
    "     \"preprocess\":[\"passthrough\"]}\n",
    "searchLRR2= RandomizedSearchCV(RR,hps2,n_iter=500,scoring=\"accuracy\",cv=5,verbose=1)\n",
    "searchLRR2.fit(X_2train_forRR, Y_2train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Présentation des résultats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchLRR0,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchLRR1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchLRR2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche encore plus fine (sert pas trop à grand chose car on va garder ce modèle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps0={\"linearrr__lbd\":uniform(loc=0.8,scale=1.2),\"linearrr__weight\":[False]}\n",
    "searchLRR0= RandomizedSearchCV(RR,hps0,n_iter=100,scoring=\"accuracy\",cv=5,verbose=1)\n",
    "searchLRR0.fit(X_0train_forRR, Y_0train)\n",
    "\n",
    "hps1={\"linearrr__lbd\":uniform(loc=0.01,scale=1.5),\"linearrr__weight\":[False],\n",
    "     \"preprocess\":[\"passthrough\"]}\n",
    "searchLRR1= RandomizedSearchCV(RR,hps1,n_iter=100,scoring=\"accuracy\",cv=5,verbose=1)\n",
    "searchLRR1.fit(X_1train_forRR, Y_1train)\n",
    "\n",
    "\n",
    "hps2={\"linearrr__lbd\":uniform(loc=0.005,scale=0.1),\"linearrr__weight\":[False],\n",
    "     \"preprocess\":[\"passthrough\"]}\n",
    "searchLRR2= RandomizedSearchCV(RR,hps2,n_iter=100,scoring=\"accuracy\",cv=5,verbose=1)\n",
    "searchLRR2.fit(X_2train_forRR, Y_2train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Présentation des résultats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchLRR0,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchLRR1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchLRR2,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Ridge regression \n",
    "\n",
    "### Crétion du kernel de manière efficiente voir ce lien pour comprendre https://stackoverflow.com/questions/47271662/what-is-the-fastest-way-to-compute-an-rbf-kernel-in-python \n",
    "Mais ce qu'il y a retenir c'est que $\\| x-y \\|^2=\\|x\\|^2 + \\|y\\|^2 -2x^Ty$ et d'utiliser à son avantage le broadcast de Numpy. Le ne.evaluate est là pour rendre l'opération plus rapide mais l'opération qui est faite et bien \"exp(-g*(A+B-2*C))\" Avec les A B C g correspondant. D'ailleurs la propriété précédente nous permet de manière générale de calculer la matrice $K(x_i,y_i)$ pour $y_1,\\dots,y_k ~~x_1,\\dots,x_n$  $y_i,x_i \\in R^d$ La kernel matrice et un cas particulier où $n=k$ et $x_i=y_i$ pour tout $i$.\n",
    "Cette fonction est contruite juste après la fonction qui construit la kernel matrice. Elle nous sera très utile en espérant que vous aviez déjà deviné pourquoi, c'est pour  calculer $\\left(f(z_1),\\dots,f(z_k)\\right)$ oû $f(z_j)=\\sum_{i=1}^{n}\\alpha_i K(z_j,x_i)$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_kernel(X_train,gamma):\n",
    "    X_norm = np.sum(X_train ** 2, axis = -1)\n",
    "    K = ne.evaluate('exp(-g * (A + B - 2 * C))', {\n",
    "        'A' : X_norm[:,None],\n",
    "        'B' : X_norm[None,:],\n",
    "        'C' : np.dot(X_train, X_train.T),\n",
    "        'g' : gamma,\n",
    "    })\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_rbf_kernel(X_test,X_train,gamma):\n",
    "   \n",
    "    Xtt_norm = np.sum(X_test ** 2, axis = -1)\n",
    "    Xtr_norm = np.sum(X_train ** 2, axis = -1)\n",
    "    K = ne.evaluate('exp(-g * (A + B - 2 * C))', {\n",
    "        'A' : Xtt_norm[:,None],\n",
    "        'B' : Xtr_norm[None,:],\n",
    "        'C' : np.dot(X_test, X_train.T),\n",
    "        'g' : gamma,\n",
    "    })\n",
    "    return K\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_kernel(X,Y,degree,c0):\n",
    "    return (X.dot(Y.T)+c0)**degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addbiais(X):\n",
    "    return np.hstack((X,np.ones((X.shape[0],1))))\n",
    "def addzeros(X):\n",
    "    n,_=X.shape\n",
    "    A=np.zeros((n+1,n+1))\n",
    "    A[:n,:n]=X\n",
    "    return(A)\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du solver Kernel ridge regresion\n",
    "\n",
    "Comme vous l'avez remarqué je laisse la possibilité d'ajouter un paramètre de biais à l'estimateur ($f(x)=\\sum_{i=1}^{n}K(xi,x)\\,+b)$ mais qui n'est pas pénalisé!! car cela aurait aucun sens. Cela mène bien au système d'équation que je résouds dans la partie *bais* du solver qui suit, vérifier à la main si vous n'êtes pas convaincu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kernel_Ridge_Regression(X_train,y_train,lbd,weight,gamma,degree,c0,k,biais,kernel):\n",
    "    if kernel==\"rbf\":\n",
    "        K=rbf_kernel(X_train,gamma)\n",
    "    elif kernel==\"poly\":\n",
    "        K=poly_kernel(X_train,X_train,degree,c0)\n",
    "    elif kernel==\"spectrum\":\n",
    "        K=spectrum_kernel(X_train,k)\n",
    "    elif kernel==\"precomputed\":\n",
    "        K=X_train\n",
    "    n=K.shape[0]\n",
    "    w=weight\n",
    "    if not(biais):\n",
    "        if isinstance(weight,bool):\n",
    "            A=(K+n*lbd*np.eye(n))\n",
    "            alpha=solve(A,y_train,assume_a=\"sym\")\n",
    "            return alpha\n",
    "        elif isinstance(weight,str):\n",
    "                w1=(y_train==1).mean()\n",
    "                w0=1-w1\n",
    "                w=np.where(y_train==1,w1,w0)\n",
    "        wi=(1/w)\n",
    "        \n",
    "        A=K+n*lbd*wi*np.eye(n)\n",
    "        alpha=solve(A,y_train,assume_a=\"sym\")\n",
    "     \n",
    "        return alpha\n",
    "    else:\n",
    "        \n",
    "        Kb=addbiais(K)\n",
    "        \n",
    "        K0=addzeros(K)\n",
    "    \n",
    "        if isinstance(weight,bool):\n",
    "            A=(Kb.T.dot(Kb)+lbd*n*K0)\n",
    "            B=Kb.T.dot(y_train)\n",
    "            alpha=solve(A,B,assume_a=\"sym\")\n",
    "            return alpha\n",
    "        elif isinstance(weight,str):\n",
    "                w1=(y_train==1).mean()\n",
    "                w0=1-w1\n",
    "                w=np.where(y_train==1,w1,w0)\n",
    "        W=np.diag(w)\n",
    "        A=(Kb.T.dot(W.dot(Kb))+lbd*n*K0)\n",
    "        B=Kb.T.dot(W.dot(y_train),assume_a=\"sym\")\n",
    "        alpha=solve(A,B)\n",
    "        return alpha\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de l'estimateur compatible avec l'Api de scikit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelRR(BaseEstimator,ClassifierMixin):\n",
    "    def __init__(self,lbd=1,weight=False,gamma=\"auto\",degree=2,c0=1,k=3,biais=False,kernel=\"rbf\"):\n",
    "        self.lbd=lbd\n",
    "        self.weight=weight\n",
    "        self.gamma=gamma\n",
    "        self.degree=degree\n",
    "        self.c0=c0\n",
    "        self.k=k\n",
    "        self.biais=biais\n",
    "        self.kernel=kernel\n",
    "    def fit(self,X,y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.Xtr=X\n",
    "        if isinstance(self.gamma,str) and self.kernel==\"rbf\":\n",
    "            self.gamma=1/self.Xtr.shape[1]\n",
    "        self.alpha=Kernel_Ridge_Regression(X,y,self.lbd,self.weight,self.gamma,self.degree,self.c0,self.k,self.biais,self.kernel)\n",
    "        return self\n",
    "    def decision_function(self,X):\n",
    "        if self.kernel==\"precomputed\":\n",
    "            return X.dot(self.alpha)\n",
    "        if not(self.biais):\n",
    "            if self.kernel==\"rbf\":\n",
    "                return K_rbf_kernel(X,self.Xtr,self.gamma).dot(self.alpha) \n",
    "            elif self.kernel==\"poly\":\n",
    "                return poly_kernel(X,self.Xtr,self.degree,self.c0).dot(self.alpha) \n",
    "            elif self.kernel==\"spectrum\":\n",
    "                return K_spectrum_kernel(X,self.Xtr,self.k).dot(self.alpha) \n",
    "        else:\n",
    "            if self.kernel==\"rbf\":\n",
    "                return addbiais(K_rbf_kernel(X,self.Xtr,self.gamma)).dot(self.alpha)\n",
    "            elif self.kernel==\"poly\":\n",
    "                return addbiais(poly_kernel(X,self.Xtr,self.degree,self.c0)).dot(self.alpha)\n",
    "            elif self.kernel==\"spectrum\":\n",
    "                return addbiais(K_spectrum_kernel(X,self.Xtr,self.k)).dot(self.alpha)\n",
    "\n",
    "    def predict(self,X,y=None):\n",
    "        scores=self.decision_function(X)\n",
    "        if len(scores.shape) == 1:\n",
    "            indices = (scores > 0).astype(np.int)\n",
    "        else:\n",
    "            indices = scores.argmax(axis=1)\n",
    "        return self.classes_[indices]\n",
    "   \n",
    "    def get_params(self, deep=True):\n",
    "    \n",
    "        return {\"lbd\": self.lbd,\"weight\":self.weight,\"gamma\":self.gamma,\"degree\":self.degree,\"c0\":self.c0,\"k\":self.k,\n",
    "                \"biais\":self.biais,\"kernel\":self.kernel}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche des hyperparamètres pour KRR avec noyau gaussien \n",
    "Pour la transformation des données ici vu qu'on va ensuite appliqué un kernel qui va rédéfinir les distance entre le points la seul transformation qui à un sens est celle où l'on standardise les données car elle conserve les rapports de distance(et donc pas affecté le kernel). De plus point très important, le paramètre *gamma* du noyau et *lambda* de la régularisation peuvent ne pas jouer de pair dans la performance de l'estimateur, il est donc difficile d'optimiser à la fois *lambda* et *gamma*. Effectivement il est possible que pour un *gamma* haut on ait besoin d'un *lambda* bas pour performer et inversement et comme on ne veut pas se perdre dans différents chemins, il semble logique de fixer *gamma* puis d'optimer *lambda*. Cela tombe bien puisque sans rentrer dans les détails mais lorsque que les données sont standardisées un paramètre de *gamma* naturel est 1/(num_features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('standardscaler', StandardScaler()), ('kernelrr', KernelRR())])\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    7.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    4.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    5.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                                       ('kernelrr', KernelRR())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'kernelrr__lbd': [1e-06, 1e-05, 0.0001, 0.001, 0.01,\n",
       "                                           0.1, 1, 10]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KRR=make_pipeline(StandardScaler(),KernelRR(kernel=\"rbf\"))\n",
    "print(KRR)\n",
    "\n",
    "hps0={'kernelrr__lbd':[10**-6,10**-5,10**-4,10**-3,10**-2,10**-1,1,10]}\n",
    "searchKRR0= GridSearchCV(KRR,hps0,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKRR0.fit(X_0train, Y_0train)\n",
    "\n",
    "hps1={\"kernelrr__lbd\":[10**-6,10**-5,10**-4,10**-3,10**-2,10**-1,1,10]}\n",
    "searchKRR1= GridSearchCV(KRR,hps1,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKRR1.fit(X_1train, Y_1train)\n",
    "\n",
    "\n",
    "hps2={\"kernelrr__lbd\":[10**-6,10**-5,10**-4,10**-3,10**-2,10**-1,1,10]}\n",
    "searchKRR2= GridSearchCV(KRR,hps2,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKRR2.fit(X_2train, Y_2train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Présentation des Résultats \n",
    "On remarque pour le training set 1 on a 10% en plus 20% en plus!!! pour le training set 2 et rien ne change pour le training set 0 par rapport au modèle linéraire. A Approfondir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'présentation_résultat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-324f44fbc78e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprésentation_résultat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearchKRR0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'présentation_résultat' is not defined"
     ]
    }
   ],
   "source": [
    "présentation_résultat(searchKRR0,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKRR1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKRR2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KRR=make_pipeline(StandardScaler(),KernelRR(weight=False,gamma=\"auto\",kernel=\"rbf\"))\n",
    "print(KRR)\n",
    "\n",
    "hps0={\"kernelrr__lbd\":uniform(loc=10**-4,scale=5*10**-2)}\n",
    "searchKRR0= RandomizedSearchCV(KRR,hps0,n_iter=500,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKRR0.fit(X_0train, Y_0train)\n",
    "\n",
    "hps1={\"kernelrr__lbd\":uniform(loc=5*10**-5,scale=5*10**-2)}\n",
    "searchKRR1=RandomizedSearchCV(KRR,hps1,n_iter=500,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKRR1.fit(X_1train, Y_1train)\n",
    "\n",
    "\n",
    "hps2={\"kernelrr__lbd\":uniform(loc=5*10**-5,scale=5*10**-2)}\n",
    "searchKRR2= RandomizedSearchCV(KRR,hps2,n_iter=100,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKRR2.fit(X_2train, Y_2train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Présentation des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKRR0,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKRR1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKRR2,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(v):\n",
    "    return 1/(1+np.exp(-v))\n",
    "def log_loss(v):\n",
    "    return np.log(1+np.exp(-v))\n",
    "def cross_loss(y,v):\n",
    "    return -(y*np.log(v)+(1-y)*np.log(1-v))\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solver Kernel Logistic Regression \n",
    "\n",
    "Le critère d'arrêt que j'ai mis c'est quand la différence deux itétéres consécutifs a une norme inférieure à $\\epsilon$. Ici aussi je laisse la possibilité d'un biais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IRLS(X_train,y_train,lbd,ga,degree,c0,k,bs,ker,n_iter,eps=10**-6,method='slow'):\n",
    "    n=y_train.shape[0]\n",
    "  \n",
    "    if ker==\"rbf\":\n",
    "        K=rbf_kernel(X_train,ga)\n",
    "    elif ker==\"poly\":\n",
    "        K=poly_kernel(X_train,X_train,degree,c0)\n",
    "    elif ker==\"spectrum\":\n",
    "        K=spectrum_kernel(X_train,k)\n",
    "    elif ker==\"precomputed\":\n",
    "        K=X_train\n",
    "    #alpha=Kernel_Ridge_Regression(K,y_train,lbd,False,1,bs,\"precomputed\")\n",
    "    #alpha=np.zeros(n)\n",
    "    #l=[]\n",
    "  \n",
    "    if bs :\n",
    "        Kb=addbiais(K)\n",
    "        K0=addzeros(K)\n",
    "        alpha=np.zeros(n+1)\n",
    "    else:\n",
    "        alpha=np.zeros(n)\n",
    "    for i in range(n_iter):\n",
    "   \n",
    "        alpha_old=alpha\n",
    "       \n",
    "        if bs:\n",
    "            m=Kb.dot(alpha)\n",
    "            #l.append(log_loss(y_train*m).mean()+lbd*alpha[:-1].dot(K.dot(alpha[:-1])))\n",
    "        \n",
    "        else:\n",
    "            m=K.dot(alpha)\n",
    "            #l.append(log_loss(y_train*m).mean()+lbd*alpha.dot(m))\n",
    "        \n",
    "        \n",
    "        p=sigmoid(m)\n",
    "       \n",
    "        weight=p*(1-p)\n",
    "       \n",
    "        weight=np.where(weight<0.000001,0.000001,weight)\n",
    "       \n",
    "   \n",
    "        u=np.where(sigmoid(y_train*m)<0.000001,0.000001,sigmoid(y_train*m))\n",
    "        z = m + y_train/u\n",
    "    \n",
    "        if not(bs):\n",
    "        \n",
    "            S = np.diag(weight**-1)\n",
    "            A=(K+2*lbd*n*S)\n",
    "            alpha=solve(A,z,assume_a=\"sym\")\n",
    "            \n",
    "            #print(np.linalg.norm(alpha_old-alpha))\n",
    "            \n",
    "            if np.linalg.norm(alpha_old-alpha)<eps:\n",
    "                break\n",
    "        else:\n",
    "            S = np.diag(weight)\n",
    "            A=(Kb.T.dot(S.dot(Kb))+2*lbd*n*K0)\n",
    "            B=Kb.T.dot(S.dot(z))\n",
    "            if method==\"slow\":\n",
    "                alpha=lstsq(A,B)[0]\n",
    "            else:\n",
    "                alpha=solve(A,B,assume_a=\"sym\")\n",
    "            #print(np.linalg.norm(alpha_old-alpha))\n",
    "            if np.linalg.norm(alpha_old-alpha)<eps:\n",
    "                break\n",
    "                \n",
    "       \n",
    "    return alpha #,l\n",
    "        \n",
    "#with np.printoptions(threshold=np.inf):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Je construit l'estimateur compatible avec l'API de scikit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelLR(BaseEstimator,ClassifierMixin):\n",
    "    def __init__(self,lbd=1,gamma='auto',degree=2,c0=1,k=3,biais=False,kernel=\"rbf\",n_iter=15,method=\"slow\"):\n",
    "        self.lbd=lbd\n",
    "        self.gamma=gamma\n",
    "        self.degree=degree\n",
    "        self.c0=c0\n",
    "        self.k=k\n",
    "        self.biais=biais\n",
    "        self.kernel=kernel\n",
    "        self.n_iter=n_iter\n",
    "        self.method=method\n",
    "    def fit(self,X,y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.Xtr=X\n",
    "        if isinstance(self.gamma,str) and self.kernel==\"rbf\":\n",
    "            self.gamma=1/self.Xtr.shape[1]\n",
    "        self.alpha=IRLS(X,y,self.lbd,self.gamma,self.degree,self.c0,self.k,self.biais,self.kernel,self.n_iter,method=self.method)\n",
    "        return self\n",
    "    def decision_function(self,X):\n",
    "        if not(self.biais):\n",
    "            if self.kernel==\"precomputed\":\n",
    "                return X.dot(self.alpha)\n",
    "            if self.kernel==\"rbf\":\n",
    "                return K_rbf_kernel(X,self.Xtr,self.gamma).dot(self.alpha) \n",
    "            elif self.kernel==\"poly\":\n",
    "                return poly_kernel(X,self.Xtr,self.degree,self.c0).dot(self.alpha) \n",
    "            elif self.kernel==\"spectrum\":\n",
    "                return K_spectrum_kernel(X,self.Xtr,self.k).dot(self.alpha) \n",
    "        else:\n",
    "            if self.kernel==\"rbf\":\n",
    "                return addbiais(K_rbf_kernel(X,self.Xtr,self.gamma)).dot(self.alpha)\n",
    "            elif self.kernel==\"poly\":\n",
    "                return addbiais(poly_kernel(X,self.Xtr,self.degree,self.c0)).dot(self.alpha)\n",
    "            elif self.kernel==\"spectrum\":\n",
    "                return addbiais(K_spectrum_kernel(X,self.Xtr,self.k)).dot(self.alpha)\n",
    "        \n",
    "\n",
    "    def predict(self,X,y=None):\n",
    "        scores=self.decision_function(X)\n",
    "        if len(scores.shape) == 1:\n",
    "            indices = (scores > 0).astype(np.int)\n",
    "        else:\n",
    "            indices = scores.argmax(axis=1)\n",
    "        return self.classes_[indices]\n",
    "    def predict_proba_(self,X,y=None):\n",
    "        p=sigmoid(self.decision_function(X)).reshape(-1,1)\n",
    "        return hstack((p,1-p))\n",
    "    def get_params(self, deep=True):\n",
    "    \n",
    "        return {\"lbd\": self.lbd,\"gamma\":self.gamma,\"degree\":self.degree,\"c0\":self.c0,\"k\":self.k,\"biais\":self.biais,\n",
    "                \"kernel\":self.kernel,\"n_iter\":self.n_iter,\"method\":self.method}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche des Hyperparamètres "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KLR=make_pipeline(StandardScaler(),KernelLR())\n",
    "print(KLR)\n",
    "\n",
    "hps0={'kernellr__lbd':[10**-6,10**-5,10**-4,10**-3,10**-2,10**-1,1,10]}\n",
    "searchKLR0= GridSearchCV(KLR,hps0,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKLR0.fit(X_0train, Y_0train)\n",
    "\n",
    "hps1={'kernellr__lbd':[10**-6,10**-5,10**-4,10**-3,10**-2,10**-1,1,10]}\n",
    "searchKLR1= GridSearchCV(KLR,hps1,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKLR1.fit(X_1train, Y_1train)\n",
    "\n",
    "\n",
    "hps2={'kernellr__lbd':[10**-6,10**-5,10**-4,10**-3,10**-2,10**-1,1,10]}\n",
    "searchKLR2= GridSearchCV(KLR,hps2,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKLR2.fit(X_2train, Y_2train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Présentation des résultats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKLR0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKLR1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKLR2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps0={\"kernellr__lbd\":uniform(loc=5*10**-6,scale=5*10**-3)}\n",
    "searchKLR0= RandomizedSearchCV(KLR,hps0,n_iter=500,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKLR0.fit(X_0train, Y_0train)\n",
    "\n",
    "hps1={\"kernellr__lbd\":uniform(loc=5*10**-7,scale=5*10**-3)}\n",
    "searchKLR1=RandomizedSearchCV(KLR,hps1,n_iter=500,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKLR1.fit(X_1train, Y_1train)\n",
    "\n",
    "\n",
    "hps2={\"kernellr__lbd\":uniform(loc=5*10**-7,scale=5*10**-3)}\n",
    "searchKLR2= RandomizedSearchCV(KLR,hps2,n_iter=500,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKLR2.fit(X_2train, Y_2train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKLR0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKLR1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKLR2,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM \n",
    "J'utilise cvxopt pour résoudre le QP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(X_train,y_train,C,gamma,degree,c0,k,kernel):\n",
    "    n=y_train.shape[0]\n",
    "    if kernel==\"rbf\":\n",
    "        K=rbf_kernel(X_train,gamma)\n",
    "    elif kernel==\"poly\":\n",
    "        K=poly_kernel(X_train,X_train,degree,c0)\n",
    "    elif kernel==\"spectrum\":\n",
    "        K=spectrum_kernel(X_train,k)\n",
    "    elif kernel==\"precomputed\":\n",
    "        K=X_train\n",
    "    P=matrix(K,tc='d')\n",
    "    q=matrix(-y_train,tc='d')\n",
    "    g1=np.diag(y_train)\n",
    "    G=matrix(np.vstack((g1,-g1)),tc='d')\n",
    "    h=matrix(np.hstack((np.repeat(C,n),np.zeros(n))),tc='d')\n",
    "    solvers.options['show_progress'] = False\n",
    "    sol=solvers.qp(P,q,G,h)\n",
    "    return np.array(sol['x']).reshape(-1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de l'estimateur compatible avec l'API de scikit \n",
    "\n",
    "Si vous remarquez bien j'utilise tout alpha pour définir ma fonction f(x) alors que je pourrai garder seulement les alpha_i telle que alpha_i plus grand > threshold (car le solver nous fera jamais arrivé exatement à zéro quand alpha_i doit être égale à zéro) car comme on le sait une solution optimale de SVM est un vecteur sparse. Je ne l'ai pas fait car j'ai eu du mal à définir le threshold, on trouve une trace de ma tentative dans le code de l'estimateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelSVM(BaseEstimator,ClassifierMixin):\n",
    "    def __init__(self,C=1,gamma='auto',degree=\"2\",c0=1,k=3,kernel=\"rbf\"):\n",
    "        self.C=C\n",
    "        self.gamma=gamma\n",
    "        self.degree=degree\n",
    "        self.c0=c0\n",
    "        self.k=k\n",
    "        self.kernel=kernel\n",
    "    def fit(self,X,y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.Xtr=X\n",
    "        if isinstance(self.gamma,str) and self.kernel==\"rbf\":\n",
    "            self.gamma=1/self.Xtr.shape[1]\n",
    "        self.alpha=SVM(X,y,self.C,self.gamma,self.degree,self.c0,self.k,self.kernel)\n",
    "        #idx=self.alpha>10**-5\n",
    "        #self.Xtr=self.Xtr[idx]\n",
    "        #self.alpha=self.alpha[idx]\n",
    "        return self\n",
    "    def decision_function(self,X):\n",
    "        if self.kernel==\"precomputed\":\n",
    "            return X.dot(self.alpha)\n",
    "        elif self.kernel==\"rbf\":\n",
    "            return K_rbf_kernel(X,self.Xtr,self.gamma).dot(self.alpha) \n",
    "        elif self.kernel==\"poly\":\n",
    "            return poly_kernel(X,self.Xtr,self.degree,self.c0).dot(self.alpha) \n",
    "        elif self.kernel==\"spectrum\":\n",
    "            return K_spectrum_kernel(X,self.Xtr,self.k).dot(self.alpha) \n",
    "            \n",
    "           \n",
    "    def predict(self,X,y=None):\n",
    "        scores=self.decision_function(X)\n",
    "        if len(scores.shape) == 1:\n",
    "            indices = (scores > 0).astype(np.int)\n",
    "        else:\n",
    "            indices = scores.argmax(axis=1)\n",
    "        return self.classes_[indices]\n",
    "    def get_params(self, deep=True):\n",
    "    \n",
    "        return {\"C\": self.C,\"gamma\":self.gamma,\"degree\":self.degree,\"c0\":self.c0,\"k\":self.k,\"kernel\":self.kernel}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KSVM=make_pipeline(StandardScaler(),KernelSVM())\n",
    "print(KSVM)\n",
    "\n",
    "hps0={'kernelsvm__C':[10**-2,10**-1,1,10,50,100,500,1000]}\n",
    "searchKSVM0= GridSearchCV(KSVM,hps0,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKSVM0.fit(X_0train, Y_0train)\n",
    "\n",
    "hps1={'kernelsvm__C':[10**-2,10**-1,1,10,50,100,500,1000]}\n",
    "searchKSVM1= GridSearchCV(KSVM,hps1,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKSVM1.fit(X_1train, Y_1train)\n",
    "\n",
    "\n",
    "hps2={'kernelsvm__C':[10**-2,10**-1,1,10,50,100,500,1000]}\n",
    "searchKSVM2= GridSearchCV(KSVM,hps2,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKSVM2.fit(X_2train, Y_2train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKSVM0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKSVM1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKSVM2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hps0={\"kernelsvm__C\":uniform(loc=0.5,scale=5)}\n",
    "searchKSVM0= RandomizedSearchCV(KSVM,hps0,n_iter=100,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKSVM0.fit(X_0train, Y_0train)\n",
    "\n",
    "hps1={\"kernelsvm__C\":uniform(loc=0.5,scale=5)}\n",
    "searchKSVM1= RandomizedSearchCV(KSVM,hps1,n_iter=100,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKSVM1.fit(X_1train, Y_1train)\n",
    "\n",
    "hps2={\"kernelsvm__C\":uniform(loc=0.1,scale=3)}\n",
    "searchKSVM2= RandomizedSearchCV(KSVM,hps2,n_iter=100,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKSVM2.fit(X_2train, Y_2train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKSVM0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKSVM1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKSVM2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KLR0=make_pipeline(StandardScaler(),KernelLR(lbd=0.00018))\n",
    "KLR1=make_pipeline(StandardScaler(),KernelLR(lbd=0.00016))\n",
    "KLR2=make_pipeline(StandardScaler(),KernelLR(lbd=5.89*(10**-5)))\n",
    "\n",
    "X_0test=pd.read_csv(\"Data/Xte0_mat100.csv\",sep=' ',header=None).to_numpy()\n",
    "X_1test=pd.read_csv(\"Data/Xte1_mat100.csv\",sep=' ',header=None).to_numpy()\n",
    "X_2test=pd.read_csv(\"Data/Xte2_mat100.csv\",sep=' ',header=None).to_numpy()\n",
    "\n",
    "\n",
    "print(X_1train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_file(models): #models is a list of 3 models\n",
    "    Y_test=np.empty(0)\n",
    "    for X_train, Y_train, X_test, model  in zip([X_0train,X_1train,X_2train], [Y_0train,Y_1train,Y_2train], [X_0test,X_1test,X_2test], models):\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred=model.predict(X_test)\n",
    "        Y_test=np.concatenate((Y_test,np.where(Y_pred==-1,0,Y_pred)), axis=0)\n",
    "    \n",
    "    Y_test=Y_test.reshape(len(Y_test),1)\n",
    "    with np.printoptions(threshold=np.inf):\n",
    "        print(Y_test.shape)\n",
    "    ids=np.arange(Y_test.shape[0])\n",
    "    ids=ids.reshape(len(ids),1)\n",
    "    \n",
    "    df=pd.DataFrame(data=np.concatenate((ids,Y_test), axis=1), columns=['Id','Bound'],dtype=np.int)\n",
    "    \n",
    "    return df.to_csv('kernel_spectrum_try2.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file([KLR0,KLR1,KLR2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String kernel \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "from tqdm import tqdm\n",
    "from scipy.stats import rankdata\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0train=pd.read_csv('Data/Xtr0.csv', sep=',')['seq']\n",
    "X_1train=pd.read_csv('Data/Xtr1.csv', sep=',')['seq']\n",
    "X_2train=pd.read_csv('Data/Xtr2.csv', sep=',')['seq']\n",
    "\n",
    "X_0test=pd.read_csv('Data/Xte0.csv', sep=',')['seq']\n",
    "X_1test=pd.read_csv('Data/Xte1.csv', sep=',')['seq']\n",
    "X_2test=pd.read_csv('Data/Xte2.csv', sep=',')['seq']\n",
    "\n",
    "Y_0=pd.read_csv(\"Data/Ytr0.csv\",sep=',')\n",
    "Y_1=pd.read_csv(\"Data/Ytr1.csv\",sep=',')\n",
    "Y_2=pd.read_csv(\"Data/Ytr2.csv\",sep=',')\n",
    "\n",
    "Y_0train=np.where(Y_0[\"Bound\"]==0,-1,Y_0[\"Bound\"])\n",
    "Y_1train=np.where(Y_1[\"Bound\"]==0,-1,Y_1[\"Bound\"])\n",
    "Y_2train=np.where(Y_2[\"Bound\"]==0,-1,Y_2[\"Bound\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_spectrum_kernel(X,Y,k,alphabet=\"ACGT\"):\n",
    "    voc=product(alphabet, repeat=k)\n",
    "    voc=[''.join(elt) for elt in voc]\n",
    "    phi_X=np.vstack(X.apply(lambda x: [x[i:i+k] for i in range(0, len(x)-k+1)]).apply(lambda x: np.array([x.count(v) for v in voc])).to_numpy())\n",
    "    phi_Y=np.vstack(Y.apply(lambda x: [x[i:i+k] for i in range(0, len(x)-k+1)]).apply(lambda x: np.array([x.count(v) for v in voc])).to_numpy())\n",
    "    return phi_X.dot(phi_Y.T)\n",
    "def spectrum_kernel(X,k,alphabet=\"ACGT\"):\n",
    "    voc=product(alphabet, repeat=k)\n",
    "    voc=[''.join(elt) for elt in voc]\n",
    "    phi_X=np.vstack(X.apply(lambda x: [x[i:i+k] for i in range(0, len(x)-k+1)]).apply(lambda x: np.array([x.count(v) for v in voc])).to_numpy())\n",
    "   \n",
    "    return phi_X.dot(phi_X.T)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65536/65536 [00:00<00:00, 135031.15it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 107649.95it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 116545.49it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 135838.71it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 131883.68it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 129471.60it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 135528.48it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 133382.91it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 133276.79it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 133025.56it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 134912.32it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 138630.69it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 135062.93it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 131023.33it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 131368.73it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 127028.35it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 128435.74it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 124192.07it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 122659.69it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 104611.70it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 119093.86it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 115260.43it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 125449.90it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 127642.75it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 133393.07it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 136621.55it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 132593.78it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 134230.84it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 126261.64it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 116494.42it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 124368.28it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 131373.44it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 121286.56it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 127832.53it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 128010.29it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 130656.14it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 134425.93it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 127073.33it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 124518.65it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 114132.85it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 124650.05it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 122874.95it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 125629.35it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 116627.63it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 103392.95it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 119854.08it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 124607.72it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 128176.77it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 133594.76it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 127814.58it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 119877.66it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 125812.09it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 112619.99it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 120401.17it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 111373.85it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 130103.34it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 125222.61it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 130693.04it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 123591.57it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 118245.16it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 127001.70it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 127752.68it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 124380.38it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 132481.18it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 121690.01it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 126206.11it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 129910.45it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 131152.99it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 134833.96it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 132485.84it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 132616.36it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 120484.28it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 121777.89it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 93472.80it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 91264.89it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 106023.01it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 127450.53it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 129648.99it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 125650.60it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 97460.47it/s] \n",
      "100%|██████████| 65536/65536 [00:00<00:00, 92404.73it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 122139.30it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 119456.30it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 119688.80it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 117672.50it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 111054.65it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 128240.34it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 123469.44it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 130859.41it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 132776.19it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 129800.03it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 124583.10it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 131446.69it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 117740.25it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 124561.59it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 121667.61it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 129679.88it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 133582.10it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 123413.50it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 119626.04it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 111890.27it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 116223.17it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 120687.53it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 106396.17it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 120355.93it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 122477.85it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 111146.30it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 110951.28it/s]\n",
      " 79%|███████▉  | 51794/65536 [00:00<00:00, 121908.90it/s]"
     ]
    }
   ],
   "source": [
    "print(spectrum_kernel(X_0train,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1/7 [00:00<00:00,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KernelSVM(kernel='precomputed')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [06:14<00:00, 53.51s/it] \n",
      "56it [13:11, 14.13s/it]\n",
      "100%|██████████| 7/7 [06:13<00:00, 53.42s/it] \n",
      "56it [35:18, 37.83s/it]\n",
      "100%|██████████| 7/7 [06:59<00:00, 59.88s/it] \n",
      "56it [15:13, 16.31s/it]\n"
     ]
    }
   ],
   "source": [
    "KSVM=KernelSVM(kernel=\"precomputed\")\n",
    "print(KSVM)\n",
    "\n",
    "hps0={'C':[10**-2,10**-1,1,10,50,100,500,1000],'k':[2,3,4,5,6,7,8]}\n",
    "searchKSVM0= Cross_val_spectrum(X_0train,Y_0train,KSVM,hps0)\n",
    "\n",
    "\n",
    "hps1={'C':[10**-2,10**-1,1,10,50,100,500,1000],'k':[2,3,4,5,6,7,8]}\n",
    "searchKSVM1= Cross_val_spectrum(X_1train,Y_1train,KSVM,hps1)\n",
    "\n",
    "\n",
    "\n",
    "hps2={'C':[10**-2,10**-1,1,10,50,100,500,1000],'k':[2,3,4,5,6,7,8]}\n",
    "searchKSVM2= Cross_val_spectrum(X_2train,Y_2train,KSVM,hps2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>k</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.01</td>\n",
       "      <td>6</td>\n",
       "      <td>0.6380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>500</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       C  k  mean_test_score\n",
       "0   0.01  8           0.6455\n",
       "1   0.01  7           0.6450\n",
       "2    0.1  8           0.6405\n",
       "3      1  8           0.6405\n",
       "4     10  8           0.6405\n",
       "5     50  8           0.6405\n",
       "6    100  8           0.6405\n",
       "7    500  8           0.6405\n",
       "8   1000  8           0.6405\n",
       "9   0.01  6           0.6380\n",
       "10   0.1  7           0.6275\n",
       "11     1  7           0.6275\n",
       "12    10  7           0.6275\n",
       "13    50  7           0.6275\n",
       "14   100  7           0.6275\n",
       "15   500  7           0.6275\n",
       "16  1000  7           0.6275\n",
       "17  0.01  5           0.6195\n",
       "18  0.01  4           0.6065\n",
       "19   0.1  4           0.6010\n",
       "20     1  4           0.5985\n",
       "21   0.1  5           0.5975\n",
       "22   0.1  6           0.5940\n",
       "23  1000  4           0.5935\n",
       "24   500  4           0.5930\n",
       "25    10  4           0.5925\n",
       "26   100  4           0.5925"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "présentation_résultat2(searchKSVM0,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>k</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>6</td>\n",
       "      <td>0.6380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>500</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.01</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       C  k  mean_test_score\n",
       "0   0.01  5           0.6435\n",
       "1   0.01  6           0.6380\n",
       "2   0.01  7           0.6295\n",
       "3    0.1  7           0.6200\n",
       "4      1  7           0.6200\n",
       "5     10  7           0.6200\n",
       "6     50  7           0.6200\n",
       "7    100  7           0.6200\n",
       "8    500  7           0.6200\n",
       "9   1000  7           0.6200\n",
       "10  0.01  8           0.6185\n",
       "11   0.1  5           0.6150\n",
       "12   0.1  4           0.6135\n",
       "13   0.1  8           0.6130\n",
       "14     1  8           0.6130\n",
       "15    10  8           0.6130\n",
       "16    50  8           0.6130\n",
       "17   100  8           0.6130\n",
       "18   500  8           0.6130\n",
       "19  1000  8           0.6130"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "présentation_résultat2(searchKSVM1,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>k</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>500</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.01</td>\n",
       "      <td>6</td>\n",
       "      <td>0.7290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.01</td>\n",
       "      <td>8</td>\n",
       "      <td>0.7275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.7255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.7245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.7245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>0.7245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>0.7245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>0.7245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.7245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       C  k  mean_test_score\n",
       "0   0.01  7           0.7415\n",
       "1    0.1  7           0.7335\n",
       "2      1  7           0.7310\n",
       "3     10  7           0.7310\n",
       "4     50  7           0.7310\n",
       "5    100  7           0.7310\n",
       "6    500  7           0.7310\n",
       "7   1000  7           0.7310\n",
       "8   0.01  6           0.7290\n",
       "9   0.01  8           0.7275\n",
       "10   0.1  8           0.7255\n",
       "11     1  8           0.7245\n",
       "12    10  8           0.7245\n",
       "13    50  8           0.7245\n",
       "14   100  8           0.7245\n",
       "15   500  8           0.7245\n",
       "16  1000  8           0.7245"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "présentation_résultat2(searchKSVM2,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [06:23<00:00, 383.41s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': array([0.46666505, 0.26907594, 0.12523631, 0.45466107, 0.26347195,\n",
      "       0.19420895, 0.18226131, 0.49544762, 0.01318606, 0.41101619,\n",
      "       0.45164923, 0.24666404, 0.05044877, 0.3151696 , 0.05091285,\n",
      "       0.42096472, 0.11227579, 0.2445298 , 0.30944494, 0.40553232,\n",
      "       0.49069645, 0.41870792, 0.4170422 , 0.41755719, 0.4080609 ,\n",
      "       0.05694352, 0.21573527, 0.01444699, 0.3645368 , 0.22691003,\n",
      "       0.21797331, 0.07831073, 0.01927725, 0.21226899, 0.43667885,\n",
      "       0.02985245, 0.0565717 , 0.19886476, 0.11112374, 0.30510266,\n",
      "       0.08007239, 0.47218621, 0.35868019, 0.24887759, 0.29805176,\n",
      "       0.25165495, 0.39362325, 0.45773882, 0.07267951, 0.05861149]), 'k': array([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "       8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "       8, 8, 8, 8, 8, 8])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [09:22, 11.24s/it]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.15s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': array([0.43176172, 0.26195195, 0.24518519, 0.41727215, 0.09133693,\n",
      "       0.34584573, 0.4296129 , 0.27213185, 0.4455721 , 0.34425933,\n",
      "       0.12402668, 0.38649431, 0.04172012, 0.40968717, 0.14548111,\n",
      "       0.08202455, 0.48124638, 0.17726664, 0.41057927, 0.1769999 ,\n",
      "       0.34431211, 0.04408077, 0.20784162, 0.39786877, 0.48186417,\n",
      "       0.38823755, 0.42120227, 0.47118595, 0.06240904, 0.23616567,\n",
      "       0.18784333, 0.23993454, 0.12151771, 0.49477509, 0.18250762,\n",
      "       0.28094271, 0.20887174, 0.24207455, 0.40490859, 0.08339908,\n",
      "       0.12515863, 0.06248199, 0.24669478, 0.26764686, 0.07934126,\n",
      "       0.16136374, 0.1944452 , 0.30599783, 0.19357854, 0.08016435]), 'k': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [10:43, 12.88s/it]\n",
      "100%|██████████| 1/1 [01:19<00:00, 79.43s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': array([0.24811796, 0.19046197, 0.02332814, 0.37084938, 0.28486939,\n",
      "       0.43829491, 0.26565659, 0.17937156, 0.06996736, 0.3658085 ,\n",
      "       0.28177865, 0.06674257, 0.28349039, 0.25354877, 0.400276  ,\n",
      "       0.49915773, 0.46203365, 0.43082258, 0.01423607, 0.42812112,\n",
      "       0.4607758 , 0.38853215, 0.40922324, 0.25191396, 0.3117775 ,\n",
      "       0.31132515, 0.39262195, 0.23339819, 0.3925347 , 0.1423535 ,\n",
      "       0.1797383 , 0.40227858, 0.41858376, 0.05750593, 0.05113303,\n",
      "       0.06096535, 0.29375129, 0.09998449, 0.32552638, 0.15315188,\n",
      "       0.24206569, 0.41775379, 0.47600435, 0.43112248, 0.17612762,\n",
      "       0.25724631, 0.27676258, 0.0929287 , 0.11508991, 0.18911116]), 'k': array([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "       7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "       7, 7, 7, 7, 7, 7])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [18:04, 21.69s/it]\n"
     ]
    }
   ],
   "source": [
    "hps0={'C':uniform(loc=0.005,scale=0.5),'k':[8]}\n",
    "searchKSVM0= Randomized_Cross_val_spectrum(X_0train,Y_0train,KSVM,hps0,50)\n",
    "\n",
    "\n",
    "hps1={'C':uniform(loc=0.005,scale=0.5),'k':[5]}\n",
    "searchKSVM1= Randomized_Cross_val_spectrum(X_1train,Y_1train,KSVM,hps1,50)\n",
    "\n",
    "\n",
    "\n",
    "hps2={'C':uniform(loc=0.005,scale=0.5),'k':[7]}\n",
    "searchKSVM2= Randomized_Cross_val_spectrum(X_2train,Y_2train,KSVM,hps2,50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>k</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.050448771307686095</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05091285130337835</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02985245022581617</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013186059645409972</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0569435202737617</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.014446992786455778</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.056571703359897856</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.05861148630114598</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      C  k  mean_test_score\n",
       "0  0.050448771307686095  8           0.6435\n",
       "1   0.05091285130337835  8           0.6430\n",
       "2   0.02985245022581617  8           0.6425\n",
       "3  0.013186059645409972  8           0.6410\n",
       "4    0.0569435202737617  8           0.6410\n",
       "5  0.014446992786455778  8           0.6410\n",
       "6  0.056571703359897856  8           0.6410\n",
       "7   0.05861148630114598  8           0.6410"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "présentation_résultat2(searchKSVM0,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>k</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.041720115086265545</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0440807747696007</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06240904239977856</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.062481994426005764</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.08202455387710322</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.12151770942350837</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.1613637411943103</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.17726663919630986</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.17699989754103973</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.08339908141150759</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.07934125740530562</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.12402667995983607</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.1251586261274244</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0913369304907905</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.1878433347372781</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.18250761986329783</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.08016434918431636</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.14548110968980926</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.19444520101531393</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.19357854405159058</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       C  k  mean_test_score\n",
       "0   0.041720115086265545  5           0.6240\n",
       "1     0.0440807747696007  5           0.6235\n",
       "2    0.06240904239977856  5           0.6205\n",
       "3   0.062481994426005764  5           0.6200\n",
       "4    0.08202455387710322  5           0.6155\n",
       "5    0.12151770942350837  5           0.6155\n",
       "6     0.1613637411943103  5           0.6145\n",
       "7    0.17726663919630986  5           0.6145\n",
       "8    0.17699989754103973  5           0.6145\n",
       "9    0.08339908141150759  5           0.6145\n",
       "10   0.07934125740530562  5           0.6145\n",
       "11   0.12402667995983607  5           0.6140\n",
       "12    0.1251586261274244  5           0.6140\n",
       "13    0.0913369304907905  5           0.6135\n",
       "14    0.1878433347372781  5           0.6135\n",
       "15   0.18250761986329783  5           0.6130\n",
       "16   0.08016434918431636  5           0.6130\n",
       "17   0.14548110968980926  5           0.6115\n",
       "18   0.19444520101531393  5           0.6110\n",
       "19   0.19357854405159058  5           0.6110"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "présentation_résultat2(searchKSVM1,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>k</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014236067163357343</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02332813750240192</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0699673590736214</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.06096535102182892</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05113303466458518</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.06674257022952479</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.057505934607167124</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0999844942020891</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.09292869707770801</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.1150899081854529</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      C  k  mean_test_score\n",
       "0  0.014236067163357343  7           0.7410\n",
       "1   0.02332813750240192  7           0.7350\n",
       "2    0.0699673590736214  7           0.7345\n",
       "3   0.06096535102182892  7           0.7345\n",
       "4   0.05113303466458518  7           0.7340\n",
       "5   0.06674257022952479  7           0.7340\n",
       "6  0.057505934607167124  7           0.7340\n",
       "7    0.0999844942020891  7           0.7335\n",
       "8   0.09292869707770801  7           0.7330\n",
       "9    0.1150899081854529  7           0.7330"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "présentation_résultat2(searchKSVM2,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0=KernelSVM(C=0.01,k=8,kernel=\"spectrum\")\n",
    "model1=KernelSVM(C=0.01,k=5,kernel=\"spectrum\")\n",
    "model2=KernelSVM(C=0.01,k=7,kernel=\"spectrum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 1)\n"
     ]
    }
   ],
   "source": [
    "csv_file([model0,model1,model2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cross_val_spectrum(X_train,Y_train,model,hps,cv=5):\n",
    "    CV=StratifiedKFold(cv)\n",
    "    dic_K={k:spectrum_kernel(X_train,k) for k in tqdm(hps[\"k\"])}\n",
    "    list_hp=[]\n",
    "    list_val_score=[]\n",
    "    idx_k=list(hps.keys()).index(\"k\")\n",
    "    \n",
    "    for i in tqdm(product(*hps.values())):\n",
    "        \n",
    "        dic_hp={keys:values for keys,values in zip(hps.keys(),i)}\n",
    "        list_hp.append(dic_hp)\n",
    "        \n",
    "        model.set_params(**dic_hp)\n",
    "        acc_mean=0\n",
    "        for train_idx,val_idx in CV.split(X_train,Y_train):\n",
    "            K=dic_K[i[idx_k]]\n",
    "            model.fit(K[train_idx][:,train_idx],Y_train[train_idx])\n",
    "            Y_pred=model.predict(K[val_idx][:,train_idx])\n",
    "            acc_mean+=accuracy_score(Y_train[val_idx],Y_pred)\n",
    "        list_val_score.append(acc_mean/cv)\n",
    "    return {\"params\":list_hp,\"mean_test_score\":np.array(list_val_score),\"rank_test_score\":rankdata(list_val_score)}\n",
    "            \n",
    "            \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Randomized_Cross_val_spectrum(X_train,Y_train,model,hps,n_iter,cv=5):\n",
    "    CV=StratifiedKFold(cv)\n",
    "    dic_K={k:spectrum_kernel(X_train,k) for k in tqdm(hps[\"k\"])}\n",
    "    list_hp=[]\n",
    "    list_val_score=[]\n",
    "    idx_k=list(hps.keys()).index(\"k\")\n",
    "    for keys,values in hps.items():\n",
    "        if isinstance(values,scipy.stats._distn_infrastructure.rv_frozen):\n",
    "            hps[keys]=values.rvs(size=n_iter)\n",
    "        else:\n",
    "            hps[keys]=np.random.choice(values,n_iter)\n",
    "    print(hps)\n",
    "    for i in tqdm(zip(*hps.values())):\n",
    "        \n",
    "        dic_hp={keys:values for keys,values in zip(hps.keys(),i)}\n",
    "        list_hp.append(dic_hp)\n",
    "        \n",
    "        model.set_params(**dic_hp)\n",
    "        acc_mean=0\n",
    "        for train_idx,val_idx in CV.split(X_train,Y_train):\n",
    "            K=dic_K[i[idx_k]]\n",
    "            model.fit(K[train_idx][:,train_idx],Y_train[train_idx])\n",
    "            Y_pred=model.predict(K[val_idx][:,train_idx])\n",
    "            acc_mean+=accuracy_score(Y_train[val_idx],Y_pred)\n",
    "        list_val_score.append(acc_mean/cv)\n",
    "    return {\"params\":list_hp,\"mean_test_score\":np.array(list_val_score),\"rank_test_score\":rankdata(list_val_score)}\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': array([2.29109288, 1.28619423, 0.54370751, 1.51972859, 1.29469697,\n",
      "       1.70426481, 2.27696594, 0.52956819, 1.45780128, 1.24405329]), 'k': array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3])}\n",
      "{'C': 2.2910928819369967, 'k': 3}\n",
      "{'C': 1.2861942342546977, 'k': 3}\n",
      "{'C': 0.5437075121323791, 'k': 3}\n",
      "{'C': 1.5197285935541702, 'k': 3}\n",
      "{'C': 1.2946969722600201, 'k': 3}\n",
      "{'C': 1.7042648064952854, 'k': 3}\n",
      "{'C': 2.276965939325671, 'k': 3}\n",
      "{'C': 0.5295681908427132, 'k': 3}\n",
      "{'C': 1.4578012788210766, 'k': 3}\n",
      "{'C': 1.2440532860608564, 'k': 3}\n"
     ]
    }
   ],
   "source": [
    "hps={'C':uniform(loc=0.5,scale=2),'k':[3]}\n",
    "CV=StratifiedKFold(5)\n",
    "list_hp=[]\n",
    "n_iter=10\n",
    "list_val_score=[]\n",
    "dic_K={k:np.arange(k) for k in hps[\"k\"]}\n",
    "idx_k=list(hps.keys()).index(\"k\")\n",
    "for keys,values in hps.items():\n",
    "    if isinstance(values,scipy.stats._distn_infrastructure.rv_frozen):\n",
    "        hps[keys]=values.rvs(size=n_iter)\n",
    "    else:\n",
    "        hps[keys]=np.random.choice(values,n_iter)\n",
    "print(hps)\n",
    "\n",
    "for i in zip(*hps.values()):\n",
    "    dic_hp={keys:values for keys,values in zip(hps.keys(),i)}\n",
    "    KSVM.set_params(**dic_hp)\n",
    "    print(dic_hp)\n",
    "    for train_idx,test_idx in CV.split(X_0train,Y_0train):\n",
    "        x=5\n",
    "       \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(uniform(loc=0.5,scale=1))\n",
    "isinstance(uniform(loc=0.5,scale=1),scipy.stats._distn_infrastructure.rv_frozen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "{'a': 1, 'b': 2}\n",
      "(1, 3)\n",
      "{'a': 1, 'b': 3}\n",
      "(3, 2)\n",
      "{'a': 3, 'b': 2}\n",
      "(3, 3)\n",
      "{'a': 3, 'b': 3}\n",
      "(4, 2)\n",
      "{'a': 4, 'b': 2}\n",
      "(4, 3)\n",
      "{'a': 4, 'b': 3}\n",
      "(5, 2)\n",
      "{'a': 5, 'b': 2}\n",
      "(5, 3)\n",
      "{'a': 5, 'b': 3}\n"
     ]
    }
   ],
   "source": [
    "for i in product(*dic.values()):\n",
    "    print(i)\n",
    "    dac={keys:values for keys,values in zip(dic.keys(),i)}\n",
    "    print(dac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 3, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 5, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=np.diag(np.arange(10))\n",
    "idx=np.array([1,3,5])\n",
    "A[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def présentation_résultat2(search,n):\n",
    "    mask=search['rank_test_score']<=n\n",
    "    params=list(compress(search['params'], list(mask)))\n",
    "    mean_test_score=search['mean_test_score'][mask]\n",
    "    a={}\n",
    "    for i in range(mean_test_score.size):\n",
    "        k=''\n",
    "        for key, value in params[i].items():\n",
    "            k+=\" \"+key+\" \"+str(value)\n",
    "        a.update({k:mean_test_score[i]})\n",
    "        sortedDict = sorted(a.items(), key=lambda x: x[1],reverse=True)\n",
    "    l=[]\n",
    "    for i in sortedDict:\n",
    "        u=i[0].split(sep=' ')\n",
    "        del(u[0])\n",
    "        lp=[]\n",
    "        for j in u[1::2]:\n",
    "            lp.append(j)\n",
    "        lp.append(i[1])\n",
    "        l.append(lp)\n",
    "    head=list(params[0].keys())+[\"mean_test_score\"]\n",
    "\n",
    "    return(pd.DataFrame(l,columns=head))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
