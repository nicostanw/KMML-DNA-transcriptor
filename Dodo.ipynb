{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel methods \n",
    "\n",
    "### Import des fonctions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV,StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.linalg import solve,lstsq\n",
    "from scipy.stats import uniform\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from itertools import compress\n",
    "import numexpr as ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.01087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.01087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.01087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.010870  0.010870  0.043478  0.010870  0.021739  0.021739  0.000000   \n",
       "1     0.000000  0.000000  0.010870  0.010870  0.000000  0.010870  0.010870   \n",
       "2     0.021739  0.010870  0.021739  0.000000  0.000000  0.000000  0.010870   \n",
       "3     0.021739  0.010870  0.043478  0.000000  0.000000  0.000000  0.010870   \n",
       "4     0.021739  0.010870  0.010870  0.010870  0.010870  0.010870  0.032609   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1995  0.000000  0.000000  0.000000  0.010870  0.000000  0.010870  0.000000   \n",
       "1996  0.010870  0.021739  0.000000  0.000000  0.000000  0.021739  0.010870   \n",
       "1997  0.010870  0.000000  0.000000  0.000000  0.000000  0.010870  0.010870   \n",
       "1998  0.010870  0.010870  0.000000  0.000000  0.021739  0.000000  0.010870   \n",
       "1999  0.000000  0.000000  0.000000  0.032609  0.010870  0.010870  0.010870   \n",
       "\n",
       "            7         8         9   ...        90        91       92  \\\n",
       "0     0.010870  0.010870  0.010870  ...  0.000000  0.032609  0.01087   \n",
       "1     0.000000  0.000000  0.000000  ...  0.010870  0.010870  0.01087   \n",
       "2     0.010870  0.000000  0.000000  ...  0.000000  0.000000  0.00000   \n",
       "3     0.000000  0.000000  0.010870  ...  0.021739  0.000000  0.00000   \n",
       "4     0.000000  0.010870  0.043478  ...  0.010870  0.010870  0.00000   \n",
       "...        ...       ...       ...  ...       ...       ...      ...   \n",
       "1995  0.021739  0.010870  0.032609  ...  0.000000  0.010870  0.01087   \n",
       "1996  0.010870  0.021739  0.000000  ...  0.021739  0.010870  0.00000   \n",
       "1997  0.010870  0.021739  0.000000  ...  0.010870  0.010870  0.00000   \n",
       "1998  0.021739  0.000000  0.032609  ...  0.032609  0.000000  0.00000   \n",
       "1999  0.010870  0.010870  0.021739  ...  0.000000  0.021739  0.01087   \n",
       "\n",
       "            93        94        95        96        97        98       99  \n",
       "0     0.010870  0.010870  0.000000  0.000000  0.010870  0.000000  0.01087  \n",
       "1     0.021739  0.000000  0.010870  0.021739  0.032609  0.000000  0.00000  \n",
       "2     0.010870  0.000000  0.021739  0.000000  0.021739  0.021739  0.01087  \n",
       "3     0.000000  0.000000  0.000000  0.010870  0.000000  0.000000  0.01087  \n",
       "4     0.000000  0.010870  0.010870  0.032609  0.010870  0.021739  0.01087  \n",
       "...        ...       ...       ...       ...       ...       ...      ...  \n",
       "1995  0.000000  0.000000  0.000000  0.000000  0.000000  0.010870  0.00000  \n",
       "1996  0.010870  0.000000  0.000000  0.000000  0.000000  0.010870  0.01087  \n",
       "1997  0.000000  0.021739  0.000000  0.032609  0.032609  0.000000  0.00000  \n",
       "1998  0.010870  0.000000  0.010870  0.000000  0.000000  0.000000  0.01087  \n",
       "1999  0.000000  0.032609  0.000000  0.010870  0.000000  0.010870  0.00000  \n",
       "\n",
       "[2000 rows x 100 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_0=pd.read_csv(\"Data/Xtr0_mat100.csv\",sep=' ',header=None)\n",
    "X_1=pd.read_csv(\"Data/Xtr1_mat100.csv\",sep=' ',header=None)\n",
    "X_2=pd.read_csv(\"Data/Xtr2_mat100.csv\",sep=' ',header=None)\n",
    "\n",
    "\n",
    "Y_0=pd.read_csv(\"Data/Ytr0.csv\",sep=',')\n",
    "Y_1=pd.read_csv(\"Data/Ytr1.csv\",sep=',')\n",
    "Y_2=pd.read_csv(\"Data/Ytr2.csv\",sep=',')\n",
    "\n",
    "X_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1038\n",
      "1     962\n",
      "Name: Bound, dtype: int64\n",
      "1    1001\n",
      "0     999\n",
      "Name: Bound, dtype: int64\n",
      "0    1003\n",
      "1     997\n",
      "Name: Bound, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Y_0[\"Bound\"].value_counts())\n",
    "print(Y_1[\"Bound\"].value_counts())\n",
    "print(Y_2[\"Bound\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les classes sont plutôt équilibrées "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  1  1 ... -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "Y_0train=np.where(Y_0[\"Bound\"]==0,-1,Y_0[\"Bound\"])\n",
    "Y_1train=np.where(Y_1[\"Bound\"]==0,-1,Y_1[\"Bound\"])\n",
    "Y_2train=np.where(Y_2[\"Bound\"]==0,-1,Y_2[\"Bound\"])\n",
    "\n",
    "X_0train=X_0.to_numpy()\n",
    "X_1train=X_1.to_numpy()\n",
    "X_2train=X_2.to_numpy()\n",
    "print(X_0train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression ( équivalent à Kernel ridge régression avec noyau linéaire) \n",
    "On ajoute un colonne de biais "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0train_forRR=np.hstack((np.ones((X_0train.shape[0],1)),X_0train))\n",
    "X_1train_forRR=np.hstack((np.ones((X_0train.shape[0],1)),X_0train))\n",
    "X_2train_forRR=np.hstack((np.ones((X_0train.shape[0],1)),X_0train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solver ridge Regression \n",
    "Même si les classes sont équilibrées je laisse la possibilité de modifier les poids. Enfin pas vraiment puis que le seul poid que je met quand on souhaite en mettre c'est le poid correspondant au poids de classes dans le set qui sera entraîné.\n",
    "J'utilise lstq pour résoudre le système lineaire car plus stable si la matrice est mal conditionné/pas inversible) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ridge_Regresssion(X_train,y_train,lbd,weight=False):\n",
    "    n=y_train.shape[0]\n",
    "    d=X_train.shape[1]\n",
    "    if not(weight):\n",
    "        A=(X_train.T.dot(X_train))/n+lbd*np.eye(d)\n",
    "        B=X_train.T.dot(y_train)/n\n",
    "        theta=lstsq(A,B)[0]\n",
    "        return theta\n",
    "    else:\n",
    "        w1=(y_train==1).mean()\n",
    "        w0=1-w1\n",
    "        w=np.where(y_train==1,w1,w0)\n",
    "        W=np.diag(w)\n",
    "        A=(X_train.T.dot(W.dot(X_train)))/n+lbd*np.eye(d)\n",
    "        B=X_train.T.dot(W.dot(y_train))/n\n",
    "        theta=lstq(A,B)[0]\n",
    "        return theta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Création de l'estimateur Ridge regression compatible avec l'API de scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRR(BaseEstimator,ClassifierMixin):\n",
    "    def __init__(self,lbd=1,weight=False):\n",
    "        self.lbd=lbd\n",
    "        self.weight=weight\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        \n",
    "        self.theta=Ridge_Regresssion(X,y,self.lbd,self.weight)\n",
    "        return self\n",
    "    def decision_function(self,X):\n",
    "        return X.dot(self.theta)\n",
    "        \n",
    "    def predict(self,X,y=None):\n",
    "        scores=self.decision_function(X)\n",
    "        if len(scores.shape) == 1:\n",
    "            indices = (scores > 0).astype(np.int)\n",
    "        else:\n",
    "            indices = scores.argmax(axis=1)\n",
    "        return self.classes_[indices]\n",
    "   \n",
    "    def get_params(self, deep=True):\n",
    "    \n",
    "        return {\"lbd\": self.lbd,\"weight\":self.weight}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction permettant d'afficher les n meilleurs résultats avec les paramètres associées d'une grid search dans un tableau (dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def présentation_résultat(search,n):\n",
    "    mask=search.cv_results_['rank_test_score']<=n\n",
    "    params=list(compress(search.cv_results_['params'], list(mask)))\n",
    "    mean_test_score=search.cv_results_['mean_test_score'][mask]\n",
    "    a={}\n",
    "    for i in range(mean_test_score.size):\n",
    "        k=''\n",
    "        for key, value in params[i].items():\n",
    "            k+=\" \"+key+\" \"+str(value)\n",
    "        a.update({k:mean_test_score[i]})\n",
    "        sortedDict = sorted(a.items(), key=lambda x: x[1],reverse=True)\n",
    "    l=[]\n",
    "    for i in sortedDict:\n",
    "        u=i[0].split(sep=' ')\n",
    "        del(u[0])\n",
    "        lp=[]\n",
    "        for j in u[1::2]:\n",
    "            lp.append(j)\n",
    "        lp.append(i[1])\n",
    "        l.append(lp)\n",
    "    head=list(params[0].keys())+[\"mean_test_score\"]\n",
    "\n",
    "    return(pd.DataFrame(l,columns=head))\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Première recherche des hyperparamètres pour chaque train set \n",
    "Je crée un pipeline composé d'un transformer de données et de la ridgre regression. Dans la manière dont j'ai défini la pipeline le transformer en question est *StandardScaler()* qui standardise les données ((X-mean)/std)). Attention cela standardise les données selon la mean et std du train set et donc lors d'une prédiction le test/validation set sera standardisé par rapport à la mean et std du training set. \n",
    "En soit la manière dont j'ai défini le tranformeur n'a pas d'importance car dans la gridSearch je teste d'autres transformeur à certain moment(mais fallait bien en mettre pour faire la pipeline), il y a même une option *\"passthrough\"* pour la première étape de la pipeline qui veut dire tout simplement passer à l'étape suivante et donc ne pas transfomrer mes données.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('preprocess', StandardScaler()), ('linearrr', LinearRR())])\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 320 out of 320 | elapsed:   13.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 320 out of 320 | elapsed:   13.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 320 out of 320 | elapsed:   14.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocess', StandardScaler()),\n",
       "                                       ('linearrr', LinearRR())]),\n",
       "             param_grid={'linearrr__lbd': [1e-06, 1e-05, 0.0001, 0.001, 0.01,\n",
       "                                           0.1, 1, 10],\n",
       "                         'linearrr__weight': [False, True],\n",
       "                         'preprocess': ['passthrough', StandardScaler(),\n",
       "                                        RobustScaler(), MinMaxScaler()]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RR=Pipeline([(\"preprocess\",StandardScaler()),(\"linearrr\",LinearRR())])\n",
    "print(RR)\n",
    "\n",
    "hps0={\"linearrr__lbd\":[10**-6,10**-5,10**-4,10**-3,10**-2,10**-1,1,10],\"linearrr__weight\":[False,True],\n",
    "     \"preprocess\":[\"passthrough\",StandardScaler(),RobustScaler(),MinMaxScaler()]}\n",
    "searchLRR0= GridSearchCV(RR,hps0,scoring=\"accuracy\",cv=5,verbose=1)\n",
    "searchLRR0.fit(X_0train_forRR, Y_0train)\n",
    "\n",
    "hps1={\"linearrr__lbd\":[10**-6,10**-5,10**-4,10**-3,10**-2,10**-1,1,10],\"linearrr__weight\":[False,True],\n",
    "     \"preprocess\":[\"passthrough\",StandardScaler(),RobustScaler(),MinMaxScaler()]}\n",
    "searchLRR1= GridSearchCV(RR,hps1,scoring=\"accuracy\",cv=5,verbose=1)\n",
    "searchLRR1.fit(X_1train_forRR, Y_1train)\n",
    "\n",
    "\n",
    "hps2={\"linearrr__lbd\":[10**-6,10**-5,10**-4,10**-3,10**-2,10**-1,1,10],\"linearrr__weight\":[False,True],\n",
    "     \"preprocess\":[\"passthrough\",StandardScaler(),RobustScaler(),MinMaxScaler()]}\n",
    "searchLRR2= GridSearchCV(RR,hps2,scoring=\"accuracy\",cv=5,verbose=1)\n",
    "searchLRR2.fit(X_2train_forRR, Y_2train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage des résulats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   linearrr__lbd linearrr__weight        preprocess  mean_test_score\n",
      "0              1             True  StandardScaler()           0.5975\n",
      "1              1            False  StandardScaler()           0.5945\n",
      "2            0.1             True  StandardScaler()           0.5940\n",
      "3           0.01            False    MinMaxScaler()           0.5930\n",
      "4            0.1            False  StandardScaler()           0.5905\n",
      "5          0.001             True    MinMaxScaler()           0.5890\n",
      "6           0.01            False  StandardScaler()           0.5885\n",
      "7           0.01             True  StandardScaler()           0.5870\n",
      "8          0.001             True  StandardScaler()           0.5865\n",
      "9          1e-06             True  StandardScaler()           0.5860\n",
      "10         1e-05             True  StandardScaler()           0.5860\n",
      "11        0.0001             True  StandardScaler()           0.5860\n",
      "12         0.001            False  StandardScaler()           0.5860\n",
      "   linearrr__lbd linearrr__weight        preprocess  mean_test_score\n",
      "0            0.1            False       passthrough           0.5150\n",
      "1            0.1             True    MinMaxScaler()           0.5150\n",
      "2             10             True  StandardScaler()           0.5135\n",
      "3              1             True    MinMaxScaler()           0.5130\n",
      "4             10             True    MinMaxScaler()           0.5130\n",
      "5              1            False    MinMaxScaler()           0.5125\n",
      "6           0.01             True       passthrough           0.5125\n",
      "7              1             True    RobustScaler()           0.5110\n",
      "8             10            False  StandardScaler()           0.5110\n",
      "9          0.001            False       passthrough           0.5090\n",
      "10           0.1            False    MinMaxScaler()           0.5090\n",
      "  linearrr__lbd linearrr__weight        preprocess  mean_test_score\n",
      "0          0.01             True       passthrough           0.5015\n",
      "1           0.1             True       passthrough           0.5015\n",
      "2             1            False       passthrough           0.5015\n",
      "3             1             True       passthrough           0.5015\n",
      "4            10            False       passthrough           0.5015\n",
      "5            10             True       passthrough           0.5015\n",
      "6            10             True    MinMaxScaler()           0.5010\n",
      "7           0.1            False       passthrough           0.5005\n",
      "8            10             True  StandardScaler()           0.4995\n",
      "9         0.001            False       passthrough           0.4980\n"
     ]
    }
   ],
   "source": [
    "print(présentation_résultat(searchLRR0,10))\n",
    "print(présentation_résultat(searchLRR1,10))\n",
    "print(présentation_résultat(searchLRR2,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche plus fine dans les zones d'intérêts déterminés à l'aide la search précedente\n",
    "\n",
    "Ici je fais une RandomizedGrid search car j'ai beaucoup plus d'inormations sur les zones d'intérêt où il faut chercher(notemment pour le lambda). Si je l'avais fait avant étant donné que j'avais aucun à priori sur la valeur de lambda la recherche au hasard aurait été plus difficile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 5000 out of 5000 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 5000 out of 5000 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 5000 out of 5000 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('preprocess', StandardScaler()),\n",
       "                                             ('linearrr', LinearRR())]),\n",
       "                   n_iter=1000,\n",
       "                   param_distributions={'linearrr__lbd': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000258DC893B50>,\n",
       "                                        'linearrr__weight': [False, True],\n",
       "                                        'preprocess': ['passthrough']},\n",
       "                   scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "hps0={\"linearrr__lbd\":uniform(loc=0.005,scale=5),\"linearrr__weight\":[False,True]}\n",
    "searchLRR0= RandomizedSearchCV(RR,hps0,n_iter=1000,scoring=\"accuracy\",cv=5,verbose=1)\n",
    "searchLRR0.fit(X_0train_forRR, Y_0train)\n",
    "\n",
    "hps1={\"linearrr__lbd\":uniform(loc=0.05,scale=10),\"linearrr__weight\":[False,True],\n",
    "     \"preprocess\":[\"passthrough\",StandardScaler(),RobustScaler(),MinMaxScaler()]}\n",
    "searchLRR1= RandomizedSearchCV(RR,hps1,n_iter=1000,scoring=\"accuracy\",cv=5,verbose=1)\n",
    "searchLRR1.fit(X_1train_forRR, Y_1train)\n",
    "\n",
    "\n",
    "hps2={\"linearrr__lbd\":uniform(loc=0.005,scale=10),\"linearrr__weight\":[False,True],\n",
    "     \"preprocess\":[\"passthrough\"]}\n",
    "searchLRR2= RandomizedSearchCV(RR,hps2,n_iter=1000,scoring=\"accuracy\",cv=5,verbose=1)\n",
    "searchLRR2.fit(X_2train_forRR, Y_2train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Présentation des résultats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         linearrr__lbd linearrr__weight  mean_test_score\n",
      "0   0.6808368789557301             True           0.5995\n",
      "1   0.6488895482849216             True           0.5995\n",
      "2   0.6767049343351716             True           0.5995\n",
      "3    0.621128518027827             True           0.5990\n",
      "4    0.664829316929445             True           0.5990\n",
      "5    0.622062086234566             True           0.5990\n",
      "6    0.608279167880712             True           0.5990\n",
      "7    0.639381675975868             True           0.5990\n",
      "8     1.23353765953284            False           0.5990\n",
      "9   1.2598755980184615            False           0.5985\n",
      "10  1.2455362990019019            False           0.5985\n",
      "          linearrr__lbd linearrr__weight      preprocess  mean_test_score\n",
      "0     1.666125807871538             True  MinMaxScaler()           0.5165\n",
      "1    1.6427502712439634             True  MinMaxScaler()           0.5165\n",
      "2   0.14439490141905037            False  MinMaxScaler()           0.5165\n",
      "3    1.6842109992352905             True  MinMaxScaler()           0.5165\n",
      "4     2.520349866838189             True  MinMaxScaler()           0.5160\n",
      "5     5.226790466489929             True  MinMaxScaler()           0.5155\n",
      "6     5.228522433599514             True  MinMaxScaler()           0.5155\n",
      "7     5.147143628510188             True  MinMaxScaler()           0.5155\n",
      "8    1.7544474502402219             True  MinMaxScaler()           0.5155\n",
      "9     5.538535884721031             True  MinMaxScaler()           0.5155\n",
      "10    5.407286783829693             True  MinMaxScaler()           0.5155\n",
      "11    5.600306238015793             True  MinMaxScaler()           0.5155\n",
      "           linearrr__lbd linearrr__weight   preprocess  mean_test_score\n",
      "0    0.06282455723898128            False  passthrough           0.5035\n",
      "1  0.0071377298218938635             True  passthrough           0.5020\n"
     ]
    }
   ],
   "source": [
    "print(présentation_résultat(searchLRR0,10))\n",
    "print(présentation_résultat(searchLRR1,10))\n",
    "print(présentation_résultat(searchLRR2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche encore plus fine (sert pas trop à grand chose car on va garder ce modèle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 2500 out of 2500 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 2500 out of 2500 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 2500 out of 2500 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('preprocess', StandardScaler()),\n",
       "                                             ('linearrr', LinearRR())]),\n",
       "                   n_iter=500,\n",
       "                   param_distributions={'linearrr__lbd': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000258D7D182E0>,\n",
       "                                        'linearrr__weight': [False, True],\n",
       "                                        'preprocess': ['passthrough']},\n",
       "                   scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hps0={\"linearrr__lbd\":uniform(loc=0.5,scale=1.5),\"linearrr__weight\":[False,True]}\n",
    "searchLRR0= RandomizedSearchCV(RR,hps0,n_iter=500,scoring=\"accuracy\",cv=5,verbose=1)\n",
    "searchLRR0.fit(X_0train_forRR, Y_0train)\n",
    "\n",
    "hps1={\"linearrr__lbd\":uniform(loc=1.5,scale=4.5),\"linearrr__weight\":[True],\n",
    "     \"preprocess\":[MinMaxScaler()]}\n",
    "searchLRR1= RandomizedSearchCV(RR,hps1,n_iter=500,scoring=\"accuracy\",cv=5,verbose=1)\n",
    "searchLRR1.fit(X_1train_forRR, Y_1train)\n",
    "\n",
    "\n",
    "hps2={\"linearrr__lbd\":uniform(loc=0.005,scale=0.1),\"linearrr__weight\":[False,True],\n",
    "     \"preprocess\":[\"passthrough\"]}\n",
    "searchLRR2= RandomizedSearchCV(RR,hps2,n_iter=500,scoring=\"accuracy\",cv=5,verbose=1)\n",
    "searchLRR2.fit(X_2train_forRR, Y_2train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Présentation des résultats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         linearrr__lbd linearrr__weight  mean_test_score\n",
      "0   0.6474957713207163             True           0.5995\n",
      "1   0.6710958253318303             True           0.5995\n",
      "2   0.6780076073848955             True           0.5995\n",
      "3    0.684706500425291             True           0.5995\n",
      "4   0.6566284985873325             True           0.5995\n",
      "5   0.6527012855360701             True           0.5995\n",
      "6   0.6332628536368978             True           0.5995\n",
      "7    0.636330197042721             True           0.5995\n",
      "8   1.3388173314288454            False           0.5990\n",
      "9   1.2439881721589723            False           0.5990\n",
      "10  0.7009797809890661             True           0.5990\n",
      "11  0.6970090412156806             True           0.5990\n",
      "12  0.6959957407336215             True           0.5990\n",
      "13  0.6250852638590156             True           0.5990\n",
      "14  0.6983219002757041             True           0.5990\n",
      "15  0.6178297739883101             True           0.5990\n",
      "16  0.6158370984442172             True           0.5990\n",
      "17  0.6078910288599091             True           0.5990\n",
      "18   0.692898639361698             True           0.5990\n",
      "19  0.6923675791613284             True           0.5990\n",
      "20  0.6689720597932818             True           0.5990\n",
      "21  1.3404067953614698            False           0.5990\n",
      "22  0.6994397575710237             True           0.5990\n",
      "         linearrr__lbd linearrr__weight      preprocess  mean_test_score\n",
      "0    5.311047018405071             True  MinMaxScaler()           0.5165\n",
      "1   1.6609723049302985             True  MinMaxScaler()           0.5165\n",
      "2    5.285977496854221             True  MinMaxScaler()           0.5165\n",
      "3   1.6479788097047328             True  MinMaxScaler()           0.5165\n",
      "4    1.687133732363223             True  MinMaxScaler()           0.5165\n",
      "5    5.313229582332886             True  MinMaxScaler()           0.5165\n",
      "6    5.291031348551257             True  MinMaxScaler()           0.5165\n",
      "7   5.3392405651221555             True  MinMaxScaler()           0.5165\n",
      "8    5.292970107304589             True  MinMaxScaler()           0.5165\n",
      "9     5.35179362044782             True  MinMaxScaler()           0.5165\n",
      "10  1.7077848094221448             True  MinMaxScaler()           0.5165\n",
      "11  1.7053526940235162             True  MinMaxScaler()           0.5165\n",
      "12   5.334279943128903             True  MinMaxScaler()           0.5165\n",
      "13   5.314988854400562             True  MinMaxScaler()           0.5165\n",
      "14  1.6484989179201743             True  MinMaxScaler()           0.5165\n",
      "15  1.6865003134820102             True  MinMaxScaler()           0.5165\n",
      "16   1.701987580265691             True  MinMaxScaler()           0.5165\n",
      "17  1.6781662506933954             True  MinMaxScaler()           0.5165\n",
      "18  1.6607204567967067             True  MinMaxScaler()           0.5165\n",
      "           linearrr__lbd linearrr__weight   preprocess  mean_test_score\n",
      "0     0.0327814522093089            False  passthrough           0.5070\n",
      "1   0.034623948459144856            False  passthrough           0.5065\n",
      "2    0.03472653095255037            False  passthrough           0.5065\n",
      "3   0.008251237322577572             True  passthrough           0.5060\n",
      "4    0.03443829032852346            False  passthrough           0.5060\n",
      "5    0.03460750892638959            False  passthrough           0.5060\n",
      "6   0.008150215107658027             True  passthrough           0.5060\n",
      "7    0.03444624732834964            False  passthrough           0.5060\n",
      "8    0.03606305240672544            False  passthrough           0.5055\n",
      "9   0.034818098732737106            False  passthrough           0.5055\n",
      "10  0.008758040635372163             True  passthrough           0.5055\n",
      "11  0.036686355301141185            False  passthrough           0.5055\n"
     ]
    }
   ],
   "source": [
    "print(présentation_résultat(searchLRR0,10))\n",
    "print(présentation_résultat(searchLRR1,10))\n",
    "print(présentation_résultat(searchLRR2,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Ridge regression \n",
    "\n",
    "### Crétion du kernel de manière efficiente voir ce lien pour comprendre https://stackoverflow.com/questions/47271662/what-is-the-fastest-way-to-compute-an-rbf-kernel-in-python \n",
    "Mais ce qu'il y a retenir c'est que $\\| x-y \\|^2=\\|x\\|^2 + \\|y\\|^2 -2x^Ty$ et d'utiliser à son avantage le broadcast de Numpy. Le ne.evaluate est là pour rendre l'opération plus rapide mais l'opération qui est faite et bien \"exp(-g*(A+B-2*C))\" Avec les A B C g correspondant. D'ailleurs la propriété précédente nous permet de manière générale de calculer la matrice $K(x_i,y_i)$ pour $y_1,\\dots,y_k ~~x_1,\\dots,x_n$  $y_i,x_i \\in R^d$ La kernel matrice et un cas particulier où $n=k$ et $x_i=y_i$ pour tout $i$.\n",
    "Cette fonction est contruite juste après la fonction qui construit la kernel matrice. Elle nous sera très utile en espérant que vous aviez déjà deviné pourquoi, c'est pour  calculer $\\left(f(z_1),\\dots,f(z_k)\\right)$ oû $f(z_j)=\\sum_{i=1}^{n}\\alpha_i K(z_j,x_i)$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_kernel(X_train,gamma):\n",
    "    X_norm = np.sum(X_train ** 2, axis = -1)\n",
    "    K = ne.evaluate('exp(-g * (A + B - 2 * C))', {\n",
    "        'A' : X_norm[:,None],\n",
    "        'B' : X_norm[None,:],\n",
    "        'C' : np.dot(X_train, X_train.T),\n",
    "        'g' : gamma,\n",
    "    })\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_rbf_kernel(X_test,X_train,gamma):\n",
    "   \n",
    "    Xtt_norm = np.sum(X_test ** 2, axis = -1)\n",
    "    Xtr_norm = np.sum(X_train ** 2, axis = -1)\n",
    "    K = ne.evaluate('exp(-g * (A + B - 2 * C))', {\n",
    "        'A' : Xtt_norm[:,None],\n",
    "        'B' : Xtr_norm[None,:],\n",
    "        'C' : np.dot(X_test, X_train.T),\n",
    "        'g' : gamma,\n",
    "    })\n",
    "    return K\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du solver Kernel ridge regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kernel_Ridge_Regression(X_train,y_train,lbd,weight,gamma):\n",
    "    K=rbf_kernel(X_train,gamma)\n",
    "    n=K.shape[0]\n",
    "    if not(weight):\n",
    "        A=(K+n*lbd*np.eye(n))\n",
    "        alpha=lstsq(A,y_train)[0]\n",
    "        return alpha\n",
    "    else :\n",
    "        w1=(y_train==1).mean()\n",
    "        w0=1-w1\n",
    "        w=np.where(y_train==1,w1,w0)\n",
    "        Wr=np.diag(w**0.5)\n",
    "        Wir=np.diag((1/w)**0.5)\n",
    "        A=((Wr.dot(K.dot(Wr)))+n*lbd*np.eye(n)).dot(Wir)\n",
    "        alpha=lstsq(A,Wr.dot(y_train))[0]\n",
    "        return alpha\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de l'estimateur compatible avec l'Api de scikit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelRR(BaseEstimator,ClassifierMixin):\n",
    "    def __init__(self,lbd=1,weight=False,gamma=1):\n",
    "        self.lbd=lbd\n",
    "        self.weight=weight\n",
    "        self.gamma=gamma\n",
    "    def fit(self,X,y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.Xtr=X\n",
    "        self.alpha=Kernel_Ridge_Regression(X,y,self.lbd,self.weight,self.gamma)\n",
    "        return self\n",
    "    def decision_function(self,X):\n",
    "        return K_rbf_kernel(X,self.Xtr,self.gamma).dot(self.alpha) \n",
    "        \n",
    "    def predict(self,X,y=None):\n",
    "        scores=self.decision_function(X)\n",
    "        if len(scores.shape) == 1:\n",
    "            indices = (scores > 0).astype(np.int)\n",
    "        else:\n",
    "            indices = scores.argmax(axis=1)\n",
    "        return self.classes_[indices]\n",
    "   \n",
    "    def get_params(self, deep=True):\n",
    "    \n",
    "        return {\"lbd\": self.lbd,\"weight\":self.weight,\"gamma\":self.gamma}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche des hyperparamètres pour KRR avec noyau gaussien \n",
    "Pas tester la transformation des données avant de cré la kernel matrices à faire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KernelRR()\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed: 12.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed: 19.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed: 12.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KernelRR(), n_jobs=-1,\n",
       "             param_grid={'gamma': [0.001, 0.01, 0.1, 1, 10],\n",
       "                         'lbd': [1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10],\n",
       "                         'weight': [False, True]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KRR=KernelRR()\n",
    "print(KRR)\n",
    "\n",
    "hps0={\"lbd\":[10**-6,10**-5,10**-4,10**-3,10**-2,10**-1,1,10],\"weight\":[False,True],\n",
    "     \"gamma\":[0.001,0.01,0.1,1,10]}\n",
    "searchKRR0= GridSearchCV(KRR,hps0,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKRR0.fit(X_0train, Y_0train)\n",
    "\n",
    "hps1={\"lbd\":[10**-6,10**-5,10**-4,10**-3,10**-2,10**-1,1,10],\"weight\":[False,True],\n",
    "     \"gamma\":[0.001,0.01,0.1,1,10]}\n",
    "searchKRR1= GridSearchCV(KRR,hps1,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKRR1.fit(X_1train, Y_1train)\n",
    "\n",
    "\n",
    "hps2={\"lbd\":[10**-6,10**-5,10**-4,10**-3,10**-2,10**-1,1,10],\"weight\":[False,True],\n",
    "     \"gamma\":[0.001,0.01,0.1,1,10]}\n",
    "searchKRR2= GridSearchCV(KRR,hps2,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKRR2.fit(X_2train, Y_2train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Présentation des Résultats \n",
    "On remarque pour le training set 1 on a 10% en plus 20% en plus!!! pour le training set 2 et rien ne change pour le training set 0 par rapport au modèle linéraire. A Approfondir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  gamma     lbd weight  mean_test_score\n",
      "0     1   1e-06  False           0.5945\n",
      "1  0.01   1e-06  False           0.5935\n",
      "2    10  0.0001  False           0.5935\n",
      "3   0.1   1e-05  False           0.5930\n",
      "4     1  0.0001  False           0.5930\n",
      "5     1   1e-05  False           0.5910\n",
      "6     1   1e-05   True           0.5900\n",
      "7    10  0.0001   True           0.5890\n",
      "8    10   0.001  False           0.5885\n",
      "9     1   1e-06   True           0.5865\n",
      "  gamma     lbd weight  mean_test_score\n",
      "0     1   1e-06  False           0.6025\n",
      "1    10  0.0001  False           0.5995\n",
      "2    10  0.0001   True           0.5980\n",
      "3     1   1e-06   True           0.5955\n",
      "4    10   1e-05   True           0.5930\n",
      "5    10   0.001  False           0.5825\n",
      "6    10   1e-05  False           0.5805\n",
      "7     1   1e-05  False           0.5785\n",
      "8     1  0.0001  False           0.5765\n",
      "9    10   0.001   True           0.5765\n",
      "  gamma     lbd weight  mean_test_score\n",
      "0    10  0.0001  False           0.7050\n",
      "1    10  0.0001   True           0.7015\n",
      "2    10   0.001  False           0.6990\n",
      "3    10   0.001   True           0.6990\n",
      "4     1   1e-06  False           0.6940\n",
      "5     1   1e-06   True           0.6940\n",
      "6     1  0.0001  False           0.6935\n",
      "7  0.01   1e-06  False           0.6935\n",
      "8   0.1   1e-05  False           0.6935\n",
      "9     1   1e-05  False           0.6925\n"
     ]
    }
   ],
   "source": [
    "print(présentation_résultat(searchKRR0,10))\n",
    "print(présentation_résultat(searchKRR1,10))\n",
    "print(présentation_résultat(searchKRR2,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
