{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook dédiée au test du noyau gaussien avec les différents classifieurs\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.Import des fonctions, créations des fonctions utiles et des classifieurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import numexpr as ne\n",
    "from scipy.stats import uniform\n",
    "from scipy.linalg import solve,lstsq\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV,StratifiedKFold\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import accuracy_score\n",
    "from cvxopt import matrix\n",
    "from cvxopt import solvers\n",
    "from tqdm import tqdm\n",
    "from itertools import product,compress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kernel_Ridge_Regression(X_train,y_train,lbd,weight,gamma,degree,c0,k,biais,kernel):\n",
    "    if kernel==\"rbf\":\n",
    "        K=rbf_kernel(X_train,gamma)\n",
    "    elif kernel==\"poly\":\n",
    "        K=poly_kernel(X_train,X_train,degree,c0)\n",
    "    elif kernel==\"spectrum\":\n",
    "        K=spectrum_kernel(X_train,k)\n",
    "    elif kernel==\"precomputed\":\n",
    "        K=X_train\n",
    "    n=K.shape[0]\n",
    "    w=weight\n",
    "    if not(biais):\n",
    "        if isinstance(weight,bool):\n",
    "            A=(K+n*lbd*np.eye(n))\n",
    "            alpha=solve(A,y_train,assume_a=\"sym\")\n",
    "            return alpha\n",
    "        elif isinstance(weight,str):\n",
    "                w1=(y_train==1).mean()\n",
    "                w0=1-w1\n",
    "                w=np.where(y_train==1,w1,w0)\n",
    "        wi=(1/w)\n",
    "        \n",
    "        A=K+n*lbd*wi*np.eye(n)\n",
    "        alpha=solve(A,y_train,assume_a=\"sym\")\n",
    "     \n",
    "        return alpha\n",
    "    else:\n",
    "        \n",
    "        Kb=addbiais(K)\n",
    "        \n",
    "        K0=addzeros(K)\n",
    "    \n",
    "        if isinstance(weight,bool):\n",
    "            A=(Kb.T.dot(Kb)+lbd*n*K0)\n",
    "            B=Kb.T.dot(y_train)\n",
    "            alpha=solve(A,B,assume_a=\"sym\")\n",
    "            return alpha\n",
    "        elif isinstance(weight,str):\n",
    "                w1=(y_train==1).mean()\n",
    "                w0=1-w1\n",
    "                w=np.where(y_train==1,w1,w0)\n",
    "        W=np.diag(w)\n",
    "        A=(Kb.T.dot(W.dot(Kb))+lbd*n*K0)\n",
    "        B=Kb.T.dot(W.dot(y_train),assume_a=\"sym\")\n",
    "        alpha=solve(A,B)\n",
    "        return alpha\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelRR(BaseEstimator,ClassifierMixin):\n",
    "    def __init__(self,lbd=1,weight=False,gamma=\"auto\",degree=2,c0=1,k=3,biais=False,kernel=\"rbf\"):\n",
    "        self.lbd=lbd\n",
    "        self.weight=weight\n",
    "        self.gamma=gamma\n",
    "        self.degree=degree\n",
    "        self.c0=c0\n",
    "        self.k=k\n",
    "        self.biais=biais\n",
    "        self.kernel=kernel\n",
    "    def fit(self,X,y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.Xtr=X\n",
    "        if isinstance(self.gamma,str) and self.kernel==\"rbf\":\n",
    "            self.gamma=1/self.Xtr.shape[1]\n",
    "        self.alpha=Kernel_Ridge_Regression(X,y,self.lbd,self.weight,self.gamma,self.degree,self.c0,self.k,self.biais,self.kernel)\n",
    "        return self\n",
    "    def decision_function(self,X):\n",
    "        if self.kernel==\"precomputed\":\n",
    "            return X.dot(self.alpha)\n",
    "        if not(self.biais):\n",
    "            if self.kernel==\"rbf\":\n",
    "                return K_rbf_kernel(X,self.Xtr,self.gamma).dot(self.alpha) \n",
    "            elif self.kernel==\"poly\":\n",
    "                return poly_kernel(X,self.Xtr,self.degree,self.c0).dot(self.alpha) \n",
    "            elif self.kernel==\"spectrum\":\n",
    "                return K_spectrum_kernel(X,self.Xtr,self.k).dot(self.alpha) \n",
    "        else:\n",
    "            if self.kernel==\"rbf\":\n",
    "                return addbiais(K_rbf_kernel(X,self.Xtr,self.gamma)).dot(self.alpha)\n",
    "            elif self.kernel==\"poly\":\n",
    "                return addbiais(poly_kernel(X,self.Xtr,self.degree,self.c0)).dot(self.alpha)\n",
    "            elif self.kernel==\"spectrum\":\n",
    "                return addbiais(K_spectrum_kernel(X,self.Xtr,self.k)).dot(self.alpha)\n",
    "\n",
    "    def predict(self,X,y=None):\n",
    "        scores=self.decision_function(X)\n",
    "        if len(scores.shape) == 1:\n",
    "            indices = (scores > 0).astype(np.int)\n",
    "        else:\n",
    "            indices = scores.argmax(axis=1)\n",
    "        return self.classes_[indices]\n",
    "   \n",
    "    def get_params(self, deep=True):\n",
    "    \n",
    "        return {\"lbd\": self.lbd,\"weight\":self.weight,\"gamma\":self.gamma,\"degree\":self.degree,\"c0\":self.c0,\"k\":self.k,\n",
    "                \"biais\":self.biais,\"kernel\":self.kernel}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Kernel Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(v):\n",
    "    return 1/(1+np.exp(-v))\n",
    "def log_loss(v):\n",
    "    return np.log(1+np.exp(-v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IRLS(X_train,y_train,lbd,ga,degree,c0,k,bs,ker,n_iter,eps=10**-6,method='slow'):\n",
    "    n=y_train.shape[0]\n",
    "  \n",
    "    if ker==\"rbf\":\n",
    "        K=rbf_kernel(X_train,ga)\n",
    "    elif ker==\"poly\":\n",
    "        K=poly_kernel(X_train,X_train,degree,c0)\n",
    "    elif ker==\"spectrum\":\n",
    "        K=spectrum_kernel(X_train,k)\n",
    "    elif ker==\"precomputed\":\n",
    "        K=X_train\n",
    "    #alpha=Kernel_Ridge_Regression(K,y_train,lbd,False,1,bs,\"precomputed\")\n",
    "    #alpha=np.zeros(n)\n",
    "    #l=[]\n",
    "  \n",
    "    if bs :\n",
    "        Kb=addbiais(K)\n",
    "        K0=addzeros(K)\n",
    "        alpha=np.zeros(n+1)\n",
    "    else:\n",
    "        alpha=np.zeros(n)\n",
    "    for i in range(n_iter):\n",
    "   \n",
    "        alpha_old=alpha\n",
    "       \n",
    "        if bs:\n",
    "            m=Kb.dot(alpha)\n",
    "            #l.append(log_loss(y_train*m).mean()+lbd*alpha[:-1].dot(K.dot(alpha[:-1])))\n",
    "        \n",
    "        else:\n",
    "            m=K.dot(alpha)\n",
    "            #l.append(log_loss(y_train*m).mean()+lbd*alpha.dot(m))\n",
    "        \n",
    "        \n",
    "        p=sigmoid(m)\n",
    "       \n",
    "        weight=p*(1-p)\n",
    "       \n",
    "        weight=np.where(weight<0.000001,0.000001,weight)\n",
    "       \n",
    "   \n",
    "        u=np.where(sigmoid(y_train*m)<0.000001,0.000001,sigmoid(y_train*m))\n",
    "        z = m + y_train/u\n",
    "    \n",
    "        if not(bs):\n",
    "        \n",
    "            S = np.diag(weight**-1)\n",
    "            A=(K+2*lbd*n*S)\n",
    "            alpha=solve(A,z,assume_a=\"sym\")\n",
    "            \n",
    "            #print(np.linalg.norm(alpha_old-alpha))\n",
    "            \n",
    "            if np.linalg.norm(alpha_old-alpha)<eps:\n",
    "                break\n",
    "        else:\n",
    "            S = np.diag(weight)\n",
    "            A=(Kb.T.dot(S.dot(Kb))+2*lbd*n*K0)\n",
    "            B=Kb.T.dot(S.dot(z))\n",
    "            if method==\"slow\":\n",
    "                alpha=lstsq(A,B)[0]\n",
    "            else:\n",
    "                alpha=solve(A,B,assume_a=\"sym\")\n",
    "            #print(np.linalg.norm(alpha_old-alpha))\n",
    "            if np.linalg.norm(alpha_old-alpha)<eps:\n",
    "                break\n",
    "                \n",
    "       \n",
    "    return alpha #,l\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelLR(BaseEstimator,ClassifierMixin):\n",
    "    def __init__(self,lbd=1,gamma='auto',degree=2,c0=1,k=3,biais=False,kernel=\"rbf\",n_iter=15,method=\"slow\"):\n",
    "        self.lbd=lbd\n",
    "        self.gamma=gamma\n",
    "        self.degree=degree\n",
    "        self.c0=c0\n",
    "        self.k=k\n",
    "        self.biais=biais\n",
    "        self.kernel=kernel\n",
    "        self.n_iter=n_iter\n",
    "        self.method=method\n",
    "    def fit(self,X,y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.Xtr=X\n",
    "        if isinstance(self.gamma,str) and self.kernel==\"rbf\":\n",
    "            self.gamma=1/self.Xtr.shape[1]\n",
    "        self.alpha=IRLS(X,y,self.lbd,self.gamma,self.degree,self.c0,self.k,self.biais,self.kernel,self.n_iter,method=self.method)\n",
    "        return self\n",
    "    def decision_function(self,X):\n",
    "        if not(self.biais):\n",
    "            if self.kernel==\"precomputed\":\n",
    "                return X.dot(self.alpha)\n",
    "            if self.kernel==\"rbf\":\n",
    "                return K_rbf_kernel(X,self.Xtr,self.gamma).dot(self.alpha) \n",
    "            elif self.kernel==\"poly\":\n",
    "                return poly_kernel(X,self.Xtr,self.degree,self.c0).dot(self.alpha) \n",
    "            elif self.kernel==\"spectrum\":\n",
    "                return K_spectrum_kernel(X,self.Xtr,self.k).dot(self.alpha) \n",
    "        else:\n",
    "            if self.kernel==\"rbf\":\n",
    "                return addbiais(K_rbf_kernel(X,self.Xtr,self.gamma)).dot(self.alpha)\n",
    "            elif self.kernel==\"poly\":\n",
    "                return addbiais(poly_kernel(X,self.Xtr,self.degree,self.c0)).dot(self.alpha)\n",
    "            elif self.kernel==\"spectrum\":\n",
    "                return addbiais(K_spectrum_kernel(X,self.Xtr,self.k)).dot(self.alpha)\n",
    "        \n",
    "\n",
    "    def predict(self,X,y=None):\n",
    "        scores=self.decision_function(X)\n",
    "        if len(scores.shape) == 1:\n",
    "            indices = (scores > 0).astype(np.int)\n",
    "        else:\n",
    "            indices = scores.argmax(axis=1)\n",
    "        return self.classes_[indices]\n",
    "    def predict_proba_(self,X,y=None):\n",
    "        p=sigmoid(self.decision_function(X)).reshape(-1,1)\n",
    "        return hstack((p,1-p))\n",
    "    def get_params(self, deep=True):\n",
    "    \n",
    "        return {\"lbd\": self.lbd,\"gamma\":self.gamma,\"degree\":self.degree,\"c0\":self.c0,\"k\":self.k,\"biais\":self.biais,\n",
    "                \"kernel\":self.kernel,\"n_iter\":self.n_iter,\"method\":self.method}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(X_train,y_train,C,gamma,degree,c0,k,kernel):\n",
    "    n=y_train.shape[0]\n",
    "    if kernel==\"rbf\":\n",
    "        K=rbf_kernel(X_train,gamma)\n",
    "    elif kernel==\"poly\":\n",
    "        K=poly_kernel(X_train,X_train,degree,c0)\n",
    "    elif kernel==\"spectrum\":\n",
    "        K=spectrum_kernel(X_train,k)\n",
    "    elif kernel==\"precomputed\":\n",
    "        K=X_train\n",
    "    P=matrix(K,tc='d')\n",
    "    q=matrix(-y_train,tc='d')\n",
    "    g1=np.diag(y_train)\n",
    "    G=matrix(np.vstack((g1,-g1)),tc='d')\n",
    "    h=matrix(np.hstack((np.repeat(C,n),np.zeros(n))),tc='d')\n",
    "    solvers.options['show_progress'] = False\n",
    "    sol=solvers.qp(P,q,G,h)\n",
    "    return np.array(sol['x']).reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelSVM(BaseEstimator,ClassifierMixin):\n",
    "    def __init__(self,C=1,gamma='auto',degree=\"2\",c0=1,k=3,kernel=\"rbf\"):\n",
    "        self.C=C\n",
    "        self.gamma=gamma\n",
    "        self.degree=degree\n",
    "        self.c0=c0\n",
    "        self.k=k\n",
    "        self.kernel=kernel\n",
    "    def fit(self,X,y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.Xtr=X\n",
    "        if isinstance(self.gamma,str) and self.kernel==\"rbf\":\n",
    "            self.gamma=1/self.Xtr.shape[1]\n",
    "        self.alpha=SVM(X,y,self.C,self.gamma,self.degree,self.c0,self.k,self.kernel)\n",
    "        #idx=self.alpha>10**-5\n",
    "        #self.Xtr=self.Xtr[idx]\n",
    "        #self.alpha=self.alpha[idx]\n",
    "        return self\n",
    "    def decision_function(self,X):\n",
    "        if self.kernel==\"precomputed\":\n",
    "            return X.dot(self.alpha)\n",
    "        elif self.kernel==\"rbf\":\n",
    "            return K_rbf_kernel(X,self.Xtr,self.gamma).dot(self.alpha) \n",
    "        elif self.kernel==\"poly\":\n",
    "            return poly_kernel(X,self.Xtr,self.degree,self.c0).dot(self.alpha) \n",
    "        elif self.kernel==\"spectrum\":\n",
    "            return K_spectrum_kernel(X,self.Xtr,self.k).dot(self.alpha) \n",
    "            \n",
    "           \n",
    "    def predict(self,X,y=None):\n",
    "        scores=self.decision_function(X)\n",
    "        if len(scores.shape) == 1:\n",
    "            indices = (scores > 0).astype(np.int)\n",
    "        else:\n",
    "            indices = scores.argmax(axis=1)\n",
    "        return self.classes_[indices]\n",
    "    def get_params(self, deep=True):\n",
    "    \n",
    "        return {\"C\": self.C,\"gamma\":self.gamma,\"degree\":self.degree,\"c0\":self.c0,\"k\":self.k,\"kernel\":self.kernel}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.4 Fonctions utiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cross_val_spectrum(dic_K,Y_train,model,hps,cv=5):\n",
    "    CV=StratifiedKFold(cv)\n",
    "    dic_K_prime={k:dic_K[k] for k in hps[\"k\"]}\n",
    "    list_hp=[]\n",
    "    list_val_score=[]\n",
    "    idx_k=list(hps.keys()).index(\"k\")\n",
    "    \n",
    "    for i in tqdm(product(*hps.values())):\n",
    "        \n",
    "        dic_hp={keys:values for keys,values in zip(hps.keys(),i)}\n",
    "        list_hp.append(dic_hp)\n",
    "        \n",
    "        model.set_params(**dic_hp)\n",
    "        acc_mean=0\n",
    "        for train_idx,val_idx in CV.split(X_train,Y_train):\n",
    "            K=dic_K_prime[i[idx_k]]\n",
    "            model.fit(K[train_idx][:,train_idx],Y_train[train_idx])\n",
    "            Y_pred=model.predict(K[val_idx][:,train_idx])\n",
    "            acc_mean+=accuracy_score(Y_train[val_idx],Y_pred)\n",
    "        list_val_score.append(acc_mean/cv)\n",
    "    return {\"params\":list_hp,\"mean_test_score\":np.array(list_val_score),\"rank_test_score\":rankdata(list_val_score,method='min')}\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Randomized_Cross_val_spectrum(dic_K,Y_train,model,hps,n_iter,cv=5):\n",
    "    CV=StratifiedKFold(cv)\n",
    "    dic_K_prime={k:dic_K[k] for k in hps[\"k\"]}\n",
    "    list_hp=[]\n",
    "    list_val_score=[]\n",
    "    idx_k=list(hps.keys()).index(\"k\")\n",
    "    for keys,values in hps.items():\n",
    "        if isinstance(values,scipy.stats._distn_infrastructure.rv_frozen):\n",
    "            hps[keys]=values.rvs(size=n_iter)\n",
    "        else:\n",
    "            hps[keys]=np.random.choice(values,n_iter)\n",
    "    print(hps)\n",
    "    for i in tqdm(zip(*hps.values())):\n",
    "        \n",
    "        dic_hp={keys:values for keys,values in zip(hps.keys(),i)}\n",
    "        list_hp.append(dic_hp)\n",
    "        \n",
    "        model.set_params(**dic_hp)\n",
    "        acc_mean=0\n",
    "        for train_idx,val_idx in CV.split(X_train,Y_train):\n",
    "            K=dic_K_prime[i[idx_k]]\n",
    "            model.fit(K[train_idx][:,train_idx],Y_train[train_idx])\n",
    "            Y_pred=model.predict(K[val_idx][:,train_idx])\n",
    "            acc_mean+=accuracy_score(Y_train[val_idx],Y_pred)\n",
    "        list_val_score.append(acc_mean/cv)\n",
    "    return {\"params\":list_hp,\"mean_test_score\":np.array(list_val_score),\"rank_test_score\":rankdata(list_val_score,method='min')}\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def présentation_résultat2(search,n):\n",
    "    mask=search['rank_test_score']<=n\n",
    "    params=list(compress(search['params'], list(mask)))\n",
    "    mean_test_score=search['mean_test_score'][mask]\n",
    "    a={}\n",
    "    for i in range(mean_test_score.size):\n",
    "        k=''\n",
    "        for key, value in params[i].items():\n",
    "            k+=\" \"+key+\" \"+str(value)\n",
    "        a.update({k:mean_test_score[i]})\n",
    "        sortedDict = sorted(a.items(), key=lambda x: x[1],reverse=True)\n",
    "    l=[]\n",
    "    for i in sortedDict:\n",
    "        u=i[0].split(sep=' ')\n",
    "        del(u[0])\n",
    "        lp=[]\n",
    "        for j in u[1::2]:\n",
    "            lp.append(j)\n",
    "        lp.append(i[1])\n",
    "        l.append(lp)\n",
    "    head=list(params[0].keys())+[\"mean_test_score\"]\n",
    "\n",
    "    return(pd.DataFrame(l,columns=head))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addbiais(X):\n",
    "    return np.hstack((X,np.ones((X.shape[0],1))))\n",
    "def addzeros(X):\n",
    "    n,_=X.shape\n",
    "    A=np.zeros((n+1,n+1))\n",
    "    A[:n,:n]=X\n",
    "    return(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_file_string_kernel(models,filename): #models is a list of 3 models\n",
    "    Y_test=np.empty(0)\n",
    "    for K_train, Y_train, K_test_train, model  in zip(list_K_train, [Y_0train,Y_1train,Y_2train], list_K_train_test, models):\n",
    "        model.fit(K_train, Y_train)\n",
    "        Y_pred=model.predict(K_test_train)\n",
    "        Y_test=np.concatenate((Y_test,np.where(Y_pred==-1,0,Y_pred)), axis=0)\n",
    "    \n",
    "    Y_test=Y_test.reshape(len(Y_test),1)\n",
    "    \n",
    "    ids=np.arange(Y_test.shape[0])\n",
    "    ids=ids.reshape(len(ids),1)\n",
    "    \n",
    "    df=pd.DataFrame(data=np.concatenate((ids,Y_test), axis=1), columns=['Id','Bound'],dtype=np.int)\n",
    "    \n",
    "    return df.to_csv('Predictions/'+filename, index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.5 Kernel spectrum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_spectrum_kernel(X,Y,k,alphabet=\"ACGT\"):\n",
    "    voc=product(alphabet, repeat=k)\n",
    "    voc=[''.join(elt) for elt in voc]\n",
    "    phi_X=np.vstack(X.apply(lambda x: [x[i:i+k] for i in range(0, len(x)-k+1)]).apply(lambda x: np.array([x.count(v) for v in voc])).to_numpy())\n",
    "    phi_Y=np.vstack(Y.apply(lambda x: [x[i:i+k] for i in range(0, len(x)-k+1)]).apply(lambda x: np.array([x.count(v) for v in voc])).to_numpy())\n",
    "    return phi_X.dot(phi_Y.T)\n",
    "def spectrum_kernel(X,k,alphabet=\"ACGT\"):\n",
    "    voc=product(alphabet, repeat=k)\n",
    "    voc=[''.join(elt) for elt in voc]\n",
    "    phi_X=np.vstack(X.apply(lambda x: [x[i:i+k] for i in range(0, len(x)-k+1)]).apply(lambda x: np.array([x.count(v) for v in voc])).to_numpy())\n",
    "   \n",
    "    return phi_X.dot(phi_X.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Test des différents classifieurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Import des données et précomputation du kernel !!! (étape hyper importante) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0train=pd.read_csv('Data/Xtr0.csv', sep=',')['seq']\n",
    "X_1train=pd.read_csv('Data/Xtr1.csv', sep=',')['seq']\n",
    "X_2train=pd.read_csv('Data/Xtr2.csv', sep=',')['seq']\n",
    "\n",
    "X_0test=pd.read_csv('Data/Xte0.csv', sep=',')['seq']\n",
    "X_1test=pd.read_csv('Data/Xte1.csv', sep=',')['seq']\n",
    "X_2test=pd.read_csv('Data/Xte2.csv', sep=',')['seq']\n",
    "\n",
    "Y_0=pd.read_csv(\"Data/Ytr0.csv\",sep=',')\n",
    "Y_1=pd.read_csv(\"Data/Ytr1.csv\",sep=',')\n",
    "Y_2=pd.read_csv(\"Data/Ytr2.csv\",sep=',')\n",
    "\n",
    "Y_0train=np.where(Y_0[\"Bound\"]==0,-1,Y_0[\"Bound\"])\n",
    "Y_1train=np.where(Y_1[\"Bound\"]==0,-1,Y_1[\"Bound\"])\n",
    "Y_2train=np.where(Y_2[\"Bound\"]==0,-1,Y_2[\"Bound\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_k=[2,3,4,5,6,7,8]\n",
    "dic_K0={k:spectrum_kernel(X_0train,k) for k in tqdm(list_k)}\n",
    "dic_K1={k:spectrum_kernel(X_1train,k) for k in tqdm(list_k)}\n",
    "dic_K2={k:spectrum_kernel(X_2train,k) for k in tqdm(list_k)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Tests de Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Tests de Kernel Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Test de Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KSVM=KernelSVM(kernel=\"precomputed\")\n",
    "print(KSVM)\n",
    "\n",
    "hps0={'C':[10**-2,10**-1,1,10,50,100,500,1000],'k':[2,3,4,5,6,7,8]}\n",
    "searchKSVM0= Cross_val_spectrum(dic_K0,Y_0train,KSVM,hps0)\n",
    "\n",
    "\n",
    "hps1={'C':[10**-2,10**-1,1,10,50,100,500,1000],'k':[2,3,4,5,6,7,8]}\n",
    "searchKSVM1= Cross_val_spectrum(dic_K1,Y_1train,KSVM,hps1)\n",
    "\n",
    "\n",
    "\n",
    "hps2={'C':[10**-2,10**-1,1,10,50,100,500,1000],'k':[2,3,4,5,6,7,8]}\n",
    "searchKSVM2= Cross_val_spectrum(dic_K2,Y_2train,KSVM,hps2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat2(searchKSVM0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat2(searchKSVM1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat2(searchKSVM2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps0={'C':uniform(loc=0.005,scale=0.5),'k':[8]}\n",
    "searchKSVM0= Randomized_Cross_val_spectrum(dic_K0,Y_0train,KSVM,hps0,50)\n",
    "\n",
    "\n",
    "hps1={'C':uniform(loc=0.005,scale=0.5),'k':[5]}\n",
    "searchKSVM1= Randomized_Cross_val_spectrum(dic_K1,Y_1train,KSVM,hps1,50)\n",
    "\n",
    "\n",
    "\n",
    "hps2={'C':uniform(loc=0.005,scale=0.5),'k':[7]}\n",
    "searchKSVM2= Randomized_Cross_val_spectrum(dic_K2,Y_2train,KSVM,hps2,50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat2(searchKSVM0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat2(searchKSVM1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat2(searchKSVM2,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Elaboration du model final et création du fichier csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Precomputation du kernel test_train selon le modèle choisi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_k_chosen=[8,5,7]\n",
    "model0=KernelSVM(C=0.01,k=list_k_chosen[0],kernel=\"precomputed\")\n",
    "model1=KernelSVM(C=0.01,k=list_k_chosen[1],kernel=\"precomputed\")\n",
    "model2=KernelSVM(C=0.01,k=list_k_chosen[2],kernel=\"precomputed\")\n",
    "list_K_train=[dic_K0[list_k_chosen[0]],dic_K1[list_k_chosen[1]],dic_K2[list_k_chosen[2]]]\n",
    "list_K_train_test=[K_spectrum_kernel(X_test,X_train,k) for X_test,X_train,k in tqdm(zip([X_0test,X_1test,X_2test],[X_0train,X_1train,X_2train],list_k_chosen))]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file([model0,model1,model2],filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
