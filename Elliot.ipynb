{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel methods \n",
    "\n",
    "### Import des fonctions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV,StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.linalg import solve,lstsq\n",
    "from scipy.stats import uniform\n",
    "from cvxopt import matrix\n",
    "from cvxopt import solvers\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from itertools import compress, product\n",
    "import numexpr as ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  Bound\n",
       "0        0      0\n",
       "1        1      1\n",
       "2        2      1\n",
       "3        3      1\n",
       "4        4      1\n",
       "...    ...    ...\n",
       "1995  1995      0\n",
       "1996  1996      1\n",
       "1997  1997      0\n",
       "1998  1998      0\n",
       "1999  1999      0\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_0=pd.read_csv(\"/Users/elliotmuller/Documents/M2/Kernel Methods/Data Challenge/Xtr0_mat100.csv\",sep=' ',header=None)\n",
    "X_1=pd.read_csv(\"/Users/elliotmuller/Documents/M2/Kernel Methods/Data Challenge/Xtr1_mat100.csv\",sep=';',header=None)\n",
    "X_2=pd.read_csv(\"/Users/elliotmuller/Documents/M2/Kernel Methods/Data Challenge/Xtr2_mat100.csv\",sep=' ',header=None)\n",
    "\n",
    "\n",
    "Y_0=pd.read_csv(\"/Users/elliotmuller/Documents/M2/Kernel Methods/Data Challenge/Ytr0.csv\",sep=',')\n",
    "Y_1=pd.read_csv(\"/Users/elliotmuller/Documents/M2/Kernel Methods/Data Challenge/Ytr1.csv\",sep=',')\n",
    "Y_2=pd.read_csv(\"/Users/elliotmuller/Documents/M2/Kernel Methods/Data Challenge/Ytr2.csv\",sep=',')\n",
    "\n",
    "Y_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1038\n",
      "1     962\n",
      "Name: Bound, dtype: int64\n",
      "1    1001\n",
      "0     999\n",
      "Name: Bound, dtype: int64\n",
      "0    1003\n",
      "1     997\n",
      "Name: Bound, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Y_0[\"Bound\"].value_counts())\n",
    "print(Y_1[\"Bound\"].value_counts())\n",
    "print(Y_2[\"Bound\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les classes sont plutôt équilibrées "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remplacer les 0 par des -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 100)\n"
     ]
    }
   ],
   "source": [
    "Y_0train=np.where(Y_0[\"Bound\"]==0,-1,Y_0[\"Bound\"])\n",
    "Y_1train=np.where(Y_1[\"Bound\"]==0,-1,Y_1[\"Bound\"])\n",
    "Y_2train=np.where(Y_2[\"Bound\"]==0,-1,Y_2[\"Bound\"])\n",
    "\n",
    "X_0train=X_0.to_numpy()\n",
    "X_1train=X_1.to_numpy()\n",
    "X_2train=X_2.to_numpy()\n",
    "print(X_0train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.141304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.032609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.000000  0.000000  0.010870  0.010870  0.000000  0.021739  0.032609   \n",
       "1     0.010870  0.000000  0.000000  0.000000  0.043478  0.010870  0.010870   \n",
       "2     0.021739  0.000000  0.000000  0.021739  0.000000  0.010870  0.021739   \n",
       "3     0.000000  0.000000  0.000000  0.021739  0.000000  0.010870  0.000000   \n",
       "4     0.000000  0.010870  0.000000  0.010870  0.000000  0.000000  0.010870   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1995  0.010870  0.000000  0.000000  0.000000  0.000000  0.000000  0.010870   \n",
       "1996  0.021739  0.000000  0.000000  0.010870  0.054348  0.010870  0.021739   \n",
       "1997  0.010870  0.000000  0.010870  0.000000  0.000000  0.000000  0.000000   \n",
       "1998  0.021739  0.032609  0.032609  0.010870  0.021739  0.010870  0.010870   \n",
       "1999  0.010870  0.021739  0.021739  0.021739  0.000000  0.010870  0.000000   \n",
       "\n",
       "            7         8         9   ...        90        91        92  \\\n",
       "0     0.021739  0.000000  0.021739  ...  0.000000  0.021739  0.021739   \n",
       "1     0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.021739   \n",
       "2     0.010870  0.000000  0.021739  ...  0.010870  0.010870  0.000000   \n",
       "3     0.010870  0.000000  0.000000  ...  0.021739  0.000000  0.010870   \n",
       "4     0.021739  0.000000  0.021739  ...  0.000000  0.000000  0.010870   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1995  0.032609  0.032609  0.010870  ...  0.000000  0.032609  0.010870   \n",
       "1996  0.010870  0.000000  0.000000  ...  0.010870  0.000000  0.010870   \n",
       "1997  0.000000  0.054348  0.043478  ...  0.010870  0.010870  0.000000   \n",
       "1998  0.032609  0.000000  0.032609  ...  0.000000  0.032609  0.010870   \n",
       "1999  0.010870  0.000000  0.010870  ...  0.000000  0.010870  0.010870   \n",
       "\n",
       "            93        94        95        96        97        98        99  \n",
       "0     0.065217  0.000000  0.000000  0.032609  0.043478  0.021739  0.010870  \n",
       "1     0.021739  0.010870  0.000000  0.000000  0.032609  0.021739  0.010870  \n",
       "2     0.010870  0.000000  0.000000  0.021739  0.000000  0.021739  0.010870  \n",
       "3     0.010870  0.000000  0.000000  0.010870  0.010870  0.021739  0.000000  \n",
       "4     0.000000  0.000000  0.000000  0.000000  0.010870  0.021739  0.010870  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1995  0.010870  0.021739  0.021739  0.000000  0.000000  0.010870  0.021739  \n",
       "1996  0.021739  0.010870  0.000000  0.000000  0.043478  0.010870  0.010870  \n",
       "1997  0.000000  0.010870  0.141304  0.000000  0.021739  0.032609  0.032609  \n",
       "1998  0.000000  0.000000  0.000000  0.021739  0.021739  0.000000  0.010870  \n",
       "1999  0.032609  0.010870  0.000000  0.021739  0.010870  0.010870  0.010870  \n",
       "\n",
       "[2000 rows x 100 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression ( équivalent à Kernel ridge régression avec noyau linéaire) \n",
    "On ajoute une colonne de biais "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0train_forRR=np.hstack((np.ones((X_0train.shape[0],1)),X_0train))\n",
    "X_1train_forRR=np.hstack((np.ones((X_0train.shape[0],1)),X_0train))\n",
    "X_2train_forRR=np.hstack((np.ones((X_0train.shape[0],1)),X_0train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solver ridge Regression \n",
    "Même si les classes sont équilibrées je laisse la possibilité de modifier les poids. Enfin pas vraiment puisque le seul poids que je met quand on souhaite en mettre c'est le poid correspondant au poids des classes dans le set qui sera entraîné.\n",
    "J'utilisais lstsq pour résoudre le système lineaire car plus stable si la matrice est mal conditionné/pas inversible mais cela prend beaucoup plus de temps que solve, ducoup je suis repassé à solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ridge_Regresssion(X_train,y_train,lbd,weight=False):\n",
    "    n=y_train.shape[0]\n",
    "    d=X_train.shape[1]\n",
    "    if not(weight):\n",
    "        A=(X_train.T.dot(X_train))/n+lbd*np.eye(d)\n",
    "        B=X_train.T.dot(y_train)/n\n",
    "        theta=solve(A,B)\n",
    "        return theta\n",
    "    else:\n",
    "        w1=(y_train==1).mean()\n",
    "        w0=1-w1\n",
    "        w=np.where(y_train==1,w1,w0)\n",
    "        W=np.diag(w)\n",
    "        A=(X_train.T.dot(W.dot(X_train)))/n+lbd*np.eye(d)\n",
    "        B=X_train.T.dot(W.dot(y_train))/n\n",
    "        theta=solve(A,B)\n",
    "        return theta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Création de l'estimateur Ridge regression compatible avec l'API de scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRR(BaseEstimator,ClassifierMixin):\n",
    "    def __init__(self,lbd=1,weight=False):\n",
    "        self.lbd=lbd\n",
    "        self.weight=weight\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        \n",
    "        self.theta=Ridge_Regresssion(X,y,self.lbd,self.weight)\n",
    "        return self\n",
    "    def decision_function(self,X):\n",
    "        return X.dot(self.theta)\n",
    "        \n",
    "    def predict(self,X,y=None):\n",
    "        scores=self.decision_function(X)\n",
    "        if len(scores.shape) == 1:\n",
    "            indices = (scores > 0).astype(np.int)\n",
    "        else:\n",
    "            indices = scores.argmax(axis=1)\n",
    "        return self.classes_[indices]\n",
    "   \n",
    "    def get_params(self, deep=True):\n",
    "    \n",
    "        return {\"lbd\": self.lbd,\"weight\":self.weight}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction permettant d'afficher les n meilleurs résultats avec les paramètres associées d'une grid search dans un tableau (dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def présentation_résultat(search,n):\n",
    "    mask=search.cv_results_['rank_test_score']<=n\n",
    "    params=list(compress(search.cv_results_['params'], list(mask)))\n",
    "    mean_test_score=search.cv_results_['mean_test_score'][mask]\n",
    "    a={}\n",
    "    for i in range(mean_test_score.size):\n",
    "        k=''\n",
    "        for key, value in params[i].items():\n",
    "            k+=\" \"+key+\" \"+str(value)\n",
    "        a.update({k:mean_test_score[i]})\n",
    "        sortedDict = sorted(a.items(), key=lambda x: x[1],reverse=True)\n",
    "    l=[]\n",
    "    for i in sortedDict:\n",
    "        u=i[0].split(sep=' ')\n",
    "        del(u[0])\n",
    "        lp=[]\n",
    "        for j in u[1::2]:\n",
    "            lp.append(j)\n",
    "        lp.append(i[1])\n",
    "        l.append(lp)\n",
    "    head=list(params[0].keys())+[\"mean_test_score\"]\n",
    "\n",
    "    return(pd.DataFrame(l,columns=head))\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Première recherche des hyperparamètres pour chaque train set \n",
    "Je crée un pipeline composé d'un transformer de données et de la ridge regression. Dans la manière dont j'ai défini la pipeline le transformer en question est *StandardScaler()* qui standardise les données ((X-mean)/std)). Attention cela standardise les données selon la mean et std du train set et donc lors d'une prédiction le test/validation set sera standardisé par rapport à la mean et std du training set. \n",
    "En soit la manière dont j'ai défini le tranformeur n'a pas d'importance car dans la gridSearch je teste d'autres transformeur à certain moment(mais fallait bien en mettre pour faire la pipeline), il y a même une option *\"passthrough\"* pour la première étape de la pipeline qui veut dire tout simplement passer à l'étape suivante et donc ne pas transfomrer mes données.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('preprocess', StandardScaler()), ('linearrr', LinearRR())])\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 320 out of 320 | elapsed:    9.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 320 out of 320 | elapsed:    9.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 320 out of 320 | elapsed:    8.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocess', StandardScaler()),\n",
       "                                       ('linearrr', LinearRR())]),\n",
       "             param_grid={'linearrr__lbd': [1e-06, 1e-05, 0.0001, 0.001, 0.01,\n",
       "                                           0.1, 1, 10],\n",
       "                         'linearrr__weight': [False, True],\n",
       "                         'preprocess': ['passthrough', StandardScaler(),\n",
       "                                        RobustScaler(), MinMaxScaler()]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RR=Pipeline([(\"preprocess\",StandardScaler()),(\"linearrr\",LinearRR())])\n",
    "print(RR)\n",
    "\n",
    "hps0={\"linearrr__lbd\":[10**-6,10**-5,10**-4,10**-3,10**-2,10**-1,1,10],\"linearrr__weight\":[False,True],\n",
    "     \"preprocess\":[\"passthrough\",StandardScaler(),RobustScaler(),MinMaxScaler()]}\n",
    "searchLRR0= GridSearchCV(RR,hps0,scoring=\"accuracy\",cv=5,verbose=1)\n",
    "searchLRR0.fit(X_0train_forRR, Y_0train)\n",
    "\n",
    "hps1={\"linearrr__lbd\":[10**-6,10**-5,10**-4,10**-3,10**-2,10**-1,1,10],\"linearrr__weight\":[False,True],\n",
    "     \"preprocess\":[\"passthrough\",StandardScaler(),RobustScaler(),MinMaxScaler()]}\n",
    "searchLRR1= GridSearchCV(RR,hps1,scoring=\"accuracy\",cv=5,verbose=1)\n",
    "searchLRR1.fit(X_1train_forRR, Y_1train)\n",
    "\n",
    "\n",
    "hps2={\"linearrr__lbd\":[10**-6,10**-5,10**-4,10**-3,10**-2,10**-1,1,10],\"linearrr__weight\":[False,True],\n",
    "     \"preprocess\":[\"passthrough\",StandardScaler(),RobustScaler(),MinMaxScaler()]}\n",
    "searchLRR2= GridSearchCV(RR,hps2,scoring=\"accuracy\",cv=5,verbose=1)\n",
    "searchLRR2.fit(X_2train_forRR, Y_2train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage des résulats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linearrr__lbd</th>\n",
       "      <th>linearrr__weight</th>\n",
       "      <th>preprocess</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>0.5975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>0.5945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>True</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>0.5940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>False</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.5930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>0.5905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.5890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.01</td>\n",
       "      <td>False</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>0.5885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.01</td>\n",
       "      <td>True</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>0.5870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>0.5865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1e-06</td>\n",
       "      <td>True</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>0.5860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1e-05</td>\n",
       "      <td>True</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>0.5860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>0.5860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.001</td>\n",
       "      <td>False</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>0.5860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   linearrr__lbd linearrr__weight        preprocess  mean_test_score\n",
       "0              1             True  StandardScaler()           0.5975\n",
       "1              1            False  StandardScaler()           0.5945\n",
       "2            0.1             True  StandardScaler()           0.5940\n",
       "3           0.01            False    MinMaxScaler()           0.5930\n",
       "4            0.1            False  StandardScaler()           0.5905\n",
       "5          0.001             True    MinMaxScaler()           0.5890\n",
       "6           0.01            False  StandardScaler()           0.5885\n",
       "7           0.01             True  StandardScaler()           0.5870\n",
       "8          0.001             True  StandardScaler()           0.5865\n",
       "9          1e-06             True  StandardScaler()           0.5860\n",
       "10         1e-05             True  StandardScaler()           0.5860\n",
       "11        0.0001             True  StandardScaler()           0.5860\n",
       "12         0.001            False  StandardScaler()           0.5860"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "présentation_résultat(searchLRR0,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linearrr__lbd</th>\n",
       "      <th>linearrr__weight</th>\n",
       "      <th>preprocess</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>0.5150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>True</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.5150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>0.5135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.5130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.5130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.5125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.01</td>\n",
       "      <td>True</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>0.5125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>0.5110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>0.5110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001</td>\n",
       "      <td>False</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>0.5090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.5090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   linearrr__lbd linearrr__weight        preprocess  mean_test_score\n",
       "0            0.1            False       passthrough           0.5150\n",
       "1            0.1             True    MinMaxScaler()           0.5150\n",
       "2             10             True  StandardScaler()           0.5135\n",
       "3              1             True    MinMaxScaler()           0.5130\n",
       "4             10             True    MinMaxScaler()           0.5130\n",
       "5              1            False    MinMaxScaler()           0.5125\n",
       "6           0.01             True       passthrough           0.5125\n",
       "7              1             True    RobustScaler()           0.5110\n",
       "8             10            False  StandardScaler()           0.5110\n",
       "9          0.001            False       passthrough           0.5090\n",
       "10           0.1            False    MinMaxScaler()           0.5090"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "présentation_résultat(searchLRR1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linearrr__lbd</th>\n",
       "      <th>linearrr__weight</th>\n",
       "      <th>preprocess</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>True</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>0.5015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>True</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>0.5015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>0.5015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>0.5015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>0.5015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>0.5015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.5010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>0.5005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>0.4995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001</td>\n",
       "      <td>False</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>0.4980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  linearrr__lbd linearrr__weight        preprocess  mean_test_score\n",
       "0          0.01             True       passthrough           0.5015\n",
       "1           0.1             True       passthrough           0.5015\n",
       "2             1            False       passthrough           0.5015\n",
       "3             1             True       passthrough           0.5015\n",
       "4            10            False       passthrough           0.5015\n",
       "5            10             True       passthrough           0.5015\n",
       "6            10             True    MinMaxScaler()           0.5010\n",
       "7           0.1            False       passthrough           0.5005\n",
       "8            10             True  StandardScaler()           0.4995\n",
       "9         0.001            False       passthrough           0.4980"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "présentation_résultat(searchLRR2,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche plus fine dans les zones d'intérêts déterminés à l'aide la search précedente\n",
    "\n",
    "Ici je fais une RandomizedGrid search car j'ai beaucoup plus d'informations sur les zones d'intérêts où il faut chercher(notamment pour le lambda). Si je l'avais fait avant étant donné que j'avais aucun à priori sur la valeur de lambda la recherche au hasard aurait été plus difficile. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-97b06a86361b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhps0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"linearrr__lbd\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"linearrr__weight\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msearchLRR0\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhps0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msearchLRR0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_0train_forRR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_0train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m hps1={\"linearrr__lbd\":uniform(loc=0.05,scale=15),\"linearrr__weight\":[False,True],\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1527\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1528\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m         evaluate_candidates(ParameterSampler(\n\u001b[0m\u001b[1;32m   1530\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m             random_state=self.random_state))\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    864\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-f41dbdd24eb6>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRidge_Regresssion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlbd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-e6f9bde84fbc>\u001b[0m in \u001b[0;36mRidge_Regresssion\u001b[0;34m(X_train, y_train, lbd, weight)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mW\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlbd\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mB\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtheta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "hps0={\"linearrr__lbd\":uniform(loc=0.005,scale=5),\"linearrr__weight\":[False,True]}\n",
    "searchLRR0= RandomizedSearchCV(RR,hps0,n_iter=500,scoring=\"accuracy\",cv=5,verbose=1)\n",
    "searchLRR0.fit(X_0train_forRR, Y_0train)\n",
    "\n",
    "hps1={\"linearrr__lbd\":uniform(loc=0.05,scale=15),\"linearrr__weight\":[False,True],\n",
    "     \"preprocess\":[\"passthrough\",StandardScaler(),RobustScaler(),MinMaxScaler()]}\n",
    "searchLRR1= RandomizedSearchCV(RR,hps1,n_iter=1000,scoring=\"accuracy\",cv=5,verbose=1)\n",
    "searchLRR1.fit(X_1train_forRR, Y_1train)\n",
    "\n",
    "\n",
    "hps2={\"linearrr__lbd\":uniform(loc=0.005,scale=15),\"linearrr__weight\":[False,True],\n",
    "     \"preprocess\":[\"passthrough\"]}\n",
    "searchLRR2= RandomizedSearchCV(RR,hps2,n_iter=500,scoring=\"accuracy\",cv=5,verbose=1)\n",
    "searchLRR2.fit(X_2train_forRR, Y_2train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Présentation des résultats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchLRR0,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linearrr__lbd</th>\n",
       "      <th>linearrr__weight</th>\n",
       "      <th>preprocess</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.662814399357097</td>\n",
       "      <td>True</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.5165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.63118211054454</td>\n",
       "      <td>True</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.5160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.022893011897496</td>\n",
       "      <td>True</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.5155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.034094985975762</td>\n",
       "      <td>True</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.5155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.786563568420897</td>\n",
       "      <td>True</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.5155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.591061637065799</td>\n",
       "      <td>True</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.5155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.777275514245422</td>\n",
       "      <td>True</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.5155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.419640410398476</td>\n",
       "      <td>True</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.5155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.7804350268823796</td>\n",
       "      <td>True</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.5155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.229126490300691</td>\n",
       "      <td>True</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.5150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.181950936634552</td>\n",
       "      <td>True</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.5150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.2099383327999425</td>\n",
       "      <td>True</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.5150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         linearrr__lbd linearrr__weight      preprocess  mean_test_score\n",
       "0    2.662814399357097             True  MinMaxScaler()           0.5165\n",
       "1     1.63118211054454             True  MinMaxScaler()           0.5160\n",
       "2    6.022893011897496             True  MinMaxScaler()           0.5155\n",
       "3    5.034094985975762             True  MinMaxScaler()           0.5155\n",
       "4    2.786563568420897             True  MinMaxScaler()           0.5155\n",
       "5    5.591061637065799             True  MinMaxScaler()           0.5155\n",
       "6    2.777275514245422             True  MinMaxScaler()           0.5155\n",
       "7    5.419640410398476             True  MinMaxScaler()           0.5155\n",
       "8   2.7804350268823796             True  MinMaxScaler()           0.5155\n",
       "9    6.229126490300691             True  MinMaxScaler()           0.5150\n",
       "10   6.181950936634552             True  MinMaxScaler()           0.5150\n",
       "11  6.2099383327999425             True  MinMaxScaler()           0.5150"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "présentation_résultat(searchLRR1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linearrr__lbd</th>\n",
       "      <th>linearrr__weight</th>\n",
       "      <th>preprocess</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.061342756436065786</td>\n",
       "      <td>False</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>0.5035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.019400442629027844</td>\n",
       "      <td>True</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>0.5025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          linearrr__lbd linearrr__weight   preprocess  mean_test_score\n",
       "0  0.061342756436065786            False  passthrough           0.5035\n",
       "1  0.019400442629027844             True  passthrough           0.5025"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "présentation_résultat(searchLRR2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche encore plus fine (sert pas trop à grand chose car on va garder ce modèle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps0={\"linearrr__lbd\":uniform(loc=0.8,scale=1.2),\"linearrr__weight\":[False]}\n",
    "searchLRR0= RandomizedSearchCV(RR,hps0,n_iter=100,scoring=\"accuracy\",cv=5,verbose=1)\n",
    "searchLRR0.fit(X_0train_forRR, Y_0train)\n",
    "\n",
    "hps1={\"linearrr__lbd\":uniform(loc=0.01,scale=1.5),\"linearrr__weight\":[False],\n",
    "     \"preprocess\":[\"passthrough\"]}\n",
    "searchLRR1= RandomizedSearchCV(RR,hps1,n_iter=100,scoring=\"accuracy\",cv=5,verbose=1)\n",
    "searchLRR1.fit(X_1train_forRR, Y_1train)\n",
    "\n",
    "\n",
    "hps2={\"linearrr__lbd\":uniform(loc=0.005,scale=0.1),\"linearrr__weight\":[False],\n",
    "     \"preprocess\":[\"passthrough\"]}\n",
    "searchLRR2= RandomizedSearchCV(RR,hps2,n_iter=100,scoring=\"accuracy\",cv=5,verbose=1)\n",
    "searchLRR2.fit(X_2train_forRR, Y_2train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Présentation des résultats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchLRR0,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchLRR1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchLRR2,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Ridge regression \n",
    "\n",
    "### Crétion du kernel de manière efficiente voir ce lien pour comprendre https://stackoverflow.com/questions/47271662/what-is-the-fastest-way-to-compute-an-rbf-kernel-in-python \n",
    "Mais ce qu'il y a retenir c'est que $\\| x-y \\|^2=\\|x\\|^2 + \\|y\\|^2 -2x^Ty$ et d'utiliser à son avantage le broadcast de Numpy. Le ne.evaluate est là pour rendre l'opération plus rapide mais l'opération qui est faite et bien \"exp(-g*(A+B-2*C))\" Avec les A B C g correspondant. D'ailleurs la propriété précédente nous permet de manière générale de calculer la matrice $K(x_i,y_i)$ pour $y_1,\\dots,y_k ~~x_1,\\dots,x_n$  $y_i,x_i \\in R^d$ La kernel matrice et un cas particulier où $n=k$ et $x_i=y_i$ pour tout $i$.\n",
    "Cette fonction est contruite juste après la fonction qui construit la kernel matrice. Elle nous sera très utile en espérant que vous aviez déjà deviné pourquoi, c'est pour  calculer $\\left(f(z_1),\\dots,f(z_k)\\right)$ oû $f(z_j)=\\sum_{i=1}^{n}\\alpha_i K(z_j,x_i)$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_kernel(X_train,gamma):\n",
    "    X_norm = np.sum(X_train ** 2, axis = -1)\n",
    "    K = ne.evaluate('exp(-g * (A + B - 2 * C))', {\n",
    "        'A' : X_norm[:,None],\n",
    "        'B' : X_norm[None,:],\n",
    "        'C' : np.dot(X_train, X_train.T),\n",
    "        'g' : gamma,\n",
    "    })\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_rbf_kernel(X_test,X_train,gamma):\n",
    "   \n",
    "    Xtt_norm = np.sum(X_test ** 2, axis = -1)\n",
    "    Xtr_norm = np.sum(X_train ** 2, axis = -1)\n",
    "    K = ne.evaluate('exp(-g * (A + B - 2 * C))', {\n",
    "        'A' : Xtt_norm[:,None],\n",
    "        'B' : Xtr_norm[None,:],\n",
    "        'C' : np.dot(X_test, X_train.T),\n",
    "        'g' : gamma,\n",
    "    })\n",
    "    return K\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_kernel(X,Y,degree,c0):\n",
    "    return (X.dot(Y.T)+c0)**degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addbiais(X):\n",
    "    return np.hstack((X,np.ones((X.shape[0],1))))\n",
    "def addzeros(X):\n",
    "    n,_=X.shape\n",
    "    A=np.zeros((n+1,n+1))\n",
    "    A[:n,:n]=X\n",
    "    return(A)\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du solver Kernel ridge regresion\n",
    "\n",
    "Comme vous l'avez remarqué je laisse la possibilité d'ajouter un paramètre de biais à l'estimateur ($f(x)=\\sum_{i=1}^{n}K(xi,x)\\,+b)$ mais qui n'est pas pénalisé!! car cela aurait aucun sens. Cela mène bien au système d'équation que je résouds dans la partie *bais* du solver qui suit, vérifier à la main si vous n'êtes pas convaincu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kernel_Ridge_Regression(X_train,y_train,lbd,weight,gamma,degree,c0,k,biais,kernel):\n",
    "    if kernel==\"rbf\":\n",
    "        K=rbf_kernel(X_train,gamma)\n",
    "    elif kernel==\"poly\":\n",
    "        K=poly_kernel(X_train,X_train,degree,c0)\n",
    "    elif kernel==\"spectrum\":\n",
    "        K=spectrum_kernel(X_train,k)\n",
    "    elif kernel==\"precomputed\":\n",
    "        K=X_train\n",
    "    n=K.shape[0]\n",
    "    w=weight\n",
    "    if not(biais):\n",
    "        if isinstance(weight,bool):\n",
    "            A=(K+n*lbd*np.eye(n))\n",
    "            alpha=solve(A,y_train,assume_a=\"sym\")\n",
    "            return alpha\n",
    "        elif isinstance(weight,str):\n",
    "                w1=(y_train==1).mean()\n",
    "                w0=1-w1\n",
    "                w=np.where(y_train==1,w1,w0)\n",
    "        wi=(1/w)\n",
    "        \n",
    "        A=K+n*lbd*wi*np.eye(n)\n",
    "        alpha=solve(A,y_train,assume_a=\"sym\")\n",
    "     \n",
    "        return alpha\n",
    "    else:\n",
    "        \n",
    "        Kb=addbiais(K)\n",
    "        \n",
    "        K0=addzeros(K)\n",
    "    \n",
    "        if isinstance(weight,bool):\n",
    "            A=(Kb.T.dot(Kb)+lbd*n*K0)\n",
    "            B=Kb.T.dot(y_train)\n",
    "            alpha=solve(A,B,assume_a=\"sym\")\n",
    "            return alpha\n",
    "        elif isinstance(weight,str):\n",
    "                w1=(y_train==1).mean()\n",
    "                w0=1-w1\n",
    "                w=np.where(y_train==1,w1,w0)\n",
    "        W=np.diag(w)\n",
    "        A=(Kb.T.dot(W.dot(Kb))+lbd*n*K0)\n",
    "        B=Kb.T.dot(W.dot(y_train),assume_a=\"sym\")\n",
    "        alpha=solve(A,B)\n",
    "        return alpha\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de l'estimateur compatible avec l'Api de scikit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelRR(BaseEstimator,ClassifierMixin):\n",
    "    def __init__(self,lbd=1,weight=False,gamma=\"auto\",degree=2,c0=1,k=3,biais=False,kernel=\"rbf\"):\n",
    "        self.lbd=lbd\n",
    "        self.weight=weight\n",
    "        self.gamma=gamma\n",
    "        self.degree=degree\n",
    "        self.c0=c0\n",
    "        self.k=k\n",
    "        self.biais=biais\n",
    "        self.kernel=kernel\n",
    "    def fit(self,X,y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.Xtr=X\n",
    "        if isinstance(self.gamma,str) and self.kernel==\"rbf\":\n",
    "            self.gamma=1/self.Xtr.shape[1]\n",
    "        self.alpha=Kernel_Ridge_Regression(X,y,self.lbd,self.weight,self.gamma,self.degree,self.c0,self.k,self.biais,self.kernel)\n",
    "        return self\n",
    "    def decision_function(self,X):\n",
    "        if self.kernel==\"precomputed\":\n",
    "            return X.dot(self.alpha)\n",
    "        if not(self.biais):\n",
    "            if self.kernel==\"rbf\":\n",
    "                return K_rbf_kernel(X,self.Xtr,self.gamma).dot(self.alpha) \n",
    "            elif self.kernel==\"poly\":\n",
    "                return poly_kernel(X,self.Xtr,self.degree,self.c0).dot(self.alpha) \n",
    "            elif self.kernel==\"spectrum\":\n",
    "                return K_spectrum_kernel(X,self.Xtr,self.k).dot(self.alpha) \n",
    "        else:\n",
    "            if self.kernel==\"rbf\":\n",
    "                return addbiais(K_rbf_kernel(X,self.Xtr,self.gamma)).dot(self.alpha)\n",
    "            elif self.kernel==\"poly\":\n",
    "                return addbiais(poly_kernel(X,self.Xtr,self.degree,self.c0)).dot(self.alpha)\n",
    "            elif self.kernel==\"spectrum\":\n",
    "                return addbiais(K_spectrum_kernel(X,self.Xtr,self.k)).dot(self.alpha)\n",
    "\n",
    "    def predict(self,X,y=None):\n",
    "        scores=self.decision_function(X)\n",
    "        if len(scores.shape) == 1:\n",
    "            indices = (scores > 0).astype(np.int)\n",
    "        else:\n",
    "            indices = scores.argmax(axis=1)\n",
    "        return self.classes_[indices]\n",
    "   \n",
    "    def get_params(self, deep=True):\n",
    "    \n",
    "        return {\"lbd\": self.lbd,\"weight\":self.weight,\"gamma\":self.gamma,\"degree\":self.degree,\"c0\":self.c0,\"k\":self.k,\n",
    "                \"biais\":self.biais,\"kernel\":self.kernel}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche des hyperparamètres pour KRR avec noyau gaussien \n",
    "Pour la transformation des données ici vu qu'on va ensuite appliqué un kernel qui va rédéfinir les distance entre le points la seul transformation qui à un sens est celle où l'on standardise les données car elle conserve les rapports de distance(et donc pas affecté le kernel). De plus point très important, le paramètre *gamma* du noyau et *lambda* de la régularisation peuvent ne pas jouer de pair dans la performance de l'estimateur, il est donc difficile d'optimiser à la fois *lambda* et *gamma*. Effectivement il est possible que pour un *gamma* haut on ait besoin d'un *lambda* bas pour performer et inversement et comme on ne veut pas se perdre dans différents chemins, il semble logique de fixer *gamma* puis d'optimer *lambda*. Cela tombe bien puisque sans rentrer dans les détails mais lorsque que les données sont standardisées un paramètre de *gamma* naturel est 1/(num_features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('standardscaler', StandardScaler()), ('kernelrr', KernelRR())])\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    9.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    7.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    6.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                                       ('kernelrr', KernelRR())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'kernelrr__lbd': [1e-06, 1e-05, 0.0001, 0.001, 0.01,\n",
       "                                           0.1, 1, 10]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KRR=make_pipeline(StandardScaler(),KernelRR(kernel=\"rbf\"))\n",
    "print(KRR)\n",
    "\n",
    "hps0={'kernelrr__lbd':[10**-6,10**-5,10**-4,10**-3,10**-2,10**-1,1,10]}\n",
    "searchKRR0= GridSearchCV(KRR,hps0,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKRR0.fit(X_0train, Y_0train)\n",
    "\n",
    "hps1={\"kernelrr__lbd\":[10**-6,10**-5,10**-4,10**-3,10**-2,10**-1,1,10]}\n",
    "searchKRR1= GridSearchCV(KRR,hps1,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKRR1.fit(X_1train, Y_1train)\n",
    "\n",
    "\n",
    "hps2={\"kernelrr__lbd\":[10**-6,10**-5,10**-4,10**-3,10**-2,10**-1,1,10]}\n",
    "searchKRR2= GridSearchCV(KRR,hps2,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKRR2.fit(X_2train, Y_2train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Présentation des Résultats \n",
    "On remarque pour le training set 1 on a 10% en plus 20% en plus!!! pour le training set 2 et rien ne change pour le training set 0 par rapport au modèle linéraire. A Approfondir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernelrr__lbd</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.5885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.5830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1e-06</td>\n",
       "      <td>0.5825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>0.5225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kernelrr__lbd  mean_test_score\n",
       "0         0.001           0.5995\n",
       "1          0.01           0.5910\n",
       "2        0.0001           0.5885\n",
       "3         1e-05           0.5830\n",
       "4         1e-06           0.5825\n",
       "5           0.1           0.5480\n",
       "6             1           0.5260\n",
       "7            10           0.5225"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "présentation_résultat(searchKRR0,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernelrr__lbd</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.6055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.5990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.5865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1e-06</td>\n",
       "      <td>0.5820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>0.5255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kernelrr__lbd  mean_test_score\n",
       "0         0.001           0.6055\n",
       "1        0.0001           0.5990\n",
       "2          0.01           0.5915\n",
       "3         1e-05           0.5865\n",
       "4         1e-06           0.5820\n",
       "5           0.1           0.5530\n",
       "6            10           0.5255\n",
       "7             1           0.5255"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "présentation_résultat(searchKRR1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernelrr__lbd</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.7100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.6895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1e-06</td>\n",
       "      <td>0.6765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.6765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>0.6545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.6530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kernelrr__lbd  mean_test_score\n",
       "0         0.001           0.7100\n",
       "1          0.01           0.6950\n",
       "2        0.0001           0.6895\n",
       "3         1e-06           0.6765\n",
       "4         1e-05           0.6765\n",
       "5           0.1           0.6685\n",
       "6            10           0.6545\n",
       "7             1           0.6530"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "présentation_résultat(searchKRR2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('standardscaler', StandardScaler()), ('kernelrr', KernelRR())])\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   32.7s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2500 out of 2500 | elapsed:  7.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   37.9s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.4min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-cf25073128ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mhps1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"kernelrr__lbd\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msearchKRR1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKRR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhps1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0msearchKRR1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_1train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_1train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1527\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1528\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m         evaluate_candidates(ParameterSampler(\n\u001b[0m\u001b[1;32m   1530\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m             random_state=self.random_state))\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "KRR=make_pipeline(StandardScaler(),KernelRR(weight=False,gamma=\"auto\",kernel=\"rbf\"))\n",
    "print(KRR)\n",
    "\n",
    "hps0={\"kernelrr__lbd\":uniform(loc=10**-4,scale=5*10**-2)}\n",
    "searchKRR0= RandomizedSearchCV(KRR,hps0,n_iter=500,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKRR0.fit(X_0train, Y_0train)\n",
    "\n",
    "hps1={\"kernelrr__lbd\":uniform(loc=5*10**-5,scale=5*10**-2)}\n",
    "searchKRR1=RandomizedSearchCV(KRR,hps1,n_iter=500,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKRR1.fit(X_1train, Y_1train)\n",
    "\n",
    "\n",
    "hps2={\"kernelrr__lbd\":uniform(loc=5*10**-5,scale=5*10**-2)}\n",
    "searchKRR2= RandomizedSearchCV(KRR,hps2,n_iter=100,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKRR2.fit(X_2train, Y_2train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Présentation des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKRR0,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKRR1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKRR2,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(v):\n",
    "    return 1/(1+np.exp(-v))\n",
    "def log_loss(v):\n",
    "    return np.log(1+np.exp(-v))\n",
    "def cross_loss(y,v):\n",
    "    return -(y*np.log(v)+(1-y)*np.log(1-v))\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solver Kernel Logistic Regression \n",
    "\n",
    "Le critère d'arrêt que j'ai mis c'est quand la différence deux itétéres consécutifs a une norme inférieure à $\\epsilon$. Ici aussi je laisse la possibilité d'un biais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IRLS(X_train,y_train,lbd,ga,degree,c0,k,bs,ker,n_iter,eps=10**-6,method='slow'):\n",
    "    n=y_train.shape[0]\n",
    "  \n",
    "    if ker==\"rbf\":\n",
    "        K=rbf_kernel(X_train,ga)\n",
    "    elif ker==\"poly\":\n",
    "        K=poly_kernel(X_train,X_train,degree,c0)\n",
    "    elif ker==\"spectrum\":\n",
    "        K=spectrum_kernel(X_train,k)\n",
    "    elif ker==\"precomputed\":\n",
    "        K=X_train\n",
    "    #alpha=Kernel_Ridge_Regression(K,y_train,lbd,False,1,bs,\"precomputed\")\n",
    "    #alpha=np.zeros(n)\n",
    "    #l=[]\n",
    "  \n",
    "    if bs :\n",
    "        Kb=addbiais(K)\n",
    "        K0=addzeros(K)\n",
    "        alpha=np.zeros(n+1)\n",
    "    else:\n",
    "        alpha=np.zeros(n)\n",
    "    for i in range(n_iter):\n",
    "   \n",
    "        alpha_old=alpha\n",
    "       \n",
    "        if bs:\n",
    "            m=Kb.dot(alpha)\n",
    "            #l.append(log_loss(y_train*m).mean()+lbd*alpha[:-1].dot(K.dot(alpha[:-1])))\n",
    "        \n",
    "        else:\n",
    "            m=K.dot(alpha)\n",
    "            #l.append(log_loss(y_train*m).mean()+lbd*alpha.dot(m))\n",
    "        \n",
    "        \n",
    "        p=sigmoid(m)\n",
    "       \n",
    "        weight=p*(1-p)\n",
    "       \n",
    "        weight=np.where(weight<0.000001,0.000001,weight)\n",
    "       \n",
    "   \n",
    "        u=np.where(sigmoid(y_train*m)<0.000001,0.000001,sigmoid(y_train*m))\n",
    "        z = m + y_train/u\n",
    "    \n",
    "        if not(bs):\n",
    "        \n",
    "            S = np.diag(weight**-1)\n",
    "            A=(K+2*lbd*n*S)\n",
    "            alpha=solve(A,z,assume_a=\"sym\")\n",
    "            \n",
    "            #print(np.linalg.norm(alpha_old-alpha))\n",
    "            \n",
    "            if np.linalg.norm(alpha_old-alpha)<eps:\n",
    "                break\n",
    "        else:\n",
    "            S = np.diag(weight)\n",
    "            A=(Kb.T.dot(S.dot(Kb))+2*lbd*n*K0)\n",
    "            B=Kb.T.dot(S.dot(z))\n",
    "            if method==\"slow\":\n",
    "                alpha=lstsq(A,B)[0]\n",
    "            else:\n",
    "                alpha=solve(A,B,assume_a=\"sym\")\n",
    "            #print(np.linalg.norm(alpha_old-alpha))\n",
    "            if np.linalg.norm(alpha_old-alpha)<eps:\n",
    "                break\n",
    "                \n",
    "       \n",
    "    return alpha #,l\n",
    "        \n",
    "#with np.printoptions(threshold=np.inf):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Je construit l'estimateur compatible avec l'API de scikit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelLR(BaseEstimator,ClassifierMixin):\n",
    "    def __init__(self,lbd=1,gamma='auto',degree=2,c0=1,k=3,biais=False,kernel=\"rbf\",n_iter=15,method=\"slow\"):\n",
    "        self.lbd=lbd\n",
    "        self.gamma=gamma\n",
    "        self.degree=degree\n",
    "        self.c0=c0\n",
    "        self.k=k\n",
    "        self.biais=biais\n",
    "        self.kernel=kernel\n",
    "        self.n_iter=n_iter\n",
    "        self.method=method\n",
    "    def fit(self,X,y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.Xtr=X\n",
    "        if isinstance(self.gamma,str) and self.kernel==\"rbf\":\n",
    "            self.gamma=1/self.Xtr.shape[1]\n",
    "        self.alpha=IRLS(X,y,self.lbd,self.gamma,self.degree,self.c0,self.k,self.biais,self.kernel,self.n_iter,method=self.method)\n",
    "        return self\n",
    "    def decision_function(self,X):\n",
    "        if not(self.biais):\n",
    "            if self.kernel==\"precomputed\":\n",
    "                return X.dot(self.alpha)\n",
    "            if self.kernel==\"rbf\":\n",
    "                return K_rbf_kernel(X,self.Xtr,self.gamma).dot(self.alpha) \n",
    "            elif self.kernel==\"poly\":\n",
    "                return poly_kernel(X,self.Xtr,self.degree,self.c0).dot(self.alpha) \n",
    "            elif self.kernel==\"spectrum\":\n",
    "                return K_spectrum_kernel(X,self.Xtr,self.k).dot(self.alpha) \n",
    "        else:\n",
    "            if self.kernel==\"rbf\":\n",
    "                return addbiais(K_rbf_kernel(X,self.Xtr,self.gamma)).dot(self.alpha)\n",
    "            elif self.kernel==\"poly\":\n",
    "                return addbiais(poly_kernel(X,self.Xtr,self.degree,self.c0)).dot(self.alpha)\n",
    "            elif self.kernel==\"spectrum\":\n",
    "                return addbiais(K_spectrum_kernel(X,self.Xtr,self.k)).dot(self.alpha)\n",
    "        \n",
    "\n",
    "    def predict(self,X,y=None):\n",
    "        scores=self.decision_function(X)\n",
    "        if len(scores.shape) == 1:\n",
    "            indices = (scores > 0).astype(np.int)\n",
    "        else:\n",
    "            indices = scores.argmax(axis=1)\n",
    "        return self.classes_[indices]\n",
    "    def predict_proba_(self,X,y=None):\n",
    "        p=sigmoid(self.decision_function(X)).reshape(-1,1)\n",
    "        return hstack((p,1-p))\n",
    "    def get_params(self, deep=True):\n",
    "    \n",
    "        return {\"lbd\": self.lbd,\"gamma\":self.gamma,\"degree\":self.degree,\"c0\":self.c0,\"k\":self.k,\"biais\":self.biais,\n",
    "                \"kernel\":self.kernel,\"n_iter\":self.n_iter,\"method\":self.method}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche des Hyperparamètres "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('standardscaler', StandardScaler()), ('kernellr', KernelLR())])\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   21.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   20.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   23.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                                       ('kernellr', KernelLR())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'kernellr__lbd': [1e-06, 1e-05, 0.0001, 0.001, 0.01,\n",
       "                                           0.1, 1, 10]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KLR=make_pipeline(StandardScaler(),KernelLR())\n",
    "print(KLR)\n",
    "\n",
    "hps0={'kernellr__lbd':[10**-6,10**-5,10**-4,10**-3,10**-2,10**-1,1,10]}\n",
    "searchKLR0= GridSearchCV(KLR,hps0,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKLR0.fit(X_0train, Y_0train)\n",
    "\n",
    "hps1={'kernellr__lbd':[10**-6,10**-5,10**-4,10**-3,10**-2,10**-1,1,10]}\n",
    "searchKLR1= GridSearchCV(KLR,hps1,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKLR1.fit(X_1train, Y_1train)\n",
    "\n",
    "\n",
    "hps2={'kernellr__lbd':[10**-6,10**-5,10**-4,10**-3,10**-2,10**-1,1,10]}\n",
    "searchKLR2= GridSearchCV(KLR,hps2,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKLR2.fit(X_2train, Y_2train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Présentation des résultats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernellr__lbd</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.6010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.5890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1e-06</td>\n",
       "      <td>0.5845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>0.5225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kernellr__lbd  mean_test_score\n",
       "0        0.0001           0.6010\n",
       "1         1e-05           0.5890\n",
       "2         0.001           0.5890\n",
       "3         1e-06           0.5845\n",
       "4          0.01           0.5515\n",
       "5           0.1           0.5250\n",
       "6            10           0.5225\n",
       "7             1           0.5225"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "présentation_résultat(searchKLR0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernellr__lbd</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.6055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1e-06</td>\n",
       "      <td>0.5970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.5965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>0.5255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kernellr__lbd  mean_test_score\n",
       "0        0.0001           0.6055\n",
       "1         1e-06           0.5970\n",
       "2         1e-05           0.5965\n",
       "3         0.001           0.5960\n",
       "4          0.01           0.5515\n",
       "5           0.1           0.5265\n",
       "6            10           0.5255\n",
       "7             1           0.5250"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "présentation_résultat(searchKLR1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernellr__lbd</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.7110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.6940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.6940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1e-06</td>\n",
       "      <td>0.6905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>0.6545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.6535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kernellr__lbd  mean_test_score\n",
       "0        0.0001           0.7110\n",
       "1         1e-05           0.6940\n",
       "2         0.001           0.6940\n",
       "3         1e-06           0.6905\n",
       "4          0.01           0.6670\n",
       "5            10           0.6545\n",
       "6             1           0.6535\n",
       "7           0.1           0.6530"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "présentation_résultat(searchKLR2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps0={\"kernellr__lbd\":uniform(loc=5*10**-6,scale=5*10**-3)}\n",
    "searchKLR0= RandomizedSearchCV(KLR,hps0,n_iter=500,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKLR0.fit(X_0train, Y_0train)\n",
    "\n",
    "hps1={\"kernellr__lbd\":uniform(loc=5*10**-7,scale=5*10**-3)}\n",
    "searchKLR1=RandomizedSearchCV(KLR,hps1,n_iter=500,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKLR1.fit(X_1train, Y_1train)\n",
    "\n",
    "\n",
    "hps2={\"kernellr__lbd\":uniform(loc=5*10**-7,scale=5*10**-3)}\n",
    "searchKLR2= RandomizedSearchCV(KLR,hps2,n_iter=500,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKLR2.fit(X_2train, Y_2train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKLR0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKLR1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKLR2,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM \n",
    "J'utilise cvxopt pour résoudre le QP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(X_train,y_train,C,gamma,degree,c0,k,kernel):\n",
    "    n=y_train.shape[0]\n",
    "    if kernel==\"rbf\":\n",
    "        K=rbf_kernel(X_train,gamma)\n",
    "    elif kernel==\"poly\":\n",
    "        K=poly_kernel(X_train,X_train,degree,c0)\n",
    "    elif kernel==\"spectrum\":\n",
    "        K=spectrum_kernel(X_train,k)\n",
    "    elif kernel==\"precomputed\":\n",
    "        K=X_train\n",
    "    P=matrix(K,tc='d')\n",
    "    q=matrix(-y_train,tc='d')\n",
    "    g1=np.diag(y_train)\n",
    "    G=matrix(np.vstack((g1,-g1)),tc='d')\n",
    "    h=matrix(np.hstack((np.repeat(C,n),np.zeros(n))),tc='d')\n",
    "    solvers.options['show_progress'] = False\n",
    "    sol=solvers.qp(P,q,G,h)\n",
    "    return np.array(sol['x']).reshape(-1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de l'estimateur compatible avec l'API de scikit \n",
    "\n",
    "Si vous remarquez bien j'utilise tout alpha pour définir ma fonction f(x) alors que je pourrai garder seulement les alpha_i telle que alpha_i plus grand > threshold (car le solver nous fera jamais arrivé exatement à zéro quand alpha_i doit être égale à zéro) car comme on le sait une solution optimale de SVM est un vecteur sparse. Je ne l'ai pas fait car j'ai eu du mal à définir le threshold, on trouve une trace de ma tentative dans le code de l'estimateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelSVM(BaseEstimator,ClassifierMixin):\n",
    "    def __init__(self,C=1,gamma='auto',degree=\"2\",c0=1,k=3,kernel=\"rbf\"):\n",
    "        self.C=C\n",
    "        self.gamma=gamma\n",
    "        self.degree=degree\n",
    "        self.c0=c0\n",
    "        self.k=k\n",
    "        self.kernel=kernel\n",
    "    def fit(self,X,y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.Xtr=X\n",
    "        if isinstance(self.gamma,str) and self.kernel==\"rbf\":\n",
    "            self.gamma=1/self.Xtr.shape[1]\n",
    "        self.alpha=SVM(X,y,self.C,self.gamma,self.degree,self.c0,self.k,self.kernel)\n",
    "        #idx=self.alpha>10**-5\n",
    "        #self.Xtr=self.Xtr[idx]\n",
    "        #self.alpha=self.alpha[idx]\n",
    "        return self\n",
    "    def decision_function(self,X):\n",
    "        if self.kernel==\"precomputed\":\n",
    "            return X.dot(self.alpha)\n",
    "        elif self.kernel==\"rbf\":\n",
    "            return K_rbf_kernel(X,self.Xtr,self.gamma).dot(self.alpha) \n",
    "        elif self.kernel==\"poly\":\n",
    "            return poly_kernel(X,self.Xtr,self.degree,self.c0).dot(self.alpha) \n",
    "        elif self.kernel==\"spectrum\":\n",
    "            return K_spectrum_kernel(X,self.Xtr,self.k).dot(self.alpha) \n",
    "            \n",
    "           \n",
    "    def predict(self,X,y=None):\n",
    "        scores=self.decision_function(X)\n",
    "        if len(scores.shape) == 1:\n",
    "            indices = (scores > 0).astype(np.int)\n",
    "        else:\n",
    "            indices = scores.argmax(axis=1)\n",
    "        return self.classes_[indices]\n",
    "    def get_params(self, deep=True):\n",
    "    \n",
    "        return {\"C\": self.C,\"gamma\":self.gamma,\"degree\":self.degree,\"c0\":self.c0,\"k\":self.k,\"kernel\":self.kernel}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('kernelsvm', KernelSVM())])\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                                       ('kernelsvm', KernelSVM())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'kernelsvm__C': [0.01, 0.1, 1, 10, 50, 100, 500,\n",
       "                                          1000]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KSVM=make_pipeline(StandardScaler(),KernelSVM())\n",
    "print(KSVM)\n",
    "\n",
    "hps0={'kernelsvm__C':[10**-2,10**-1,1,10,50,100,500,1000]}\n",
    "searchKSVM0= GridSearchCV(KSVM,hps0,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKSVM0.fit(X_0train, Y_0train)\n",
    "\n",
    "hps1={'kernelsvm__C':[10**-2,10**-1,1,10,50,100,500,1000]}\n",
    "searchKSVM1= GridSearchCV(KSVM,hps1,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKSVM1.fit(X_1train, Y_1train)\n",
    "\n",
    "\n",
    "hps2={'kernelsvm__C':[10**-2,10**-1,1,10,50,100,500,1000]}\n",
    "searchKSVM2= GridSearchCV(KSVM,hps2,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKSVM2.fit(X_2train, Y_2train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernelsvm__C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>0.5845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>0.5845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "      <td>0.5845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.5845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>0.5835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kernelsvm__C  mean_test_score\n",
       "0            1           0.5940\n",
       "1           50           0.5845\n",
       "2          100           0.5845\n",
       "3          500           0.5845\n",
       "4         1000           0.5845\n",
       "5           10           0.5835\n",
       "6          0.1           0.5670\n",
       "7         0.01           0.5225"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "présentation_résultat(searchKSVM0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernelsvm__C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.6030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>0.5865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.5865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0.5860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0.5860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>500</td>\n",
       "      <td>0.5860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kernelsvm__C  mean_test_score\n",
       "0            1           0.6030\n",
       "1          100           0.5865\n",
       "2         1000           0.5865\n",
       "3           10           0.5860\n",
       "4           50           0.5860\n",
       "5          500           0.5860\n",
       "6         0.01           0.5250\n",
       "7          0.1           0.5210"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "présentation_résultat(searchKSVM1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernelsvm__C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.7040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0.6845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>0.6840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>0.6840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>500</td>\n",
       "      <td>0.6840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.6840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kernelsvm__C  mean_test_score\n",
       "0            1           0.7040\n",
       "1          0.1           0.6845\n",
       "2           10           0.6845\n",
       "3           50           0.6840\n",
       "4          100           0.6840\n",
       "5          500           0.6840\n",
       "6         1000           0.6840\n",
       "7         0.01           0.6535"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "présentation_résultat(searchKSVM2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hps0={\"kernelsvm__C\":uniform(loc=0.5,scale=5)}\n",
    "searchKSVM0= RandomizedSearchCV(KSVM,hps0,n_iter=100,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKSVM0.fit(X_0train, Y_0train)\n",
    "\n",
    "hps1={\"kernelsvm__C\":uniform(loc=0.5,scale=5)}\n",
    "searchKSVM1= RandomizedSearchCV(KSVM,hps1,n_iter=100,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKSVM1.fit(X_1train, Y_1train)\n",
    "\n",
    "hps2={\"kernelsvm__C\":uniform(loc=0.1,scale=3)}\n",
    "searchKSVM2= RandomizedSearchCV(KSVM,hps2,n_iter=100,scoring=\"accuracy\",cv=5,verbose=1,n_jobs=-1)\n",
    "searchKSVM2.fit(X_2train, Y_2train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKSVM0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKSVM1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "présentation_résultat(searchKSVM2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KLR0=make_pipeline(StandardScaler(),KernelLR(lbd=0.00018))\n",
    "KLR1=make_pipeline(StandardScaler(),KernelLR(lbd=0.00016))\n",
    "KLR2=make_pipeline(StandardScaler(),KernelLR(lbd=5.89*(10**-5)))\n",
    "\n",
    "X_0test=pd.read_csv(\"Data/Xte0_mat100.csv\",sep=' ',header=None).to_numpy()\n",
    "X_1test=pd.read_csv(\"Data/Xte1_mat100.csv\",sep=' ',header=None).to_numpy()\n",
    "X_2test=pd.read_csv(\"Data/Xte2_mat100.csv\",sep=' ',header=None).to_numpy()\n",
    "\n",
    "\n",
    "print(X_1train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_file(models): #models is a list of 3 models\n",
    "    Y_test=np.empty(0)\n",
    "    for X_train, Y_train, X_test, model  in zip([X_0train,X_1train,X_2train], [Y_0train,Y_1train,Y_2train], [X_0test,X_1test,X_2test], models):\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred=model.predict(X_test)\n",
    "        Y_test=np.concatenate((Y_test,np.where(Y_pred==-1,0,Y_pred)), axis=0)\n",
    "    \n",
    "    Y_test=Y_test.reshape(len(Y_test),1)\n",
    "    with np.printoptions(threshold=np.inf):\n",
    "        print(Y_test.shape)\n",
    "    ids=np.arange(Y_test.shape[0])\n",
    "    ids=ids.reshape(len(ids),1)\n",
    "    \n",
    "    df=pd.DataFrame(data=np.concatenate((ids,Y_test), axis=1), columns=['Id','Bound'],dtype=np.int)\n",
    "    \n",
    "    return df.to_csv('kernel_spectrum_try2.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file([KLR0,KLR1,KLR2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String kernel \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "from tqdm import tqdm\n",
    "from scipy.stats import rankdata\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/Xtr0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-9a148e8709d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_0train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data/Xtr0.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_1train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data/Xtr1.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_2train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data/Xtr2.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_0test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data/Xte0.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/Xtr0.csv'"
     ]
    }
   ],
   "source": [
    "X_0train=pd.read_csv('\"/Users/elliotmuller/Documents/M2/Kernel Methods/Data Challenge/Xtr0.csv', sep=',')['seq']\n",
    "X_1train=pd.read_csv('Data/Xtr1.csv', sep=',')['seq']\n",
    "X_2train=pd.read_csv('Data/Xtr2.csv', sep=',')['seq']\n",
    "\n",
    "X_0test=pd.read_csv('Data/Xte0.csv', sep=',')['seq']\n",
    "X_1test=pd.read_csv('Data/Xte1.csv', sep=',')['seq']\n",
    "X_2test=pd.read_csv('Data/Xte2.csv', sep=',')['seq']\n",
    "\n",
    "Y_0=pd.read_csv(\"Data/Ytr0.csv\",sep=',')\n",
    "Y_1=pd.read_csv(\"Data/Ytr1.csv\",sep=',')\n",
    "Y_2=pd.read_csv(\"Data/Ytr2.csv\",sep=',')\n",
    "\n",
    "Y_0train=np.where(Y_0[\"Bound\"]==0,-1,Y_0[\"Bound\"])\n",
    "Y_1train=np.where(Y_1[\"Bound\"]==0,-1,Y_1[\"Bound\"])\n",
    "Y_2train=np.where(Y_2[\"Bound\"]==0,-1,Y_2[\"Bound\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_spectrum_kernel(X,Y,k,alphabet=\"ACGT\"):\n",
    "    voc=product(alphabet, repeat=k)\n",
    "    voc=[''.join(elt) for elt in voc]\n",
    "    phi_X=np.vstack(X.apply(lambda x: [x[i:i+k] for i in range(0, len(x)-k+1)]).apply(lambda x: np.array([x.count(v) for v in voc])).to_numpy())\n",
    "    phi_Y=np.vstack(Y.apply(lambda x: [x[i:i+k] for i in range(0, len(x)-k+1)]).apply(lambda x: np.array([x.count(v) for v in voc])).to_numpy())\n",
    "    return phi_X.dot(phi_Y.T)\n",
    "def spectrum_kernel(X,k,alphabet=\"ACGT\"):\n",
    "    voc=product(alphabet, repeat=k)\n",
    "    voc=[''.join(elt) for elt in voc]\n",
    "    phi_X=np.vstack(X.apply(lambda x: [x[i:i+k] for i in range(0, len(x)-k+1)]).apply(lambda x: np.array([x.count(v) for v in voc])).to_numpy())\n",
    "   \n",
    "    return phi_X.dot(phi_X.T)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65536/65536 [00:00<00:00, 135031.15it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 107649.95it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 116545.49it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 135838.71it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 131883.68it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 129471.60it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 135528.48it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 133382.91it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 133276.79it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 133025.56it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 134912.32it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 138630.69it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 135062.93it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 131023.33it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 131368.73it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 127028.35it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 128435.74it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 124192.07it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 122659.69it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 104611.70it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 119093.86it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 115260.43it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 125449.90it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 127642.75it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 133393.07it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 136621.55it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 132593.78it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 134230.84it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 126261.64it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 116494.42it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 124368.28it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 131373.44it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 121286.56it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 127832.53it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 128010.29it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 130656.14it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 134425.93it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 127073.33it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 124518.65it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 114132.85it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 124650.05it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 122874.95it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 125629.35it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 116627.63it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 103392.95it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 119854.08it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 124607.72it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 128176.77it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 133594.76it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 127814.58it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 119877.66it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 125812.09it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 112619.99it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 120401.17it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 111373.85it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 130103.34it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 125222.61it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 130693.04it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 123591.57it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 118245.16it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 127001.70it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 127752.68it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 124380.38it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 132481.18it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 121690.01it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 126206.11it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 129910.45it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 131152.99it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 134833.96it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 132485.84it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 132616.36it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 120484.28it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 121777.89it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 93472.80it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 91264.89it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 106023.01it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 127450.53it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 129648.99it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 125650.60it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 97460.47it/s] \n",
      "100%|██████████| 65536/65536 [00:00<00:00, 92404.73it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 122139.30it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 119456.30it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 119688.80it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 117672.50it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 111054.65it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 128240.34it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 123469.44it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 130859.41it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 132776.19it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 129800.03it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 124583.10it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 131446.69it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 117740.25it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 124561.59it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 121667.61it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 129679.88it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 133582.10it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 123413.50it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 119626.04it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 111890.27it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 116223.17it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 120687.53it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 106396.17it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 120355.93it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 122477.85it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 111146.30it/s]\n",
      "100%|██████████| 65536/65536 [00:00<00:00, 110951.28it/s]\n",
      " 79%|███████▉  | 51794/65536 [00:00<00:00, 121908.90it/s]"
     ]
    }
   ],
   "source": [
    "print(spectrum_kernel(X_0train,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1/7 [00:00<00:00,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KernelSVM(kernel='precomputed')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [06:14<00:00, 53.51s/it] \n",
      "56it [13:11, 14.13s/it]\n",
      "100%|██████████| 7/7 [06:13<00:00, 53.42s/it] \n",
      "56it [35:18, 37.83s/it]\n",
      "100%|██████████| 7/7 [06:59<00:00, 59.88s/it] \n",
      "56it [15:13, 16.31s/it]\n"
     ]
    }
   ],
   "source": [
    "KSVM=KernelSVM(kernel=\"precomputed\")\n",
    "print(KSVM)\n",
    "\n",
    "hps0={'C':[10**-2,10**-1,1,10,50,100,500,1000],'k':[2,3,4,5,6,7,8]}\n",
    "searchKSVM0= Cross_val_spectrum(X_0train,Y_0train,KSVM,hps0)\n",
    "\n",
    "\n",
    "hps1={'C':[10**-2,10**-1,1,10,50,100,500,1000],'k':[2,3,4,5,6,7,8]}\n",
    "searchKSVM1= Cross_val_spectrum(X_1train,Y_1train,KSVM,hps1)\n",
    "\n",
    "\n",
    "\n",
    "hps2={'C':[10**-2,10**-1,1,10,50,100,500,1000],'k':[2,3,4,5,6,7,8]}\n",
    "searchKSVM2= Cross_val_spectrum(X_2train,Y_2train,KSVM,hps2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>k</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.01</td>\n",
       "      <td>6</td>\n",
       "      <td>0.6380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>500</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       C  k  mean_test_score\n",
       "0   0.01  8           0.6455\n",
       "1   0.01  7           0.6450\n",
       "2    0.1  8           0.6405\n",
       "3      1  8           0.6405\n",
       "4     10  8           0.6405\n",
       "5     50  8           0.6405\n",
       "6    100  8           0.6405\n",
       "7    500  8           0.6405\n",
       "8   1000  8           0.6405\n",
       "9   0.01  6           0.6380\n",
       "10   0.1  7           0.6275\n",
       "11     1  7           0.6275\n",
       "12    10  7           0.6275\n",
       "13    50  7           0.6275\n",
       "14   100  7           0.6275\n",
       "15   500  7           0.6275\n",
       "16  1000  7           0.6275\n",
       "17  0.01  5           0.6195\n",
       "18  0.01  4           0.6065\n",
       "19   0.1  4           0.6010\n",
       "20     1  4           0.5985\n",
       "21   0.1  5           0.5975\n",
       "22   0.1  6           0.5940\n",
       "23  1000  4           0.5935\n",
       "24   500  4           0.5930\n",
       "25    10  4           0.5925\n",
       "26   100  4           0.5925"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "présentation_résultat2(searchKSVM0,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>k</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>6</td>\n",
       "      <td>0.6380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>500</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.01</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       C  k  mean_test_score\n",
       "0   0.01  5           0.6435\n",
       "1   0.01  6           0.6380\n",
       "2   0.01  7           0.6295\n",
       "3    0.1  7           0.6200\n",
       "4      1  7           0.6200\n",
       "5     10  7           0.6200\n",
       "6     50  7           0.6200\n",
       "7    100  7           0.6200\n",
       "8    500  7           0.6200\n",
       "9   1000  7           0.6200\n",
       "10  0.01  8           0.6185\n",
       "11   0.1  5           0.6150\n",
       "12   0.1  4           0.6135\n",
       "13   0.1  8           0.6130\n",
       "14     1  8           0.6130\n",
       "15    10  8           0.6130\n",
       "16    50  8           0.6130\n",
       "17   100  8           0.6130\n",
       "18   500  8           0.6130\n",
       "19  1000  8           0.6130"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "présentation_résultat2(searchKSVM1,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>k</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>500</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.01</td>\n",
       "      <td>6</td>\n",
       "      <td>0.7290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.01</td>\n",
       "      <td>8</td>\n",
       "      <td>0.7275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.7255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.7245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.7245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>0.7245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>0.7245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>0.7245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.7245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       C  k  mean_test_score\n",
       "0   0.01  7           0.7415\n",
       "1    0.1  7           0.7335\n",
       "2      1  7           0.7310\n",
       "3     10  7           0.7310\n",
       "4     50  7           0.7310\n",
       "5    100  7           0.7310\n",
       "6    500  7           0.7310\n",
       "7   1000  7           0.7310\n",
       "8   0.01  6           0.7290\n",
       "9   0.01  8           0.7275\n",
       "10   0.1  8           0.7255\n",
       "11     1  8           0.7245\n",
       "12    10  8           0.7245\n",
       "13    50  8           0.7245\n",
       "14   100  8           0.7245\n",
       "15   500  8           0.7245\n",
       "16  1000  8           0.7245"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "présentation_résultat2(searchKSVM2,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [06:23<00:00, 383.41s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': array([0.46666505, 0.26907594, 0.12523631, 0.45466107, 0.26347195,\n",
      "       0.19420895, 0.18226131, 0.49544762, 0.01318606, 0.41101619,\n",
      "       0.45164923, 0.24666404, 0.05044877, 0.3151696 , 0.05091285,\n",
      "       0.42096472, 0.11227579, 0.2445298 , 0.30944494, 0.40553232,\n",
      "       0.49069645, 0.41870792, 0.4170422 , 0.41755719, 0.4080609 ,\n",
      "       0.05694352, 0.21573527, 0.01444699, 0.3645368 , 0.22691003,\n",
      "       0.21797331, 0.07831073, 0.01927725, 0.21226899, 0.43667885,\n",
      "       0.02985245, 0.0565717 , 0.19886476, 0.11112374, 0.30510266,\n",
      "       0.08007239, 0.47218621, 0.35868019, 0.24887759, 0.29805176,\n",
      "       0.25165495, 0.39362325, 0.45773882, 0.07267951, 0.05861149]), 'k': array([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "       8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "       8, 8, 8, 8, 8, 8])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [09:22, 11.24s/it]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.15s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': array([0.43176172, 0.26195195, 0.24518519, 0.41727215, 0.09133693,\n",
      "       0.34584573, 0.4296129 , 0.27213185, 0.4455721 , 0.34425933,\n",
      "       0.12402668, 0.38649431, 0.04172012, 0.40968717, 0.14548111,\n",
      "       0.08202455, 0.48124638, 0.17726664, 0.41057927, 0.1769999 ,\n",
      "       0.34431211, 0.04408077, 0.20784162, 0.39786877, 0.48186417,\n",
      "       0.38823755, 0.42120227, 0.47118595, 0.06240904, 0.23616567,\n",
      "       0.18784333, 0.23993454, 0.12151771, 0.49477509, 0.18250762,\n",
      "       0.28094271, 0.20887174, 0.24207455, 0.40490859, 0.08339908,\n",
      "       0.12515863, 0.06248199, 0.24669478, 0.26764686, 0.07934126,\n",
      "       0.16136374, 0.1944452 , 0.30599783, 0.19357854, 0.08016435]), 'k': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [10:43, 12.88s/it]\n",
      "100%|██████████| 1/1 [01:19<00:00, 79.43s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': array([0.24811796, 0.19046197, 0.02332814, 0.37084938, 0.28486939,\n",
      "       0.43829491, 0.26565659, 0.17937156, 0.06996736, 0.3658085 ,\n",
      "       0.28177865, 0.06674257, 0.28349039, 0.25354877, 0.400276  ,\n",
      "       0.49915773, 0.46203365, 0.43082258, 0.01423607, 0.42812112,\n",
      "       0.4607758 , 0.38853215, 0.40922324, 0.25191396, 0.3117775 ,\n",
      "       0.31132515, 0.39262195, 0.23339819, 0.3925347 , 0.1423535 ,\n",
      "       0.1797383 , 0.40227858, 0.41858376, 0.05750593, 0.05113303,\n",
      "       0.06096535, 0.29375129, 0.09998449, 0.32552638, 0.15315188,\n",
      "       0.24206569, 0.41775379, 0.47600435, 0.43112248, 0.17612762,\n",
      "       0.25724631, 0.27676258, 0.0929287 , 0.11508991, 0.18911116]), 'k': array([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "       7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "       7, 7, 7, 7, 7, 7])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [18:04, 21.69s/it]\n"
     ]
    }
   ],
   "source": [
    "hps0={'C':uniform(loc=0.005,scale=0.5),'k':[8]}\n",
    "searchKSVM0= Randomized_Cross_val_spectrum(X_0train,Y_0train,KSVM,hps0,50)\n",
    "\n",
    "\n",
    "hps1={'C':uniform(loc=0.005,scale=0.5),'k':[5]}\n",
    "searchKSVM1= Randomized_Cross_val_spectrum(X_1train,Y_1train,KSVM,hps1,50)\n",
    "\n",
    "\n",
    "\n",
    "hps2={'C':uniform(loc=0.005,scale=0.5),'k':[7]}\n",
    "searchKSVM2= Randomized_Cross_val_spectrum(X_2train,Y_2train,KSVM,hps2,50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>k</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.050448771307686095</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05091285130337835</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02985245022581617</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013186059645409972</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0569435202737617</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.014446992786455778</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.056571703359897856</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.05861148630114598</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      C  k  mean_test_score\n",
       "0  0.050448771307686095  8           0.6435\n",
       "1   0.05091285130337835  8           0.6430\n",
       "2   0.02985245022581617  8           0.6425\n",
       "3  0.013186059645409972  8           0.6410\n",
       "4    0.0569435202737617  8           0.6410\n",
       "5  0.014446992786455778  8           0.6410\n",
       "6  0.056571703359897856  8           0.6410\n",
       "7   0.05861148630114598  8           0.6410"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "présentation_résultat2(searchKSVM0,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>k</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.041720115086265545</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0440807747696007</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06240904239977856</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.062481994426005764</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.08202455387710322</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.12151770942350837</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.1613637411943103</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.17726663919630986</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.17699989754103973</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.08339908141150759</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.07934125740530562</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.12402667995983607</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.1251586261274244</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0913369304907905</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.1878433347372781</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.18250761986329783</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.08016434918431636</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.14548110968980926</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.19444520101531393</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.19357854405159058</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       C  k  mean_test_score\n",
       "0   0.041720115086265545  5           0.6240\n",
       "1     0.0440807747696007  5           0.6235\n",
       "2    0.06240904239977856  5           0.6205\n",
       "3   0.062481994426005764  5           0.6200\n",
       "4    0.08202455387710322  5           0.6155\n",
       "5    0.12151770942350837  5           0.6155\n",
       "6     0.1613637411943103  5           0.6145\n",
       "7    0.17726663919630986  5           0.6145\n",
       "8    0.17699989754103973  5           0.6145\n",
       "9    0.08339908141150759  5           0.6145\n",
       "10   0.07934125740530562  5           0.6145\n",
       "11   0.12402667995983607  5           0.6140\n",
       "12    0.1251586261274244  5           0.6140\n",
       "13    0.0913369304907905  5           0.6135\n",
       "14    0.1878433347372781  5           0.6135\n",
       "15   0.18250761986329783  5           0.6130\n",
       "16   0.08016434918431636  5           0.6130\n",
       "17   0.14548110968980926  5           0.6115\n",
       "18   0.19444520101531393  5           0.6110\n",
       "19   0.19357854405159058  5           0.6110"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "présentation_résultat2(searchKSVM1,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>k</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014236067163357343</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02332813750240192</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0699673590736214</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.06096535102182892</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05113303466458518</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.06674257022952479</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.057505934607167124</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0999844942020891</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.09292869707770801</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.1150899081854529</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      C  k  mean_test_score\n",
       "0  0.014236067163357343  7           0.7410\n",
       "1   0.02332813750240192  7           0.7350\n",
       "2    0.0699673590736214  7           0.7345\n",
       "3   0.06096535102182892  7           0.7345\n",
       "4   0.05113303466458518  7           0.7340\n",
       "5   0.06674257022952479  7           0.7340\n",
       "6  0.057505934607167124  7           0.7340\n",
       "7    0.0999844942020891  7           0.7335\n",
       "8   0.09292869707770801  7           0.7330\n",
       "9    0.1150899081854529  7           0.7330"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "présentation_résultat2(searchKSVM2,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0=KernelSVM(C=0.01,k=8,kernel=\"spectrum\")\n",
    "model1=KernelSVM(C=0.01,k=5,kernel=\"spectrum\")\n",
    "model2=KernelSVM(C=0.01,k=7,kernel=\"spectrum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 1)\n"
     ]
    }
   ],
   "source": [
    "csv_file([model0,model1,model2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cross_val_spectrum(X_train,Y_train,model,hps,cv=5):\n",
    "    CV=StratifiedKFold(cv)\n",
    "    dic_K={k:spectrum_kernel(X_train,k) for k in tqdm(hps[\"k\"])}\n",
    "    list_hp=[]\n",
    "    list_val_score=[]\n",
    "    idx_k=list(hps.keys()).index(\"k\")\n",
    "    \n",
    "    for i in tqdm(product(*hps.values())):\n",
    "        \n",
    "        dic_hp={keys:values for keys,values in zip(hps.keys(),i)}\n",
    "        list_hp.append(dic_hp)\n",
    "        \n",
    "        model.set_params(**dic_hp)\n",
    "        acc_mean=0\n",
    "        for train_idx,val_idx in CV.split(X_train,Y_train):\n",
    "            K=dic_K[i[idx_k]]\n",
    "            model.fit(K[train_idx][:,train_idx],Y_train[train_idx])\n",
    "            Y_pred=model.predict(K[val_idx][:,train_idx])\n",
    "            acc_mean+=accuracy_score(Y_train[val_idx],Y_pred)\n",
    "        list_val_score.append(acc_mean/cv)\n",
    "    return {\"params\":list_hp,\"mean_test_score\":np.array(list_val_score),\"rank_test_score\":rankdata(list_val_score)}\n",
    "            \n",
    "            \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Randomized_Cross_val_spectrum(X_train,Y_train,model,hps,n_iter,cv=5):\n",
    "    CV=StratifiedKFold(cv)\n",
    "    dic_K={k:spectrum_kernel(X_train,k) for k in tqdm(hps[\"k\"])}\n",
    "    list_hp=[]\n",
    "    list_val_score=[]\n",
    "    idx_k=list(hps.keys()).index(\"k\")\n",
    "    for keys,values in hps.items():\n",
    "        if isinstance(values,scipy.stats._distn_infrastructure.rv_frozen):\n",
    "            hps[keys]=values.rvs(size=n_iter)\n",
    "        else:\n",
    "            hps[keys]=np.random.choice(values,n_iter)\n",
    "    print(hps)\n",
    "    for i in tqdm(zip(*hps.values())):\n",
    "        \n",
    "        dic_hp={keys:values for keys,values in zip(hps.keys(),i)}\n",
    "        list_hp.append(dic_hp)\n",
    "        \n",
    "        model.set_params(**dic_hp)\n",
    "        acc_mean=0\n",
    "        for train_idx,val_idx in CV.split(X_train,Y_train):\n",
    "            K=dic_K[i[idx_k]]\n",
    "            model.fit(K[train_idx][:,train_idx],Y_train[train_idx])\n",
    "            Y_pred=model.predict(K[val_idx][:,train_idx])\n",
    "            acc_mean+=accuracy_score(Y_train[val_idx],Y_pred)\n",
    "        list_val_score.append(acc_mean/cv)\n",
    "    return {\"params\":list_hp,\"mean_test_score\":np.array(list_val_score),\"rank_test_score\":rankdata(list_val_score)}\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': array([2.29109288, 1.28619423, 0.54370751, 1.51972859, 1.29469697,\n",
      "       1.70426481, 2.27696594, 0.52956819, 1.45780128, 1.24405329]), 'k': array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3])}\n",
      "{'C': 2.2910928819369967, 'k': 3}\n",
      "{'C': 1.2861942342546977, 'k': 3}\n",
      "{'C': 0.5437075121323791, 'k': 3}\n",
      "{'C': 1.5197285935541702, 'k': 3}\n",
      "{'C': 1.2946969722600201, 'k': 3}\n",
      "{'C': 1.7042648064952854, 'k': 3}\n",
      "{'C': 2.276965939325671, 'k': 3}\n",
      "{'C': 0.5295681908427132, 'k': 3}\n",
      "{'C': 1.4578012788210766, 'k': 3}\n",
      "{'C': 1.2440532860608564, 'k': 3}\n"
     ]
    }
   ],
   "source": [
    "hps={'C':uniform(loc=0.5,scale=2),'k':[3]}\n",
    "CV=StratifiedKFold(5)\n",
    "list_hp=[]\n",
    "n_iter=10\n",
    "list_val_score=[]\n",
    "dic_K={k:np.arange(k) for k in hps[\"k\"]}\n",
    "idx_k=list(hps.keys()).index(\"k\")\n",
    "for keys,values in hps.items():\n",
    "    if isinstance(values,scipy.stats._distn_infrastructure.rv_frozen):\n",
    "        hps[keys]=values.rvs(size=n_iter)\n",
    "    else:\n",
    "        hps[keys]=np.random.choice(values,n_iter)\n",
    "print(hps)\n",
    "\n",
    "for i in zip(*hps.values()):\n",
    "    dic_hp={keys:values for keys,values in zip(hps.keys(),i)}\n",
    "    KSVM.set_params(**dic_hp)\n",
    "    print(dic_hp)\n",
    "    for train_idx,test_idx in CV.split(X_0train,Y_0train):\n",
    "        x=5\n",
    "       \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(uniform(loc=0.5,scale=1))\n",
    "isinstance(uniform(loc=0.5,scale=1),scipy.stats._distn_infrastructure.rv_frozen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "{'a': 1, 'b': 2}\n",
      "(1, 3)\n",
      "{'a': 1, 'b': 3}\n",
      "(3, 2)\n",
      "{'a': 3, 'b': 2}\n",
      "(3, 3)\n",
      "{'a': 3, 'b': 3}\n",
      "(4, 2)\n",
      "{'a': 4, 'b': 2}\n",
      "(4, 3)\n",
      "{'a': 4, 'b': 3}\n",
      "(5, 2)\n",
      "{'a': 5, 'b': 2}\n",
      "(5, 3)\n",
      "{'a': 5, 'b': 3}\n"
     ]
    }
   ],
   "source": [
    "for i in product(*dic.values()):\n",
    "    print(i)\n",
    "    dac={keys:values for keys,values in zip(dic.keys(),i)}\n",
    "    print(dac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 3, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 5, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=np.diag(np.arange(10))\n",
    "idx=np.array([1,3,5])\n",
    "A[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def présentation_résultat2(search,n):\n",
    "    mask=search['rank_test_score']<=n\n",
    "    params=list(compress(search['params'], list(mask)))\n",
    "    mean_test_score=search['mean_test_score'][mask]\n",
    "    a={}\n",
    "    for i in range(mean_test_score.size):\n",
    "        k=''\n",
    "        for key, value in params[i].items():\n",
    "            k+=\" \"+key+\" \"+str(value)\n",
    "        a.update({k:mean_test_score[i]})\n",
    "        sortedDict = sorted(a.items(), key=lambda x: x[1],reverse=True)\n",
    "    l=[]\n",
    "    for i in sortedDict:\n",
    "        u=i[0].split(sep=' ')\n",
    "        del(u[0])\n",
    "        lp=[]\n",
    "        for j in u[1::2]:\n",
    "            lp.append(j)\n",
    "        lp.append(i[1])\n",
    "        l.append(lp)\n",
    "    head=list(params[0].keys())+[\"mean_test_score\"]\n",
    "\n",
    "    return(pd.DataFrame(l,columns=head))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple MKL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mismatch Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TCCTGTGCACATCTGCACCCCTGTTGTGGCCACAAAATGATCCGGCACCACCCAGTGGGAGACGACAGAGGTGGCAATGGGGTGTCGGCTCTGACGCCTCC'"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_0train=pd.read_csv('/Users/elliotmuller/Documents/M2/Kernel Methods/Data Challenge/Xtr0.csv', sep=';')['seq']\n",
    "X_1train=pd.read_csv('/Users/elliotmuller/Documents/M2/Kernel Methods/Data Challenge/Xtr1.csv', sep=';')['seq']\n",
    "X_2train=pd.read_csv('/Users/elliotmuller/Documents/M2/Kernel Methods/Data Challenge/Xtr2.csv', sep=';')['seq']\n",
    "\n",
    "X_0test=pd.read_csv('/Users/elliotmuller/Documents/M2/Kernel Methods/Data Challenge/Xte0.csv', sep=';')['seq']\n",
    "X_1test=pd.read_csv('/Users/elliotmuller/Documents/M2/Kernel Methods/Data Challenge/Xte1.csv', sep=';')['seq']\n",
    "X_2test=pd.read_csv('/Users/elliotmuller/Documents/M2/Kernel Methods/Data Challenge/Xte2.csv', sep=';')['seq']\n",
    "\n",
    "Y_0=pd.read_csv('/Users/elliotmuller/Documents/M2/Kernel Methods/Data Challenge/Ytr0.csv',sep=',')\n",
    "Y_1=pd.read_csv('/Users/elliotmuller/Documents/M2/Kernel Methods/Data Challenge/Ytr1.csv',sep=',')\n",
    "Y_2=pd.read_csv('/Users/elliotmuller/Documents/M2/Kernel Methods/Data Challenge/Ytr2.csv',sep=',')\n",
    "Y_0train=np.where(Y_0[\"Bound\"]==0,-1,Y_0[\"Bound\"])\n",
    "Y_1train=np.where(Y_1[\"Bound\"]==0,-1,Y_1[\"Bound\"])\n",
    "Y_2train=np.where(Y_2[\"Bound\"]==0,-1,Y_2[\"Bound\"])\n",
    "\n",
    "X_0train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from Bio import pairwise2\n",
    "\n",
    "def build_dic_voc(k):\n",
    "    return {''.join(v):i for i,v in enumerate(product(\"ACGT\",repeat=k))}\n",
    "\n",
    "def mismatch_kernel(X,k,m,voc):\n",
    "    if m>k:\n",
    "        return(\"Error, k needs to be greater than m\")\n",
    "    L=[]\n",
    "    iterable=['A','T','C','G']\n",
    "    for subset in list(itertools.product('ACGT', repeat=k)):   #Toutes les sous sequences de longueur k possibles\n",
    "        subseq=''.join(subset)\n",
    "        L+=[subseq]   #On les stocke dans L \n",
    "    K=np.zeros((len(X),len(L)))   #On cree la matrice K \n",
    "    for i in (range(len(X))):   #Une ligne pour chaque observation\n",
    "        sequence=X_0train[i]\n",
    "        kernel_obs=np.zeros(len(L))\n",
    "        for (j,subseq) in zip(range(len(L)),L):   #On regarde le nombre d'occurences de chaque sous seq possible\n",
    "            #x=sequence.count(subseq)\n",
    "            #kernel_obs[j]=x\n",
    "            for l in (range(len(sequence)-(k-1))):\n",
    "                s1=sequence[l:l+k]\n",
    "                s2=subseq\n",
    "                if (sum(c1!=c2 for c1,c2 in zip(s1,s2))<=m):\n",
    "                    kernel_obs[j]+=1\n",
    "        kernel_obs=kernel_obs.reshape(1,-1)\n",
    "        K[i,]=kernel_obs\n",
    "    return(K)\n",
    "        \n",
    "K=mismatch_kernel(X_0train,3,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dic_voc(k):\n",
    "    return {''.join(v):i for i,v in enumerate(product(\"ACGT\",repeat=k))}\n",
    "\n",
    "def mismatch_kernel(X,k,m,voc):\n",
    "    if m>k:\n",
    "        return(\"Error, k needs to be greater than m\")\n",
    "    phi_X=np.zeros(len(voc))   \n",
    "    sequence=X\n",
    "    for subseq in (voc.keys()):   #On regarde le nombre d'occurences de chaque sous seq possible\n",
    "        for l in (range(len(sequence)-(k-1))):\n",
    "            s1=sequence[l:l+k]\n",
    "            s2=subseq\n",
    "            if (sum(c1!=c2 for c1,c2 in zip(s1,s2))<=m):\n",
    "                phi_X[j]+=1\n",
    "    return(phi_X)\n",
    "        \n",
    "K=mismatch_kernel(X_0train,3,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z', 'Z', 'Z', 'Z', 'Z']\n"
     ]
    }
   ],
   "source": [
    "#zone_interet=X[l:l+k]\n",
    "k=5\n",
    "x='ATCTG'\n",
    "x=list(x)\n",
    "voc=['A','C','G','T']\n",
    "m=2\n",
    "L=[]\n",
    "for mm in (range(m,-1,-1)):\n",
    "    if mm==0:\n",
    "        L.append(x)\n",
    "    for i in itertools.combinations(range(k),mm):\n",
    "        for y in (list(i)):\n",
    "            x_copy=x.copy()\n",
    "            voc_copy=voc[:]\n",
    "            for u in voc_copy.remove[x[y]]:\n",
    "                x_copy=x.copy()\n",
    "                \n",
    "        \n",
    "    \n",
    "print(x)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "remove() takes no keyword arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-249-85528ae99304>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvoc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'G'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'T'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: remove() takes no keyword arguments"
     ]
    }
   ],
   "source": [
    "voc=['A','C','G','T']\n",
    "voc.remove('A',inplace=False)\n",
    "print(voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=list(itertools.combinations(range(5),2))\n",
    "len(a)\n",
    "#x='ATCTG'\n",
    "#for i in \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n",
      "64\n",
      "64\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "for k in (range(2,4)):\n",
    "    for m in (range(k)):\n",
    "        K=mismatch_kernel(X_0train,k,m)\n",
    "        A=K.dot(K.T)\n",
    "        print(np.linalg.matrix_rank(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "23\n",
      "23\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "26\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "33\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "43\n",
      "43\n",
      "43\n",
      "43\n",
      "43\n",
      "43\n",
      "43\n",
      "43\n",
      "44\n",
      "45\n",
      "45\n",
      "45\n",
      "45\n",
      "45\n",
      "45\n",
      "45\n",
      "46\n",
      "47\n",
      "47\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "59\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "63\n",
      "63\n",
      "63\n",
      "63\n",
      "64\n",
      "65\n",
      "65\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "72\n",
      "72\n",
      "72\n",
      "72\n",
      "72\n",
      "72\n",
      "72\n",
      "72\n",
      "72\n",
      "72\n",
      "72\n",
      "72\n",
      "72\n",
      "73\n",
      "74\n",
      "74\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "94\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "106\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "125\n",
      "126\n",
      "126\n",
      "126\n",
      "126\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "130\n",
      "130\n",
      "130\n",
      "130\n",
      "130\n",
      "130\n",
      "130\n",
      "130\n",
      "130\n",
      "130\n",
      "131\n",
      "132\n",
      "132\n",
      "132\n",
      "132\n",
      "132\n",
      "133\n",
      "134\n",
      "134\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "152\n",
      "152\n",
      "152\n",
      "152\n",
      "152\n",
      "152\n",
      "152\n",
      "152\n",
      "153\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "155\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "177\n",
      "177\n",
      "178\n",
      "179\n",
      "179\n",
      "179\n",
      "180\n",
      "181\n",
      "181\n",
      "181\n",
      "181\n",
      "181\n",
      "181\n",
      "181\n",
      "181\n",
      "181\n",
      "181\n",
      "181\n",
      "181\n",
      "181\n",
      "181\n",
      "182\n",
      "183\n",
      "183\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "209\n",
      "209\n",
      "209\n",
      "209\n",
      "209\n",
      "209\n",
      "209\n",
      "209\n",
      "209\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "214\n",
      "215\n",
      "215\n",
      "215\n",
      "215\n",
      "215\n",
      "215\n",
      "215\n",
      "216\n",
      "217\n",
      "217\n",
      "217\n",
      "217\n",
      "217\n",
      "217\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "221\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "233\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "247\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "268\n",
      "268\n",
      "268\n",
      "268\n",
      "268\n",
      "268\n",
      "268\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "272\n",
      "272\n",
      "272\n",
      "272\n",
      "272\n",
      "272\n",
      "272\n",
      "272\n",
      "273\n",
      "274\n",
      "274\n",
      "274\n",
      "274\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "284\n",
      "285\n",
      "286\n",
      "286\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "290\n",
      "290\n",
      "290\n",
      "290\n",
      "290\n",
      "290\n",
      "291\n",
      "292\n",
      "292\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "297\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "307\n",
      "307\n",
      "307\n",
      "307\n",
      "308\n",
      "309\n",
      "309\n",
      "309\n",
      "309\n",
      "309\n",
      "310\n",
      "311\n",
      "311\n",
      "311\n",
      "311\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "317\n",
      "317\n",
      "317\n",
      "317\n",
      "317\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "332\n",
      "332\n",
      "332\n",
      "332\n",
      "332\n",
      "332\n",
      "332\n",
      "332\n",
      "332\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "346\n",
      "346\n",
      "346\n",
      "346\n",
      "346\n",
      "346\n",
      "346\n",
      "346\n",
      "346\n",
      "346\n",
      "347\n",
      "348\n",
      "348\n",
      "348\n",
      "349\n",
      "350\n",
      "350\n",
      "350\n",
      "350\n",
      "350\n",
      "351\n",
      "352\n",
      "352\n",
      "352\n",
      "352\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "358\n",
      "358\n",
      "358\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "362\n",
      "362\n",
      "362\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "366\n",
      "366\n",
      "366\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "382\n",
      "383\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "385\n",
      "386\n",
      "386\n",
      "386\n",
      "386\n",
      "386\n",
      "386\n",
      "386\n",
      "387\n",
      "388\n",
      "388\n",
      "388\n",
      "389\n",
      "390\n",
      "390\n",
      "390\n",
      "391\n",
      "392\n",
      "392\n",
      "392\n",
      "392\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "398\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "404\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "408\n",
      "408\n",
      "408\n",
      "408\n",
      "408\n",
      "408\n",
      "408\n",
      "408\n",
      "409\n",
      "410\n",
      "410\n",
      "410\n",
      "410\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "417\n",
      "417\n",
      "418\n",
      "419\n",
      "419\n",
      "419\n",
      "419\n",
      "419\n",
      "420\n",
      "421\n",
      "421\n",
      "421\n",
      "422\n",
      "423\n",
      "423\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "427\n",
      "427\n",
      "428\n",
      "429\n",
      "429\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "437\n",
      "437\n",
      "438\n",
      "439\n",
      "439\n",
      "439\n",
      "439\n",
      "439\n",
      "439\n",
      "439\n",
      "439\n",
      "439\n",
      "440\n",
      "441\n",
      "441\n",
      "441\n",
      "441\n",
      "441\n",
      "442\n",
      "443\n",
      "443\n",
      "443\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "455\n",
      "455\n",
      "455\n",
      "455\n",
      "455\n",
      "455\n",
      "455\n",
      "455\n",
      "456\n",
      "457\n",
      "457\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "463\n",
      "463\n",
      "463\n",
      "463\n",
      "464\n",
      "465\n",
      "465\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "469\n",
      "469\n",
      "469\n",
      "470\n",
      "471\n",
      "471\n",
      "471\n",
      "471\n",
      "471\n",
      "471\n",
      "471\n",
      "471\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "475\n",
      "475\n",
      "476\n",
      "477\n",
      "477\n",
      "477\n",
      "478\n",
      "479\n",
      "479\n",
      "479\n",
      "480\n",
      "481\n",
      "481\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "487\n",
      "487\n",
      "487\n",
      "487\n",
      "487\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "507\n",
      "507\n",
      "507\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "516\n",
      "517\n",
      "518\n",
      "518\n",
      "518\n",
      "518\n",
      "518\n",
      "519\n",
      "520\n",
      "520\n",
      "520\n",
      "520\n",
      "520\n",
      "521\n",
      "522\n",
      "522\n",
      "522\n",
      "522\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "528\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "532\n",
      "532\n",
      "532\n",
      "532\n",
      "532\n",
      "532\n",
      "532\n",
      "532\n",
      "532\n",
      "532\n",
      "533\n",
      "534\n",
      "534\n",
      "534\n",
      "534\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "538\n",
      "538\n",
      "539\n",
      "540\n",
      "540\n",
      "540\n",
      "540\n",
      "540\n",
      "540\n",
      "540\n",
      "540\n",
      "540\n",
      "540\n",
      "540\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "548\n",
      "548\n",
      "549\n",
      "550\n",
      "550\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "555\n",
      "556\n",
      "556\n",
      "556\n",
      "556\n",
      "556\n",
      "556\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "564\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "568\n",
      "568\n",
      "568\n",
      "568\n",
      "568\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "574\n",
      "574\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "584\n",
      "584\n",
      "584\n",
      "584\n",
      "584\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "588\n",
      "588\n",
      "588\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "600\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "606\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "610\n",
      "610\n",
      "610\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "615\n",
      "615\n",
      "616\n",
      "617\n",
      "617\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "628\n",
      "629\n",
      "629\n",
      "629\n",
      "630\n",
      "631\n",
      "631\n",
      "631\n",
      "631\n",
      "631\n",
      "632\n",
      "632\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "636\n",
      "636\n",
      "637\n",
      "638\n",
      "638\n",
      "638\n",
      "638\n",
      "638\n",
      "638\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "656\n",
      "656\n",
      "656\n",
      "656\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "664\n",
      "664\n",
      "664\n",
      "664\n",
      "665\n",
      "666\n",
      "666\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "670\n",
      "670\n",
      "670\n",
      "670\n",
      "670\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "682\n",
      "682\n",
      "682\n",
      "682\n",
      "682\n",
      "682\n",
      "682\n",
      "682\n",
      "683\n",
      "684\n",
      "684\n",
      "684\n",
      "684\n",
      "684\n",
      "684\n",
      "684\n",
      "685\n",
      "686\n",
      "686\n",
      "686\n",
      "686\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "692\n",
      "692\n",
      "692\n",
      "692\n",
      "692\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "695\n",
      "695\n",
      "695\n",
      "695\n",
      "696\n",
      "697\n",
      "697\n",
      "697\n",
      "697\n",
      "698\n",
      "699\n",
      "699\n",
      "699\n",
      "699\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "703\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "709\n",
      "709\n",
      "709\n",
      "709\n",
      "709\n",
      "709\n",
      "709\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "719\n",
      "719\n",
      "719\n",
      "719\n",
      "719\n",
      "719\n",
      "719\n",
      "719\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "727\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "731\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "734\n",
      "734\n",
      "734\n",
      "734\n",
      "734\n",
      "734\n",
      "735\n",
      "736\n",
      "736\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "742\n",
      "742\n",
      "743\n",
      "744\n",
      "744\n",
      "744\n",
      "744\n",
      "744\n",
      "744\n",
      "744\n",
      "744\n",
      "744\n",
      "745\n",
      "746\n",
      "746\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "752\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "758\n",
      "758\n",
      "759\n",
      "760\n",
      "760\n",
      "760\n",
      "760\n",
      "760\n",
      "761\n",
      "762\n",
      "762\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "766\n",
      "766\n",
      "767\n",
      "768\n",
      "768\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "776\n",
      "776\n",
      "777\n",
      "778\n",
      "778\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "782\n",
      "782\n",
      "782\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "786\n",
      "786\n",
      "787\n",
      "788\n",
      "788\n",
      "788\n",
      "789\n",
      "790\n",
      "790\n",
      "790\n",
      "790\n",
      "790\n",
      "790\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "796\n",
      "796\n",
      "796\n",
      "796\n",
      "796\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "806\n",
      "806\n",
      "807\n",
      "808\n",
      "808\n",
      "808\n",
      "808\n",
      "808\n",
      "808\n",
      "808\n",
      "808\n",
      "808\n",
      "809\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "846\n",
      "846\n",
      "846\n",
      "846\n",
      "846\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "854\n",
      "854\n",
      "854\n",
      "854\n",
      "854\n",
      "854\n",
      "854\n",
      "854\n",
      "854\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "858\n",
      "858\n",
      "858\n",
      "859\n",
      "860\n",
      "860\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "871\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "875\n",
      "875\n",
      "875\n",
      "875\n",
      "875\n",
      "875\n",
      "875\n",
      "875\n",
      "876\n",
      "877\n",
      "877\n",
      "877\n",
      "877\n",
      "877\n",
      "877\n",
      "877\n",
      "877\n",
      "877\n",
      "877\n",
      "877\n",
      "877\n",
      "877\n",
      "878\n",
      "879\n",
      "879\n",
      "879\n",
      "880\n",
      "881\n",
      "881\n",
      "881\n",
      "882\n",
      "883\n",
      "883\n",
      "883\n",
      "883\n",
      "883\n",
      "884\n",
      "885\n",
      "885\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "893\n",
      "893\n",
      "893\n",
      "893\n",
      "893\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "897\n",
      "897\n",
      "897\n",
      "897\n",
      "898\n",
      "899\n",
      "899\n",
      "899\n",
      "899\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "903\n",
      "903\n",
      "903\n",
      "903\n",
      "903\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "907\n",
      "907\n",
      "907\n",
      "907\n",
      "907\n",
      "907\n",
      "907\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "911\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "919\n",
      "919\n",
      "919\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "930\n",
      "930\n",
      "930\n",
      "930\n",
      "930\n",
      "930\n",
      "931\n",
      "932\n",
      "932\n",
      "932\n",
      "932\n",
      "932\n",
      "932\n",
      "932\n",
      "933\n",
      "934\n",
      "934\n",
      "934\n",
      "934\n",
      "934\n",
      "935\n",
      "936\n",
      "936\n",
      "936\n",
      "936\n",
      "936\n",
      "936\n",
      "936\n",
      "936\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "948\n",
      "948\n",
      "948\n",
      "948\n",
      "948\n",
      "948\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "952\n",
      "952\n",
      "953\n",
      "954\n",
      "954\n",
      "955\n",
      "956\n",
      "956\n",
      "956\n",
      "956\n",
      "956\n",
      "956\n",
      "956\n",
      "957\n",
      "958\n",
      "958\n",
      "958\n",
      "959\n",
      "960\n",
      "960\n",
      "960\n",
      "961\n",
      "962\n",
      "962\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "969\n",
      "969\n",
      "969\n",
      "969\n",
      "970\n",
      "971\n",
      "971\n",
      "971\n",
      "972\n",
      "973\n",
      "973\n",
      "973\n",
      "973\n",
      "973\n",
      "973\n",
      "973\n",
      "973\n",
      "973\n",
      "973\n",
      "973\n",
      "973\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "980\n",
      "980\n",
      "981\n",
      "982\n",
      "982\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "986\n",
      "986\n",
      "986\n",
      "986\n",
      "987\n",
      "988\n",
      "988\n",
      "988\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "991\n",
      "991\n",
      "991\n",
      "991\n",
      "991\n",
      "991\n",
      "991\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "994\n",
      "994\n",
      "995\n",
      "996\n",
      "996\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1008\n",
      "1008\n",
      "1008\n",
      "2000\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "23\n",
      "23\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "26\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "33\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "43\n",
      "43\n",
      "43\n",
      "43\n",
      "43\n",
      "43\n",
      "43\n",
      "43\n",
      "44\n",
      "45\n",
      "45\n",
      "45\n",
      "45\n",
      "45\n",
      "45\n",
      "45\n",
      "46\n",
      "47\n",
      "47\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "59\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "63\n",
      "63\n",
      "63\n",
      "63\n",
      "64\n",
      "65\n",
      "65\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "72\n",
      "72\n",
      "72\n",
      "72\n",
      "72\n",
      "72\n",
      "72\n",
      "72\n",
      "72\n",
      "72\n",
      "72\n",
      "72\n",
      "72\n",
      "73\n",
      "74\n",
      "74\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "94\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "106\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "125\n",
      "126\n",
      "126\n",
      "126\n",
      "126\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "130\n",
      "130\n",
      "130\n",
      "130\n",
      "130\n",
      "130\n",
      "130\n",
      "130\n",
      "130\n",
      "130\n",
      "131\n",
      "132\n",
      "132\n",
      "132\n",
      "132\n",
      "132\n",
      "133\n",
      "134\n",
      "134\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "152\n",
      "152\n",
      "152\n",
      "152\n",
      "152\n",
      "152\n",
      "152\n",
      "152\n",
      "153\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "155\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "177\n",
      "177\n",
      "178\n",
      "179\n",
      "179\n",
      "179\n",
      "180\n",
      "181\n",
      "181\n",
      "181\n",
      "181\n",
      "181\n",
      "181\n",
      "181\n",
      "181\n",
      "181\n",
      "181\n",
      "181\n",
      "181\n",
      "181\n",
      "181\n",
      "182\n",
      "183\n",
      "183\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "209\n",
      "209\n",
      "209\n",
      "209\n",
      "209\n",
      "209\n",
      "209\n",
      "209\n",
      "209\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "214\n",
      "215\n",
      "215\n",
      "215\n",
      "215\n",
      "215\n",
      "215\n",
      "215\n",
      "216\n",
      "217\n",
      "217\n",
      "217\n",
      "217\n",
      "217\n",
      "217\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "221\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "233\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "247\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "268\n",
      "268\n",
      "268\n",
      "268\n",
      "268\n",
      "268\n",
      "268\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "272\n",
      "272\n",
      "272\n",
      "272\n",
      "272\n",
      "272\n",
      "272\n",
      "272\n",
      "273\n",
      "274\n",
      "274\n",
      "274\n",
      "274\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "284\n",
      "285\n",
      "286\n",
      "286\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "290\n",
      "290\n",
      "290\n",
      "290\n",
      "290\n",
      "290\n",
      "291\n",
      "292\n",
      "292\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "297\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "307\n",
      "307\n",
      "307\n",
      "307\n",
      "308\n",
      "309\n",
      "309\n",
      "309\n",
      "309\n",
      "309\n",
      "310\n",
      "311\n",
      "311\n",
      "311\n",
      "311\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "317\n",
      "317\n",
      "317\n",
      "317\n",
      "317\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "332\n",
      "332\n",
      "332\n",
      "332\n",
      "332\n",
      "332\n",
      "332\n",
      "332\n",
      "332\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "346\n",
      "346\n",
      "346\n",
      "346\n",
      "346\n",
      "346\n",
      "346\n",
      "346\n",
      "346\n",
      "346\n",
      "347\n",
      "348\n",
      "348\n",
      "348\n",
      "349\n",
      "350\n",
      "350\n",
      "350\n",
      "350\n",
      "350\n",
      "351\n",
      "352\n",
      "352\n",
      "352\n",
      "352\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "358\n",
      "358\n",
      "358\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "362\n",
      "362\n",
      "362\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "366\n",
      "366\n",
      "366\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "382\n",
      "383\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "385\n",
      "386\n",
      "386\n",
      "386\n",
      "386\n",
      "386\n",
      "386\n",
      "386\n",
      "387\n",
      "388\n",
      "388\n",
      "388\n",
      "389\n",
      "390\n",
      "390\n",
      "390\n",
      "391\n",
      "392\n",
      "392\n",
      "392\n",
      "392\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "398\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "404\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "408\n",
      "408\n",
      "408\n",
      "408\n",
      "408\n",
      "408\n",
      "408\n",
      "408\n",
      "409\n",
      "410\n",
      "410\n",
      "410\n",
      "410\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "417\n",
      "417\n",
      "418\n",
      "419\n",
      "419\n",
      "419\n",
      "419\n",
      "419\n",
      "420\n",
      "421\n",
      "421\n",
      "421\n",
      "422\n",
      "423\n",
      "423\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "427\n",
      "427\n",
      "428\n",
      "429\n",
      "429\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "437\n",
      "437\n",
      "438\n",
      "439\n",
      "439\n",
      "439\n",
      "439\n",
      "439\n",
      "439\n",
      "439\n",
      "439\n",
      "439\n",
      "440\n",
      "441\n",
      "441\n",
      "441\n",
      "441\n",
      "441\n",
      "442\n",
      "443\n",
      "443\n",
      "443\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "455\n",
      "455\n",
      "455\n",
      "455\n",
      "455\n",
      "455\n",
      "455\n",
      "455\n",
      "456\n",
      "457\n",
      "457\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "463\n",
      "463\n",
      "463\n",
      "463\n",
      "464\n",
      "465\n",
      "465\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "469\n",
      "469\n",
      "469\n",
      "470\n",
      "471\n",
      "471\n",
      "471\n",
      "471\n",
      "471\n",
      "471\n",
      "471\n",
      "471\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "475\n",
      "475\n",
      "476\n",
      "477\n",
      "477\n",
      "477\n",
      "478\n",
      "479\n",
      "479\n",
      "479\n",
      "480\n",
      "481\n",
      "481\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "487\n",
      "487\n",
      "487\n",
      "487\n",
      "487\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "507\n",
      "507\n",
      "507\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "516\n",
      "517\n",
      "518\n",
      "518\n",
      "518\n",
      "518\n",
      "518\n",
      "519\n",
      "520\n",
      "520\n",
      "520\n",
      "520\n",
      "520\n",
      "521\n",
      "522\n",
      "522\n",
      "522\n",
      "522\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "528\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "532\n",
      "532\n",
      "532\n",
      "532\n",
      "532\n",
      "532\n",
      "532\n",
      "532\n",
      "532\n",
      "532\n",
      "533\n",
      "534\n",
      "534\n",
      "534\n",
      "534\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "538\n",
      "538\n",
      "539\n",
      "540\n",
      "540\n",
      "540\n",
      "540\n",
      "540\n",
      "540\n",
      "540\n",
      "540\n",
      "540\n",
      "540\n",
      "540\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "548\n",
      "548\n",
      "549\n",
      "550\n",
      "550\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "555\n",
      "556\n",
      "556\n",
      "556\n",
      "556\n",
      "556\n",
      "556\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "564\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "568\n",
      "568\n",
      "568\n",
      "568\n",
      "568\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "574\n",
      "574\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "584\n",
      "584\n",
      "584\n",
      "584\n",
      "584\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "588\n",
      "588\n",
      "588\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "600\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "606\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "610\n",
      "610\n",
      "610\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "615\n",
      "615\n",
      "616\n",
      "617\n",
      "617\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "628\n",
      "629\n",
      "629\n",
      "629\n",
      "630\n",
      "631\n",
      "631\n",
      "631\n",
      "631\n",
      "631\n",
      "632\n",
      "632\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "636\n",
      "636\n",
      "637\n",
      "638\n",
      "638\n",
      "638\n",
      "638\n",
      "638\n",
      "638\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "656\n",
      "656\n",
      "656\n",
      "656\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "664\n",
      "664\n",
      "664\n",
      "664\n",
      "665\n",
      "666\n",
      "666\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "670\n",
      "670\n",
      "670\n",
      "670\n",
      "670\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "682\n",
      "682\n",
      "682\n",
      "682\n",
      "682\n",
      "682\n",
      "682\n",
      "682\n",
      "683\n",
      "684\n",
      "684\n",
      "684\n",
      "684\n",
      "684\n",
      "684\n",
      "684\n",
      "685\n",
      "686\n",
      "686\n",
      "686\n",
      "686\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "692\n",
      "692\n",
      "692\n",
      "692\n",
      "692\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "695\n",
      "695\n",
      "695\n",
      "695\n",
      "696\n",
      "697\n",
      "697\n",
      "697\n",
      "697\n",
      "698\n",
      "699\n",
      "699\n",
      "699\n",
      "699\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "703\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "709\n",
      "709\n",
      "709\n",
      "709\n",
      "709\n",
      "709\n",
      "709\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "719\n",
      "719\n",
      "719\n",
      "719\n",
      "719\n",
      "719\n",
      "719\n",
      "719\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "727\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "731\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "734\n",
      "734\n",
      "734\n",
      "734\n",
      "734\n",
      "734\n",
      "735\n",
      "736\n",
      "736\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "742\n",
      "742\n",
      "743\n",
      "744\n",
      "744\n",
      "744\n",
      "744\n",
      "744\n",
      "744\n",
      "744\n",
      "744\n",
      "744\n",
      "745\n",
      "746\n",
      "746\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "752\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "758\n",
      "758\n",
      "759\n",
      "760\n",
      "760\n",
      "760\n",
      "760\n",
      "760\n",
      "761\n",
      "762\n",
      "762\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "766\n",
      "766\n",
      "767\n",
      "768\n",
      "768\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "776\n",
      "776\n",
      "777\n",
      "778\n",
      "778\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "782\n",
      "782\n",
      "782\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "786\n",
      "786\n",
      "787\n",
      "788\n",
      "788\n",
      "788\n",
      "789\n",
      "790\n",
      "790\n",
      "790\n",
      "790\n",
      "790\n",
      "790\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "796\n",
      "796\n",
      "796\n",
      "796\n",
      "796\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "806\n",
      "806\n",
      "807\n",
      "808\n",
      "808\n",
      "808\n",
      "808\n",
      "808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808\n",
      "808\n",
      "808\n",
      "808\n",
      "809\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "846\n",
      "846\n",
      "846\n",
      "846\n",
      "846\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "854\n",
      "854\n",
      "854\n",
      "854\n",
      "854\n",
      "854\n",
      "854\n",
      "854\n",
      "854\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "858\n",
      "858\n",
      "858\n",
      "859\n",
      "860\n",
      "860\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "871\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "875\n",
      "875\n",
      "875\n",
      "875\n",
      "875\n",
      "875\n",
      "875\n",
      "875\n",
      "876\n",
      "877\n",
      "877\n",
      "877\n",
      "877\n",
      "877\n",
      "877\n",
      "877\n",
      "877\n",
      "877\n",
      "877\n",
      "877\n",
      "877\n",
      "877\n",
      "878\n",
      "879\n",
      "879\n",
      "879\n",
      "880\n",
      "881\n",
      "881\n",
      "881\n",
      "882\n",
      "883\n",
      "883\n",
      "883\n",
      "883\n",
      "883\n",
      "884\n",
      "885\n",
      "885\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "893\n",
      "893\n",
      "893\n",
      "893\n",
      "893\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "897\n",
      "897\n",
      "897\n",
      "897\n",
      "898\n",
      "899\n",
      "899\n",
      "899\n",
      "899\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "903\n",
      "903\n",
      "903\n",
      "903\n",
      "903\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "907\n",
      "907\n",
      "907\n",
      "907\n",
      "907\n",
      "907\n",
      "907\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "911\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "919\n",
      "919\n",
      "919\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "930\n",
      "930\n",
      "930\n",
      "930\n",
      "930\n",
      "930\n",
      "931\n",
      "932\n",
      "932\n",
      "932\n",
      "932\n",
      "932\n",
      "932\n",
      "932\n",
      "933\n",
      "934\n",
      "934\n",
      "934\n",
      "934\n",
      "934\n",
      "935\n",
      "936\n",
      "936\n",
      "936\n",
      "936\n",
      "936\n",
      "936\n",
      "936\n",
      "936\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "948\n",
      "948\n",
      "948\n",
      "948\n",
      "948\n",
      "948\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "952\n",
      "952\n",
      "953\n",
      "954\n",
      "954\n",
      "955\n",
      "956\n",
      "956\n",
      "956\n",
      "956\n",
      "956\n",
      "956\n",
      "956\n",
      "957\n",
      "958\n",
      "958\n",
      "958\n",
      "959\n",
      "960\n",
      "960\n",
      "960\n",
      "961\n",
      "962\n",
      "962\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "969\n",
      "969\n",
      "969\n",
      "969\n",
      "970\n",
      "971\n",
      "971\n",
      "971\n",
      "972\n",
      "973\n",
      "973\n",
      "973\n",
      "973\n",
      "973\n",
      "973\n",
      "973\n",
      "973\n",
      "973\n",
      "973\n",
      "973\n",
      "973\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "980\n",
      "980\n",
      "981\n",
      "982\n",
      "982\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "986\n",
      "986\n",
      "986\n",
      "986\n",
      "987\n",
      "988\n",
      "988\n",
      "988\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "991\n",
      "991\n",
      "991\n",
      "991\n",
      "991\n",
      "991\n",
      "991\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "994\n",
      "994\n",
      "995\n",
      "996\n",
      "996\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1008\n",
      "1008\n",
      "1008\n",
      "1616518778.794317\n",
      "2000\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "23\n",
      "23\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "26\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "33\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "43\n",
      "43\n",
      "43\n",
      "43\n",
      "43\n",
      "43\n",
      "43\n",
      "43\n",
      "44\n",
      "45\n",
      "45\n",
      "45\n",
      "45\n",
      "45\n",
      "45\n",
      "45\n",
      "46\n",
      "47\n",
      "47\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "59\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "63\n",
      "63\n",
      "63\n",
      "63\n",
      "64\n",
      "65\n",
      "65\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "72\n",
      "72\n",
      "72\n",
      "72\n",
      "72\n",
      "72\n",
      "72\n",
      "72\n",
      "72\n",
      "72\n",
      "72\n",
      "72\n",
      "72\n",
      "73\n",
      "74\n",
      "74\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "94\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "106\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "124\n",
      "125\n",
      "126\n",
      "126\n",
      "126\n",
      "126\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "130\n",
      "130\n",
      "130\n",
      "130\n",
      "130\n",
      "130\n",
      "130\n",
      "130\n",
      "130\n",
      "130\n",
      "131\n",
      "132\n",
      "132\n",
      "132\n",
      "132\n",
      "132\n",
      "133\n",
      "134\n",
      "134\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "152\n",
      "152\n",
      "152\n",
      "152\n",
      "152\n",
      "152\n",
      "152\n",
      "152\n",
      "153\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "155\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "177\n",
      "177\n",
      "178\n",
      "179\n",
      "179\n",
      "179\n",
      "180\n",
      "181\n",
      "181\n",
      "181\n",
      "181\n",
      "181\n",
      "181\n",
      "181\n",
      "181\n",
      "181\n",
      "181\n",
      "181\n",
      "181\n",
      "181\n",
      "181\n",
      "182\n",
      "183\n",
      "183\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "209\n",
      "209\n",
      "209\n",
      "209\n",
      "209\n",
      "209\n",
      "209\n",
      "209\n",
      "209\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "213\n",
      "214\n",
      "215\n",
      "215\n",
      "215\n",
      "215\n",
      "215\n",
      "215\n",
      "215\n",
      "216\n",
      "217\n",
      "217\n",
      "217\n",
      "217\n",
      "217\n",
      "217\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "221\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "233\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "247\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "268\n",
      "268\n",
      "268\n",
      "268\n",
      "268\n",
      "268\n",
      "268\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "272\n",
      "272\n",
      "272\n",
      "272\n",
      "272\n",
      "272\n",
      "272\n",
      "272\n",
      "273\n",
      "274\n",
      "274\n",
      "274\n",
      "274\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "284\n",
      "285\n",
      "286\n",
      "286\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "290\n",
      "290\n",
      "290\n",
      "290\n",
      "290\n",
      "290\n",
      "291\n",
      "292\n",
      "292\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "297\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "307\n",
      "307\n",
      "307\n",
      "307\n",
      "308\n",
      "309\n",
      "309\n",
      "309\n",
      "309\n",
      "309\n",
      "310\n",
      "311\n",
      "311\n",
      "311\n",
      "311\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "317\n",
      "317\n",
      "317\n",
      "317\n",
      "317\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "332\n",
      "332\n",
      "332\n",
      "332\n",
      "332\n",
      "332\n",
      "332\n",
      "332\n",
      "332\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "346\n",
      "346\n",
      "346\n",
      "346\n",
      "346\n",
      "346\n",
      "346\n",
      "346\n",
      "346\n",
      "346\n",
      "347\n",
      "348\n",
      "348\n",
      "348\n",
      "349\n",
      "350\n",
      "350\n",
      "350\n",
      "350\n",
      "350\n",
      "351\n",
      "352\n",
      "352\n",
      "352\n",
      "352\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "358\n",
      "358\n",
      "358\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "362\n",
      "362\n",
      "362\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "366\n",
      "366\n",
      "366\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "382\n",
      "383\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "385\n",
      "386\n",
      "386\n",
      "386\n",
      "386\n",
      "386\n",
      "386\n",
      "386\n",
      "387\n",
      "388\n",
      "388\n",
      "388\n",
      "389\n",
      "390\n",
      "390\n",
      "390\n",
      "391\n",
      "392\n",
      "392\n",
      "392\n",
      "392\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "398\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "404\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "408\n",
      "408\n",
      "408\n",
      "408\n",
      "408\n",
      "408\n",
      "408\n",
      "408\n",
      "409\n",
      "410\n",
      "410\n",
      "410\n",
      "410\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "417\n",
      "417\n",
      "418\n",
      "419\n",
      "419\n",
      "419\n",
      "419\n",
      "419\n",
      "420\n",
      "421\n",
      "421\n",
      "421\n",
      "422\n",
      "423\n",
      "423\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "427\n",
      "427\n",
      "428\n",
      "429\n",
      "429\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "437\n",
      "437\n",
      "438\n",
      "439\n",
      "439\n",
      "439\n",
      "439\n",
      "439\n",
      "439\n",
      "439\n",
      "439\n",
      "439\n",
      "440\n",
      "441\n",
      "441\n",
      "441\n",
      "441\n",
      "441\n",
      "442\n",
      "443\n",
      "443\n",
      "443\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "455\n",
      "455\n",
      "455\n",
      "455\n",
      "455\n",
      "455\n",
      "455\n",
      "455\n",
      "456\n",
      "457\n",
      "457\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "463\n",
      "463\n",
      "463\n",
      "463\n",
      "464\n",
      "465\n",
      "465\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "469\n",
      "469\n",
      "469\n",
      "470\n",
      "471\n",
      "471\n",
      "471\n",
      "471\n",
      "471\n",
      "471\n",
      "471\n",
      "471\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "475\n",
      "475\n",
      "476\n",
      "477\n",
      "477\n",
      "477\n",
      "478\n",
      "479\n",
      "479\n",
      "479\n",
      "480\n",
      "481\n",
      "481\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "487\n",
      "487\n",
      "487\n",
      "487\n",
      "487\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "507\n",
      "507\n",
      "507\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "516\n",
      "517\n",
      "518\n",
      "518\n",
      "518\n",
      "518\n",
      "518\n",
      "519\n",
      "520\n",
      "520\n",
      "520\n",
      "520\n",
      "520\n",
      "521\n",
      "522\n",
      "522\n",
      "522\n",
      "522\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "528\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "532\n",
      "532\n",
      "532\n",
      "532\n",
      "532\n",
      "532\n",
      "532\n",
      "532\n",
      "532\n",
      "532\n",
      "533\n",
      "534\n",
      "534\n",
      "534\n",
      "534\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "538\n",
      "538\n",
      "539\n",
      "540\n",
      "540\n",
      "540\n",
      "540\n",
      "540\n",
      "540\n",
      "540\n",
      "540\n",
      "540\n",
      "540\n",
      "540\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "548\n",
      "548\n",
      "549\n",
      "550\n",
      "550\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "554\n",
      "555\n",
      "556\n",
      "556\n",
      "556\n",
      "556\n",
      "556\n",
      "556\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "564\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "568\n",
      "568\n",
      "568\n",
      "568\n",
      "568\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "574\n",
      "574\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "584\n",
      "584\n",
      "584\n",
      "584\n",
      "584\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "588\n",
      "588\n",
      "588\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "600\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "606\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "610\n",
      "610\n",
      "610\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "615\n",
      "615\n",
      "616\n",
      "617\n",
      "617\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "627\n",
      "628\n",
      "629\n",
      "629\n",
      "629\n",
      "630\n",
      "631\n",
      "631\n",
      "631\n",
      "631\n",
      "631\n",
      "632\n",
      "632\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "636\n",
      "636\n",
      "637\n",
      "638\n",
      "638\n",
      "638\n",
      "638\n",
      "638\n",
      "638\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "656\n",
      "656\n",
      "656\n",
      "656\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "664\n",
      "664\n",
      "664\n",
      "664\n",
      "665\n",
      "666\n",
      "666\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "670\n",
      "670\n",
      "670\n",
      "670\n",
      "670\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "682\n",
      "682\n",
      "682\n",
      "682\n",
      "682\n",
      "682\n",
      "682\n",
      "682\n",
      "683\n",
      "684\n",
      "684\n",
      "684\n",
      "684\n",
      "684\n",
      "684\n",
      "684\n",
      "685\n",
      "686\n",
      "686\n",
      "686\n",
      "686\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "692\n",
      "692\n",
      "692\n",
      "692\n",
      "692\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "695\n",
      "695\n",
      "695\n",
      "695\n",
      "696\n",
      "697\n",
      "697\n",
      "697\n",
      "697\n",
      "698\n",
      "699\n",
      "699\n",
      "699\n",
      "699\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "703\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "709\n",
      "709\n",
      "709\n",
      "709\n",
      "709\n",
      "709\n",
      "709\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "719\n",
      "719\n",
      "719\n",
      "719\n",
      "719\n",
      "719\n",
      "719\n",
      "719\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "727\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "731\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "734\n",
      "734\n",
      "734\n",
      "734\n",
      "734\n",
      "734\n",
      "735\n",
      "736\n",
      "736\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "742\n",
      "742\n",
      "743\n",
      "744\n",
      "744\n",
      "744\n",
      "744\n",
      "744\n",
      "744\n",
      "744\n",
      "744\n",
      "744\n",
      "745\n",
      "746\n",
      "746\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "752\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "758\n",
      "758\n",
      "759\n",
      "760\n",
      "760\n",
      "760\n",
      "760\n",
      "760\n",
      "761\n",
      "762\n",
      "762\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "766\n",
      "766\n",
      "767\n",
      "768\n",
      "768\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "776\n",
      "776\n",
      "777\n",
      "778\n",
      "778\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "782\n",
      "782\n",
      "782\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "786\n",
      "786\n",
      "787\n",
      "788\n",
      "788\n",
      "788\n",
      "789\n",
      "790\n",
      "790\n",
      "790\n",
      "790\n",
      "790\n",
      "790\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "796\n",
      "796\n",
      "796\n",
      "796\n",
      "796\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "806\n",
      "806\n",
      "807\n",
      "808\n",
      "808\n",
      "808\n",
      "808\n",
      "808\n",
      "808\n",
      "808\n",
      "808\n",
      "808\n",
      "809\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "846\n",
      "846\n",
      "846\n",
      "846\n",
      "846\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "854\n",
      "854\n",
      "854\n",
      "854\n",
      "854\n",
      "854\n",
      "854\n",
      "854\n",
      "854\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "858\n",
      "858\n",
      "858\n",
      "859\n",
      "860\n",
      "860\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "871\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "875\n",
      "875\n",
      "875\n",
      "875\n",
      "875\n",
      "875\n",
      "875\n",
      "875\n",
      "876\n",
      "877\n",
      "877\n",
      "877\n",
      "877\n",
      "877\n",
      "877\n",
      "877\n",
      "877\n",
      "877\n",
      "877\n",
      "877\n",
      "877\n",
      "877\n",
      "878\n",
      "879\n",
      "879\n",
      "879\n",
      "880\n",
      "881\n",
      "881\n",
      "881\n",
      "882\n",
      "883\n",
      "883\n",
      "883\n",
      "883\n",
      "883\n",
      "884\n",
      "885\n",
      "885\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "893\n",
      "893\n",
      "893\n",
      "893\n",
      "893\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "897\n",
      "897\n",
      "897\n",
      "897\n",
      "898\n",
      "899\n",
      "899\n",
      "899\n",
      "899\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "903\n",
      "903\n",
      "903\n",
      "903\n",
      "903\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "907\n",
      "907\n",
      "907\n",
      "907\n",
      "907\n",
      "907\n",
      "907\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "911\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "919\n",
      "919\n",
      "919\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "930\n",
      "930\n",
      "930\n",
      "930\n",
      "930\n",
      "930\n",
      "931\n",
      "932\n",
      "932\n",
      "932\n",
      "932\n",
      "932\n",
      "932\n",
      "932\n",
      "933\n",
      "934\n",
      "934\n",
      "934\n",
      "934\n",
      "934\n",
      "935\n",
      "936\n",
      "936\n",
      "936\n",
      "936\n",
      "936\n",
      "936\n",
      "936\n",
      "936\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "948\n",
      "948\n",
      "948\n",
      "948\n",
      "948\n",
      "948\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "952\n",
      "952\n",
      "953\n",
      "954\n",
      "954\n",
      "955\n",
      "956\n",
      "956\n",
      "956\n",
      "956\n",
      "956\n",
      "956\n",
      "956\n",
      "957\n",
      "958\n",
      "958\n",
      "958\n",
      "959\n",
      "960\n",
      "960\n",
      "960\n",
      "961\n",
      "962\n",
      "962\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "969\n",
      "969\n",
      "969\n",
      "969\n",
      "970\n",
      "971\n",
      "971\n",
      "971\n",
      "972\n",
      "973\n",
      "973\n",
      "973\n",
      "973\n",
      "973\n",
      "973\n",
      "973\n",
      "973\n",
      "973\n",
      "973\n",
      "973\n",
      "973\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "980\n",
      "980\n",
      "981\n",
      "982\n",
      "982\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "986\n",
      "986\n",
      "986\n",
      "986\n",
      "987\n",
      "988\n",
      "988\n",
      "988\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "991\n",
      "991\n",
      "991\n",
      "991\n",
      "991\n",
      "991\n",
      "991\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "994\n",
      "994\n",
      "995\n",
      "996\n",
      "996\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1008\n",
      "1008\n",
      "1008\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-191-febcd1270f0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmismatch_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_0train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meigvals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36meigvals\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36meigvals\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   1067\u001b[0m         _raise_linalgerror_eigenvalues_nonconvergence)\n\u001b[1;32m   1068\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->D'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meigvals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "a=time.time()\n",
    "\n",
    "for k in (2,6):\n",
    "    for m in (range(k)):\n",
    "        K=mismatch_kernel(X_0train,2,0)\n",
    "        A=K.dot(K.T)\n",
    "        u=np.linalg.eigvals(A)\n",
    "        a=0\n",
    "        print(len(u))\n",
    "        for i in range(len(u)):\n",
    "            a+=(u[i]>0)\n",
    "            print(a)\n",
    "        if a==len(u):\n",
    "            print('True for k={} and m={}'.format(k,m))\n",
    "    b=time.time()\n",
    "    print(b-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2000)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "A=K.dot(K.T)\n",
    "A.shape\n",
    "#u=np.linalg.eigvals(A)\n",
    "#a=0\n",
    "#len(u)\n",
    "#for i in range(64):\n",
    "#    a+=(u[i]>0)\n",
    "#a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.matrix_rank(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AAA', 'AAC', 'AAG', 'AAT', 'ACA', 'ACC', 'ACG', 'ACT', 'AGA', 'AGC', 'AGG', 'AGT', 'ATA', 'ATC', 'ATG', 'ATT', 'CAA', 'CAC', 'CAG', 'CAT', 'CCA', 'CCC', 'CCG', 'CCT', 'CGA', 'CGC', 'CGG', 'CGT', 'CTA', 'CTC', 'CTG', 'CTT', 'GAA', 'GAC', 'GAG', 'GAT', 'GCA', 'GCC', 'GCG', 'GCT', 'GGA', 'GGC', 'GGG', 'GGT', 'GTA', 'GTC', 'GTG', 'GTT', 'TAA', 'TAC', 'TAG', 'TAT', 'TCA', 'TCC', 'TCG', 'TCT', 'TGA', 'TGC', 'TGG', 'TGT', 'TTA', 'TTC', 'TTG', 'TTT'] 64\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "iterable=['ACGT']\n",
    "L=[]\n",
    "for subset in list(itertools.product('ACGT', repeat=3)):\n",
    "    subseq=''.join(subset)\n",
    "    L+=[subseq]\n",
    "print(L,len(L))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
